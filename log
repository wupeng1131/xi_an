Epoch: [0][ 0/43]	Time 10.491 (10.491)	Data  0.946 ( 0.946)	Loss 3.8421e+00 (3.8421e+00)	Acc@1   1.56 (  1.56)	Acc@5  12.50 ( 12.50)
Epoch: [0][ 5/43]	Time  0.159 ( 1.887)	Data  0.000 ( 0.158)	Loss 3.7766e+00 (3.8273e+00)	Acc@1   3.12 (  3.12)	Acc@5  17.19 ( 13.54)
Epoch: [0][10/43]	Time  0.226 ( 1.133)	Data  0.000 ( 0.087)	Loss 3.6764e+00 (3.7755e+00)	Acc@1  12.50 (  5.11)	Acc@5  31.25 ( 19.74)
Epoch: [0][15/43]	Time  0.171 ( 0.839)	Data  0.000 ( 0.060)	Loss 3.5441e+00 (3.7132e+00)	Acc@1  25.00 (  8.98)	Acc@5  46.88 ( 26.66)
Epoch: [0][20/43]	Time  0.276 ( 0.694)	Data  0.000 ( 0.046)	Loss 3.3977e+00 (3.6259e+00)	Acc@1  21.88 ( 14.29)	Acc@5  50.00 ( 34.52)
Epoch: [0][25/43]	Time  0.325 ( 0.608)	Data  0.000 ( 0.037)	Loss 3.1308e+00 (3.5456e+00)	Acc@1  37.50 ( 17.67)	Acc@5  62.50 ( 39.78)
Epoch: [0][30/43]	Time  0.149 ( 0.540)	Data  0.001 ( 0.031)	Loss 2.7666e+00 (3.4495e+00)	Acc@1  51.56 ( 21.17)	Acc@5  78.12 ( 44.76)
Epoch: [0][35/43]	Time  0.209 ( 0.492)	Data  0.000 ( 0.027)	Loss 2.6479e+00 (3.3536e+00)	Acc@1  48.44 ( 24.18)	Acc@5  82.81 ( 49.09)
Epoch: [0][40/43]	Time  0.131 ( 0.451)	Data  0.000 ( 0.024)	Loss 2.4009e+00 (3.2502e+00)	Acc@1  59.38 ( 27.59)	Acc@5  82.81 ( 52.97)
learning rate is: 0.0094
Epoch: [1][ 0/43]	Time  1.025 ( 1.025)	Data  0.745 ( 0.745)	Loss 2.3193e+00 (2.3193e+00)	Acc@1  53.12 ( 53.12)	Acc@5  85.94 ( 85.94)
Epoch: [1][ 5/43]	Time  0.192 ( 0.334)	Data  0.000 ( 0.131)	Loss 2.0827e+00 (2.1772e+00)	Acc@1  57.81 ( 57.03)	Acc@5  85.94 ( 85.94)
Epoch: [1][10/43]	Time  0.171 ( 0.272)	Data  0.000 ( 0.071)	Loss 1.8090e+00 (2.0323e+00)	Acc@1  64.06 ( 59.23)	Acc@5  87.50 ( 86.22)
Epoch: [1][15/43]	Time  0.202 ( 0.253)	Data  0.000 ( 0.053)	Loss 1.6400e+00 (1.9343e+00)	Acc@1  70.31 ( 61.72)	Acc@5  85.94 ( 86.43)
Epoch: [1][20/43]	Time  0.158 ( 0.243)	Data  0.000 ( 0.041)	Loss 1.5751e+00 (1.8680e+00)	Acc@1  57.81 ( 62.05)	Acc@5  89.06 ( 87.72)
Epoch: [1][25/43]	Time  0.181 ( 0.234)	Data  0.000 ( 0.033)	Loss 1.3459e+00 (1.8038e+00)	Acc@1  75.00 ( 63.10)	Acc@5  90.62 ( 88.10)
Epoch: [1][30/43]	Time  0.161 ( 0.230)	Data  0.000 ( 0.028)	Loss 1.4509e+00 (1.7224e+00)	Acc@1  70.31 ( 64.11)	Acc@5  85.94 ( 88.46)
Epoch: [1][35/43]	Time  0.186 ( 0.227)	Data  0.001 ( 0.024)	Loss 1.2624e+00 (1.6592e+00)	Acc@1  70.31 ( 64.93)	Acc@5  96.88 ( 89.06)
Epoch: [1][40/43]	Time  0.129 ( 0.222)	Data  0.000 ( 0.021)	Loss 1.1998e+00 (1.6037e+00)	Acc@1  71.88 ( 65.97)	Acc@5  95.31 ( 89.52)
learning rate is: 0.008836
Epoch: [2][ 0/43]	Time  1.068 ( 1.068)	Data  0.794 ( 0.794)	Loss 8.5526e-01 (8.5526e-01)	Acc@1  81.25 ( 81.25)	Acc@5  95.31 ( 95.31)
Epoch: [2][ 5/43]	Time  0.219 ( 0.338)	Data  0.000 ( 0.133)	Loss 1.0943e+00 (9.8343e-01)	Acc@1  71.88 ( 73.70)	Acc@5  93.75 ( 94.53)
Epoch: [2][10/43]	Time  0.271 ( 0.278)	Data  0.000 ( 0.073)	Loss 1.1605e+00 (9.6167e-01)	Acc@1  65.62 ( 75.43)	Acc@5  90.62 ( 94.74)
Epoch: [2][15/43]	Time  0.292 ( 0.256)	Data  0.000 ( 0.050)	Loss 6.8223e-01 (9.2458e-01)	Acc@1  84.38 ( 76.66)	Acc@5  93.75 ( 94.14)
Epoch: [2][20/43]	Time  0.151 ( 0.233)	Data  0.000 ( 0.039)	Loss 8.1518e-01 (9.1317e-01)	Acc@1  82.81 ( 76.34)	Acc@5  93.75 ( 94.27)
Epoch: [2][25/43]	Time  0.265 ( 0.234)	Data  0.000 ( 0.031)	Loss 8.8149e-01 (9.0204e-01)	Acc@1  71.88 ( 76.86)	Acc@5  95.31 ( 94.47)
Epoch: [2][30/43]	Time  0.273 ( 0.231)	Data  0.000 ( 0.026)	Loss 1.0069e+00 (8.9926e-01)	Acc@1  73.44 ( 76.66)	Acc@5  92.19 ( 94.41)
Epoch: [2][35/43]	Time  0.278 ( 0.225)	Data  0.000 ( 0.023)	Loss 8.7447e-01 (8.7738e-01)	Acc@1  76.56 ( 77.43)	Acc@5  90.62 ( 94.66)
Epoch: [2][40/43]	Time  0.130 ( 0.217)	Data  0.000 ( 0.020)	Loss 8.0072e-01 (8.6387e-01)	Acc@1  75.00 ( 77.52)	Acc@5  96.88 ( 94.70)
learning rate is: 0.008305839999999998
Epoch: [3][ 0/43]	Time  1.062 ( 1.062)	Data  0.793 ( 0.793)	Loss 5.9800e-01 (5.9800e-01)	Acc@1  84.38 ( 84.38)	Acc@5  96.88 ( 96.88)
Epoch: [3][ 5/43]	Time  0.132 ( 0.347)	Data  0.000 ( 0.133)	Loss 6.7386e-01 (6.4470e-01)	Acc@1  79.69 ( 82.29)	Acc@5  96.88 ( 96.09)
Epoch: [3][10/43]	Time  0.256 ( 0.273)	Data  0.001 ( 0.073)	Loss 7.8434e-01 (6.4131e-01)	Acc@1  82.81 ( 81.39)	Acc@5  95.31 ( 96.59)
Epoch: [3][15/43]	Time  0.155 ( 0.238)	Data  0.000 ( 0.050)	Loss 5.2485e-01 (6.1413e-01)	Acc@1  82.81 ( 81.93)	Acc@5  98.44 ( 97.17)
Epoch: [3][20/43]	Time  0.204 ( 0.231)	Data  0.000 ( 0.038)	Loss 7.0700e-01 (6.1753e-01)	Acc@1  81.25 ( 81.77)	Acc@5  92.19 ( 96.73)
Epoch: [3][25/43]	Time  0.227 ( 0.229)	Data  0.000 ( 0.031)	Loss 5.4646e-01 (6.0541e-01)	Acc@1  81.25 ( 82.15)	Acc@5  93.75 ( 96.88)
Epoch: [3][30/43]	Time  0.187 ( 0.223)	Data  0.000 ( 0.026)	Loss 6.0675e-01 (6.1412e-01)	Acc@1  79.69 ( 82.01)	Acc@5  96.88 ( 96.72)
Epoch: [3][35/43]	Time  0.260 ( 0.223)	Data  0.000 ( 0.023)	Loss 4.2662e-01 (6.1054e-01)	Acc@1  89.06 ( 81.99)	Acc@5  96.88 ( 96.61)
Epoch: [3][40/43]	Time  0.130 ( 0.216)	Data  0.000 ( 0.020)	Loss 4.5418e-01 (6.1377e-01)	Acc@1  84.38 ( 81.86)	Acc@5 100.00 ( 96.61)
learning rate is: 0.007807489599999998
Epoch: [4][ 0/43]	Time  1.030 ( 1.030)	Data  0.828 ( 0.828)	Loss 5.6372e-01 (5.6372e-01)	Acc@1  76.56 ( 76.56)	Acc@5  98.44 ( 98.44)
Epoch: [4][ 5/43]	Time  0.132 ( 0.331)	Data  0.000 ( 0.138)	Loss 3.7890e-01 (4.9064e-01)	Acc@1  89.06 ( 83.85)	Acc@5  98.44 ( 97.66)
Epoch: [4][10/43]	Time  0.238 ( 0.270)	Data  0.001 ( 0.076)	Loss 6.4651e-01 (4.8972e-01)	Acc@1  76.56 ( 84.09)	Acc@5  92.19 ( 97.44)
Epoch: [4][15/43]	Time  0.276 ( 0.245)	Data  0.000 ( 0.052)	Loss 4.8095e-01 (5.3456e-01)	Acc@1  81.25 ( 82.23)	Acc@5  96.88 ( 97.17)
Epoch: [4][20/43]	Time  0.217 ( 0.238)	Data  0.002 ( 0.040)	Loss 5.7087e-01 (5.2194e-01)	Acc@1  75.00 ( 82.44)	Acc@5  98.44 ( 97.40)
Epoch: [4][25/43]	Time  0.223 ( 0.231)	Data  0.000 ( 0.032)	Loss 4.3408e-01 (5.1692e-01)	Acc@1  85.94 ( 82.15)	Acc@5 100.00 ( 97.48)
Epoch: [4][30/43]	Time  0.184 ( 0.225)	Data  0.000 ( 0.027)	Loss 4.9616e-01 (5.0403e-01)	Acc@1  84.38 ( 82.86)	Acc@5  98.44 ( 97.68)
Epoch: [4][35/43]	Time  0.190 ( 0.223)	Data  0.000 ( 0.024)	Loss 3.9734e-01 (5.0424e-01)	Acc@1  84.38 ( 83.16)	Acc@5  98.44 ( 97.57)
Epoch: [4][40/43]	Time  0.131 ( 0.214)	Data  0.000 ( 0.021)	Loss 5.0082e-01 (4.9830e-01)	Acc@1  84.38 ( 83.50)	Acc@5  98.44 ( 97.68)
Test: [ 0/16]	Time  1.003 ( 1.003)	Loss 3.0674e-01 (3.0674e-01)	Acc@1  85.94 ( 85.94)	Acc@5 100.00 (100.00)
Test: [ 5/16]	Time  0.101 ( 0.310)	Loss 2.7023e-01 (1.9693e-01)	Acc@1  90.62 ( 92.71)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.044 ( 0.254)	Loss 5.4878e-01 (2.9393e-01)	Acc@1  75.00 ( 88.92)	Acc@5  95.31 ( 98.72)
Test: [15/16]	Time  0.437 ( 0.249)	Loss 1.2217e-01 (3.0436e-01)	Acc@1 100.00 ( 89.80)	Acc@5 100.00 ( 98.80)
 * Acc@1 89.800 Acc@5 98.800
learning rate is: 0.007339040223999997
Epoch: [5][ 0/43]	Time  1.103 ( 1.103)	Data  0.747 ( 0.747)	Loss 4.5277e-01 (4.5277e-01)	Acc@1  82.81 ( 82.81)	Acc@5  98.44 ( 98.44)
Epoch: [5][ 5/43]	Time  0.185 ( 0.345)	Data  0.000 ( 0.125)	Loss 4.3639e-01 (5.1370e-01)	Acc@1  89.06 ( 83.33)	Acc@5  96.88 ( 96.09)
Epoch: [5][10/43]	Time  0.223 ( 0.286)	Data  0.000 ( 0.068)	Loss 4.0647e-01 (4.9432e-01)	Acc@1  79.69 ( 83.81)	Acc@5 100.00 ( 97.16)
Epoch: [5][15/43]	Time  0.224 ( 0.259)	Data  0.000 ( 0.047)	Loss 4.9006e-01 (4.7229e-01)	Acc@1  87.50 ( 84.47)	Acc@5  96.88 ( 97.56)
Epoch: [5][20/43]	Time  0.175 ( 0.243)	Data  0.000 ( 0.036)	Loss 6.8611e-01 (4.7599e-01)	Acc@1  76.56 ( 83.63)	Acc@5  90.62 ( 97.17)
Epoch: [5][25/43]	Time  0.212 ( 0.236)	Data  0.000 ( 0.029)	Loss 4.1972e-01 (4.7170e-01)	Acc@1  87.50 ( 84.07)	Acc@5  98.44 ( 97.18)
Epoch: [5][30/43]	Time  0.204 ( 0.230)	Data  0.000 ( 0.025)	Loss 4.2408e-01 (4.6675e-01)	Acc@1  85.94 ( 84.02)	Acc@5  96.88 ( 97.18)
Epoch: [5][35/43]	Time  0.216 ( 0.227)	Data  0.000 ( 0.021)	Loss 4.4400e-01 (4.5721e-01)	Acc@1  84.38 ( 84.24)	Acc@5  96.88 ( 97.31)
Epoch: [5][40/43]	Time  0.131 ( 0.222)	Data  0.000 ( 0.019)	Loss 2.7750e-01 (4.4069e-01)	Acc@1  95.31 ( 84.95)	Acc@5  98.44 ( 97.41)
learning rate is: 0.006898697810559997
Epoch: [6][ 0/43]	Time  1.093 ( 1.093)	Data  0.785 ( 0.785)	Loss 4.8017e-01 (4.8017e-01)	Acc@1  87.50 ( 87.50)	Acc@5  95.31 ( 95.31)
Epoch: [6][ 5/43]	Time  0.163 ( 0.330)	Data  0.000 ( 0.132)	Loss 2.2439e-01 (3.7916e-01)	Acc@1  95.31 ( 88.80)	Acc@5 100.00 ( 97.40)
Epoch: [6][10/43]	Time  0.174 ( 0.268)	Data  0.000 ( 0.072)	Loss 4.1848e-01 (3.8876e-01)	Acc@1  84.38 ( 87.64)	Acc@5  95.31 ( 97.87)
Epoch: [6][15/43]	Time  0.170 ( 0.244)	Data  0.000 ( 0.050)	Loss 2.9925e-01 (3.8022e-01)	Acc@1  89.06 ( 87.21)	Acc@5  98.44 ( 98.14)
Epoch: [6][20/43]	Time  0.137 ( 0.234)	Data  0.000 ( 0.038)	Loss 4.5204e-01 (3.8925e-01)	Acc@1  84.38 ( 86.83)	Acc@5  96.88 ( 97.77)
Epoch: [6][25/43]	Time  0.173 ( 0.225)	Data  0.000 ( 0.031)	Loss 2.7543e-01 (3.8027e-01)	Acc@1  92.19 ( 87.32)	Acc@5  98.44 ( 97.78)
Epoch: [6][30/43]	Time  0.134 ( 0.223)	Data  0.000 ( 0.026)	Loss 2.8214e-01 (3.6836e-01)	Acc@1  89.06 ( 87.50)	Acc@5 100.00 ( 97.93)
Epoch: [6][35/43]	Time  0.217 ( 0.221)	Data  0.000 ( 0.022)	Loss 2.2548e-01 (3.6555e-01)	Acc@1  92.19 ( 87.63)	Acc@5 100.00 ( 98.00)
Epoch: [6][40/43]	Time  0.131 ( 0.216)	Data  0.000 ( 0.020)	Loss 3.9321e-01 (3.7752e-01)	Acc@1  87.50 ( 87.08)	Acc@5  96.88 ( 97.83)
learning rate is: 0.006484775941926397
Epoch: [7][ 0/43]	Time  1.031 ( 1.031)	Data  0.774 ( 0.774)	Loss 3.5237e-01 (3.5237e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
Epoch: [7][ 5/43]	Time  0.171 ( 0.340)	Data  0.000 ( 0.129)	Loss 3.8665e-01 (3.2741e-01)	Acc@1  84.38 ( 89.06)	Acc@5  96.88 ( 98.70)
Epoch: [7][10/43]	Time  0.300 ( 0.273)	Data  0.000 ( 0.071)	Loss 3.5094e-01 (3.1764e-01)	Acc@1  84.38 ( 87.50)	Acc@5  98.44 ( 98.86)
Epoch: [7][15/43]	Time  0.278 ( 0.250)	Data  0.000 ( 0.049)	Loss 3.4885e-01 (3.2370e-01)	Acc@1  87.50 ( 87.99)	Acc@5  96.88 ( 98.73)
Epoch: [7][20/43]	Time  0.256 ( 0.236)	Data  0.000 ( 0.037)	Loss 3.3633e-01 (3.1579e-01)	Acc@1  90.62 ( 88.62)	Acc@5  98.44 ( 98.96)
Epoch: [7][25/43]	Time  0.186 ( 0.233)	Data  0.000 ( 0.030)	Loss 3.9015e-01 (3.1910e-01)	Acc@1  89.06 ( 88.64)	Acc@5  98.44 ( 98.98)
Epoch: [7][30/43]	Time  0.235 ( 0.231)	Data  0.001 ( 0.026)	Loss 2.7391e-01 (3.2585e-01)	Acc@1  93.75 ( 88.36)	Acc@5  96.88 ( 98.74)
Epoch: [7][35/43]	Time  0.202 ( 0.227)	Data  0.000 ( 0.022)	Loss 2.0087e-01 (3.2098e-01)	Acc@1  93.75 ( 88.63)	Acc@5 100.00 ( 98.65)
Epoch: [7][40/43]	Time  0.139 ( 0.218)	Data  0.000 ( 0.020)	Loss 3.7255e-01 (3.1617e-01)	Acc@1  85.94 ( 88.80)	Acc@5 100.00 ( 98.67)
learning rate is: 0.006095689385410813
Epoch: [8][ 0/43]	Time  1.071 ( 1.071)	Data  0.777 ( 0.777)	Loss 3.5634e-01 (3.5634e-01)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [8][ 5/43]	Time  0.199 ( 0.334)	Data  0.000 ( 0.130)	Loss 3.2120e-01 (3.0356e-01)	Acc@1  89.06 ( 90.10)	Acc@5  98.44 ( 98.70)
Epoch: [8][10/43]	Time  0.303 ( 0.275)	Data  0.000 ( 0.071)	Loss 3.2514e-01 (3.2046e-01)	Acc@1  85.94 ( 88.35)	Acc@5  96.88 ( 98.15)
Epoch: [8][15/43]	Time  0.275 ( 0.257)	Data  0.000 ( 0.049)	Loss 2.8626e-01 (3.1377e-01)	Acc@1  92.19 ( 88.48)	Acc@5  98.44 ( 98.14)
Epoch: [8][20/43]	Time  0.162 ( 0.239)	Data  0.000 ( 0.038)	Loss 3.9469e-01 (3.1676e-01)	Acc@1  81.25 ( 88.47)	Acc@5  98.44 ( 98.21)
Epoch: [8][25/43]	Time  0.198 ( 0.233)	Data  0.000 ( 0.031)	Loss 1.2449e-01 (3.0979e-01)	Acc@1  95.31 ( 88.70)	Acc@5 100.00 ( 98.26)
Epoch: [8][30/43]	Time  0.254 ( 0.232)	Data  0.000 ( 0.026)	Loss 2.4112e-01 (3.1085e-01)	Acc@1  93.75 ( 88.86)	Acc@5 100.00 ( 98.29)
Epoch: [8][35/43]	Time  0.154 ( 0.224)	Data  0.000 ( 0.022)	Loss 3.3830e-01 (3.1448e-01)	Acc@1  84.38 ( 88.41)	Acc@5  98.44 ( 98.31)
Epoch: [8][40/43]	Time  0.131 ( 0.219)	Data  0.000 ( 0.020)	Loss 3.5938e-01 (3.2086e-01)	Acc@1  85.94 ( 88.22)	Acc@5  96.88 ( 98.17)
learning rate is: 0.0057299480222861646
Epoch: [9][ 0/43]	Time  1.061 ( 1.061)	Data  0.832 ( 0.832)	Loss 3.6960e-01 (3.6960e-01)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [9][ 5/43]	Time  0.159 ( 0.327)	Data  0.000 ( 0.139)	Loss 4.7122e-01 (3.1492e-01)	Acc@1  84.38 ( 88.28)	Acc@5  95.31 ( 97.92)
Epoch: [9][10/43]	Time  0.186 ( 0.268)	Data  0.000 ( 0.076)	Loss 2.6402e-01 (2.9697e-01)	Acc@1  90.62 ( 89.77)	Acc@5 100.00 ( 98.30)
Epoch: [9][15/43]	Time  0.200 ( 0.247)	Data  0.000 ( 0.053)	Loss 3.0788e-01 (3.0896e-01)	Acc@1  90.62 ( 88.57)	Acc@5  98.44 ( 98.54)
Epoch: [9][20/43]	Time  0.174 ( 0.237)	Data  0.000 ( 0.040)	Loss 2.2311e-01 (2.9145e-01)	Acc@1  93.75 ( 89.66)	Acc@5  96.88 ( 98.36)
Epoch: [9][25/43]	Time  0.197 ( 0.232)	Data  0.000 ( 0.033)	Loss 3.3916e-01 (2.9712e-01)	Acc@1  89.06 ( 88.94)	Acc@5  98.44 ( 98.38)
Epoch: [9][30/43]	Time  0.164 ( 0.225)	Data  0.000 ( 0.027)	Loss 2.4196e-01 (2.9106e-01)	Acc@1  90.62 ( 89.21)	Acc@5  98.44 ( 98.44)
Epoch: [9][35/43]	Time  0.180 ( 0.222)	Data  0.001 ( 0.024)	Loss 2.0874e-01 (2.8934e-01)	Acc@1  93.75 ( 89.19)	Acc@5 100.00 ( 98.61)
Epoch: [9][40/43]	Time  0.131 ( 0.219)	Data  0.000 ( 0.021)	Loss 3.4999e-01 (2.9476e-01)	Acc@1  89.06 ( 89.14)	Acc@5  98.44 ( 98.48)
Test: [ 0/16]	Time  1.004 ( 1.004)	Loss 2.0711e-01 (2.0711e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Test: [ 5/16]	Time  0.303 ( 0.343)	Loss 2.0053e-01 (1.3827e-01)	Acc@1  93.75 ( 94.27)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.072 ( 0.266)	Loss 3.9456e-01 (2.1631e-01)	Acc@1  81.25 ( 91.05)	Acc@5  96.88 ( 98.72)
Test: [15/16]	Time  0.064 ( 0.240)	Loss 6.3498e-02 (2.1802e-01)	Acc@1 100.00 ( 91.40)	Acc@5 100.00 ( 98.80)
 * Acc@1 91.400 Acc@5 98.800
learning rate is: 0.005386151140948993
Epoch: [10][ 0/43]	Time  1.034 ( 1.034)	Data  0.790 ( 0.790)	Loss 4.5187e-01 (4.5187e-01)	Acc@1  84.38 ( 84.38)	Acc@5  95.31 ( 95.31)
Epoch: [10][ 5/43]	Time  0.233 ( 0.333)	Data  0.000 ( 0.132)	Loss 3.6977e-01 (3.2261e-01)	Acc@1  85.94 ( 88.80)	Acc@5  98.44 ( 97.66)
Epoch: [10][10/43]	Time  0.211 ( 0.266)	Data  0.000 ( 0.072)	Loss 2.5748e-01 (3.0254e-01)	Acc@1  89.06 ( 88.49)	Acc@5  98.44 ( 98.01)
Epoch: [10][15/43]	Time  0.293 ( 0.257)	Data  0.000 ( 0.050)	Loss 1.7655e-01 (2.8413e-01)	Acc@1  93.75 ( 88.96)	Acc@5 100.00 ( 98.54)
Epoch: [10][20/43]	Time  0.185 ( 0.237)	Data  0.000 ( 0.038)	Loss 4.4443e-01 (3.0174e-01)	Acc@1  81.25 ( 88.47)	Acc@5  96.88 ( 98.29)
Epoch: [10][25/43]	Time  0.173 ( 0.229)	Data  0.000 ( 0.031)	Loss 1.8613e-01 (2.9900e-01)	Acc@1  92.19 ( 88.52)	Acc@5  98.44 ( 98.38)
Epoch: [10][30/43]	Time  0.189 ( 0.220)	Data  0.000 ( 0.026)	Loss 3.9325e-01 (3.0096e-01)	Acc@1  84.38 ( 88.46)	Acc@5  98.44 ( 98.34)
Epoch: [10][35/43]	Time  0.209 ( 0.214)	Data  0.000 ( 0.023)	Loss 2.2675e-01 (2.9329e-01)	Acc@1  90.62 ( 88.89)	Acc@5 100.00 ( 98.48)
Epoch: [10][40/43]	Time  0.122 ( 0.206)	Data  0.000 ( 0.020)	Loss 1.7588e-01 (2.9098e-01)	Acc@1  92.19 ( 88.80)	Acc@5 100.00 ( 98.55)
learning rate is: 0.005062982072492054
Epoch: [11][ 0/43]	Time  1.172 ( 1.172)	Data  0.981 ( 0.981)	Loss 2.0285e-01 (2.0285e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [11][ 5/43]	Time  0.129 ( 0.346)	Data  0.000 ( 0.169)	Loss 2.0351e-01 (3.0433e-01)	Acc@1  92.19 ( 87.50)	Acc@5 100.00 ( 97.92)
Epoch: [11][10/43]	Time  0.192 ( 0.270)	Data  0.000 ( 0.098)	Loss 2.0695e-01 (2.7749e-01)	Acc@1  87.50 ( 88.92)	Acc@5 100.00 ( 98.15)
Epoch: [11][15/43]	Time  0.222 ( 0.249)	Data  0.000 ( 0.074)	Loss 3.6072e-01 (2.8586e-01)	Acc@1  85.94 ( 88.87)	Acc@5  96.88 ( 98.34)
Epoch: [11][20/43]	Time  0.280 ( 0.239)	Data  0.110 ( 0.063)	Loss 2.9734e-01 (2.8692e-01)	Acc@1  89.06 ( 88.91)	Acc@5  96.88 ( 98.29)
Epoch: [11][25/43]	Time  0.212 ( 0.230)	Data  0.000 ( 0.055)	Loss 1.8424e-01 (2.7908e-01)	Acc@1  92.19 ( 89.06)	Acc@5 100.00 ( 98.50)
Epoch: [11][30/43]	Time  0.140 ( 0.222)	Data  0.000 ( 0.049)	Loss 1.7245e-01 (2.7341e-01)	Acc@1  95.31 ( 89.31)	Acc@5  98.44 ( 98.59)
Epoch: [11][35/43]	Time  0.160 ( 0.220)	Data  0.000 ( 0.046)	Loss 2.1289e-01 (2.6944e-01)	Acc@1  90.62 ( 89.37)	Acc@5  98.44 ( 98.70)
Epoch: [11][40/43]	Time  0.302 ( 0.219)	Data  0.121 ( 0.045)	Loss 2.0247e-01 (2.6731e-01)	Acc@1  93.75 ( 89.63)	Acc@5 100.00 ( 98.67)
learning rate is: 0.00475920314814253
Epoch: [12][ 0/43]	Time  1.473 ( 1.473)	Data  1.282 ( 1.282)	Loss 2.4264e-01 (2.4264e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [12][ 5/43]	Time  0.183 ( 0.408)	Data  0.034 ( 0.251)	Loss 4.4616e-01 (3.2455e-01)	Acc@1  79.69 ( 88.02)	Acc@5  95.31 ( 97.66)
Epoch: [12][10/43]	Time  0.149 ( 0.327)	Data  0.000 ( 0.166)	Loss 2.6586e-01 (2.9517e-01)	Acc@1  93.75 ( 88.92)	Acc@5  98.44 ( 98.30)
Epoch: [12][15/43]	Time  0.133 ( 0.296)	Data  0.000 ( 0.141)	Loss 2.7408e-01 (2.8740e-01)	Acc@1  89.06 ( 89.16)	Acc@5 100.00 ( 98.54)
Epoch: [12][20/43]	Time  0.306 ( 0.285)	Data  0.124 ( 0.129)	Loss 2.7345e-01 (2.7505e-01)	Acc@1  90.62 ( 89.51)	Acc@5  98.44 ( 98.59)
Epoch: [12][25/43]	Time  0.373 ( 0.278)	Data  0.201 ( 0.118)	Loss 2.7584e-01 (2.6721e-01)	Acc@1  84.38 ( 89.84)	Acc@5  96.88 ( 98.62)
Epoch: [12][30/43]	Time  0.176 ( 0.269)	Data  0.000 ( 0.105)	Loss 4.3198e-01 (2.6495e-01)	Acc@1  84.38 ( 89.92)	Acc@5  95.31 ( 98.59)
Epoch: [12][35/43]	Time  0.275 ( 0.267)	Data  0.000 ( 0.095)	Loss 1.7916e-01 (2.5885e-01)	Acc@1  95.31 ( 90.28)	Acc@5 100.00 ( 98.61)
Epoch: [12][40/43]	Time  0.379 ( 0.260)	Data  0.196 ( 0.089)	Loss 4.3367e-01 (2.6307e-01)	Acc@1  87.50 ( 90.02)	Acc@5  95.31 ( 98.51)
learning rate is: 0.004473650959253978
Epoch: [13][ 0/43]	Time  1.446 ( 1.446)	Data  1.232 ( 1.232)	Loss 2.0612e-01 (2.0612e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [13][ 5/43]	Time  0.194 ( 0.423)	Data  0.000 ( 0.247)	Loss 4.1942e-01 (2.9193e-01)	Acc@1  87.50 ( 89.84)	Acc@5  98.44 ( 98.44)
Epoch: [13][10/43]	Time  0.154 ( 0.327)	Data  0.000 ( 0.146)	Loss 1.3747e-01 (2.7317e-01)	Acc@1  95.31 ( 89.63)	Acc@5 100.00 ( 98.30)
Epoch: [13][15/43]	Time  0.153 ( 0.309)	Data  0.000 ( 0.131)	Loss 2.5051e-01 (2.5648e-01)	Acc@1  89.06 ( 90.43)	Acc@5  98.44 ( 98.24)
Epoch: [13][20/43]	Time  0.571 ( 0.312)	Data  0.395 ( 0.137)	Loss 2.0216e-01 (2.5432e-01)	Acc@1  90.62 ( 90.33)	Acc@5 100.00 ( 98.51)
Epoch: [13][25/43]	Time  0.164 ( 0.301)	Data  0.000 ( 0.125)	Loss 2.3010e-01 (2.5756e-01)	Acc@1  90.62 ( 89.96)	Acc@5 100.00 ( 98.62)
Epoch: [13][30/43]	Time  0.188 ( 0.284)	Data  0.000 ( 0.107)	Loss 3.2404e-01 (2.6376e-01)	Acc@1  90.62 ( 89.82)	Acc@5  96.88 ( 98.49)
Epoch: [13][35/43]	Time  0.193 ( 0.277)	Data  0.000 ( 0.101)	Loss 1.0298e-01 (2.5845e-01)	Acc@1  96.88 ( 90.02)	Acc@5 100.00 ( 98.44)
Epoch: [13][40/43]	Time  0.299 ( 0.275)	Data  0.130 ( 0.099)	Loss 2.6872e-01 (2.5471e-01)	Acc@1  90.62 ( 90.17)	Acc@5  98.44 ( 98.44)
learning rate is: 0.004205231901698739
Epoch: [14][ 0/43]	Time  1.361 ( 1.361)	Data  1.183 ( 1.183)	Loss 1.8155e-01 (1.8155e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [14][ 5/43]	Time  0.323 ( 0.416)	Data  0.145 ( 0.242)	Loss 2.9589e-01 (2.4492e-01)	Acc@1  89.06 ( 90.10)	Acc@5 100.00 ( 99.22)
Epoch: [14][10/43]	Time  0.192 ( 0.336)	Data  0.000 ( 0.158)	Loss 1.7967e-01 (2.4482e-01)	Acc@1  92.19 ( 90.62)	Acc@5 100.00 ( 99.01)
Epoch: [14][15/43]	Time  0.440 ( 0.317)	Data  0.132 ( 0.132)	Loss 4.0614e-01 (2.3575e-01)	Acc@1  85.94 ( 90.62)	Acc@5  96.88 ( 98.83)
Epoch: [14][20/43]	Time  0.149 ( 0.291)	Data  0.000 ( 0.109)	Loss 2.3219e-01 (2.5669e-01)	Acc@1  90.62 ( 90.25)	Acc@5 100.00 ( 98.59)
Epoch: [14][25/43]	Time  0.162 ( 0.286)	Data  0.001 ( 0.107)	Loss 2.9416e-01 (2.4469e-01)	Acc@1  85.94 ( 90.50)	Acc@5 100.00 ( 98.80)
Epoch: [14][30/43]	Time  0.358 ( 0.293)	Data  0.223 ( 0.112)	Loss 2.2263e-01 (2.4725e-01)	Acc@1  90.62 ( 90.88)	Acc@5 100.00 ( 98.64)
Epoch: [14][35/43]	Time  0.164 ( 0.303)	Data  0.000 ( 0.124)	Loss 1.4178e-01 (2.3822e-01)	Acc@1  95.31 ( 91.28)	Acc@5 100.00 ( 98.78)
Epoch: [14][40/43]	Time  0.145 ( 0.286)	Data  0.000 ( 0.112)	Loss 2.1711e-01 (2.3914e-01)	Acc@1  89.06 ( 91.16)	Acc@5 100.00 ( 98.82)
Test: [ 0/16]	Time  1.512 ( 1.512)	Loss 1.9354e-01 (1.9354e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.296 ( 0.501)	Loss 1.6143e-01 (1.1418e-01)	Acc@1  92.19 ( 95.05)	Acc@5 100.00 ( 99.48)
Test: [10/16]	Time  0.093 ( 0.380)	Loss 3.4016e-01 (1.8357e-01)	Acc@1  84.38 ( 92.05)	Acc@5  96.88 ( 98.72)
Test: [15/16]	Time  0.048 ( 0.339)	Loss 4.2090e-02 (1.8751e-01)	Acc@1 100.00 ( 92.40)	Acc@5 100.00 ( 98.70)
 * Acc@1 92.400 Acc@5 98.700
learning rate is: 0.003952917987596815
Epoch: [15][ 0/43]	Time  1.645 ( 1.645)	Data  1.293 ( 1.293)	Loss 3.3422e-01 (3.3422e-01)	Acc@1  87.50 ( 87.50)	Acc@5  96.88 ( 96.88)
Epoch: [15][ 5/43]	Time  0.171 ( 0.431)	Data  0.001 ( 0.242)	Loss 2.7013e-01 (2.6288e-01)	Acc@1  89.06 ( 88.54)	Acc@5 100.00 ( 99.22)
Epoch: [15][10/43]	Time  0.152 ( 0.361)	Data  0.000 ( 0.186)	Loss 2.6709e-01 (2.6885e-01)	Acc@1  87.50 ( 89.49)	Acc@5  98.44 ( 98.58)
Epoch: [15][15/43]	Time  0.146 ( 0.322)	Data  0.000 ( 0.150)	Loss 3.2095e-01 (2.5564e-01)	Acc@1  90.62 ( 90.23)	Acc@5  98.44 ( 98.83)
Epoch: [15][20/43]	Time  0.708 ( 0.336)	Data  0.525 ( 0.165)	Loss 1.4252e-01 (2.4573e-01)	Acc@1  93.75 ( 90.33)	Acc@5 100.00 ( 98.88)
Epoch: [15][25/43]	Time  0.175 ( 0.329)	Data  0.001 ( 0.156)	Loss 2.6481e-01 (2.3802e-01)	Acc@1  87.50 ( 90.75)	Acc@5 100.00 ( 98.98)
Epoch: [15][30/43]	Time  0.162 ( 0.315)	Data  0.000 ( 0.142)	Loss 2.1876e-01 (2.3167e-01)	Acc@1  92.19 ( 91.13)	Acc@5 100.00 ( 99.04)
Epoch: [15][35/43]	Time  0.154 ( 0.304)	Data  0.000 ( 0.130)	Loss 1.8215e-01 (2.2573e-01)	Acc@1  92.19 ( 91.19)	Acc@5 100.00 ( 99.09)
Epoch: [15][40/43]	Time  0.491 ( 0.304)	Data  0.315 ( 0.133)	Loss 1.3779e-01 (2.1869e-01)	Acc@1  95.31 ( 91.46)	Acc@5  98.44 ( 99.01)
learning rate is: 0.003715742908341006
Epoch: [16][ 0/43]	Time  1.360 ( 1.360)	Data  1.195 ( 1.195)	Loss 1.2647e-01 (1.2647e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [16][ 5/43]	Time  0.512 ( 0.508)	Data  0.340 ( 0.349)	Loss 2.2598e-01 (2.2438e-01)	Acc@1  92.19 ( 90.36)	Acc@5  96.88 ( 98.96)
Epoch: [16][10/43]	Time  0.182 ( 0.373)	Data  0.023 ( 0.211)	Loss 1.8163e-01 (1.9963e-01)	Acc@1  92.19 ( 91.90)	Acc@5 100.00 ( 99.43)
Epoch: [16][15/43]	Time  0.153 ( 0.335)	Data  0.000 ( 0.171)	Loss 1.6104e-01 (2.0677e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 99.41)
Epoch: [16][20/43]	Time  0.590 ( 0.337)	Data  0.418 ( 0.173)	Loss 2.3031e-01 (2.3050e-01)	Acc@1  90.62 ( 91.29)	Acc@5 100.00 ( 99.11)
Epoch: [16][25/43]	Time  0.175 ( 0.321)	Data  0.000 ( 0.154)	Loss 3.7389e-01 (2.3642e-01)	Acc@1  84.38 ( 90.87)	Acc@5  95.31 ( 98.92)
Epoch: [16][30/43]	Time  0.207 ( 0.306)	Data  0.053 ( 0.138)	Loss 3.2639e-01 (2.4102e-01)	Acc@1  90.62 ( 90.93)	Acc@5  98.44 ( 98.89)
Epoch: [16][35/43]	Time  0.131 ( 0.304)	Data  0.000 ( 0.136)	Loss 2.2960e-01 (2.3406e-01)	Acc@1  92.19 ( 90.97)	Acc@5  96.88 ( 98.87)
Epoch: [16][40/43]	Time  0.365 ( 0.295)	Data  0.186 ( 0.127)	Loss 2.1060e-01 (2.3223e-01)	Acc@1  92.19 ( 90.97)	Acc@5  98.44 ( 98.86)
learning rate is: 0.0034927983338405456
Epoch: [17][ 0/43]	Time  1.430 ( 1.430)	Data  1.244 ( 1.244)	Loss 1.4955e-01 (1.4955e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [17][ 5/43]	Time  0.162 ( 0.400)	Data  0.000 ( 0.237)	Loss 1.8382e-01 (2.4398e-01)	Acc@1  96.88 ( 89.58)	Acc@5 100.00 ( 98.44)
Epoch: [17][10/43]	Time  0.157 ( 0.310)	Data  0.000 ( 0.146)	Loss 2.0636e-01 (2.2370e-01)	Acc@1  93.75 ( 90.91)	Acc@5  98.44 ( 98.72)
Epoch: [17][15/43]	Time  0.366 ( 0.295)	Data  0.152 ( 0.130)	Loss 2.2962e-01 (2.0762e-01)	Acc@1  93.75 ( 91.89)	Acc@5  98.44 ( 98.93)
Epoch: [17][20/43]	Time  0.340 ( 0.282)	Data  0.180 ( 0.112)	Loss 3.5792e-01 (2.1064e-01)	Acc@1  90.62 ( 91.89)	Acc@5  96.88 ( 98.81)
Epoch: [17][25/43]	Time  0.137 ( 0.271)	Data  0.000 ( 0.105)	Loss 1.8019e-01 (2.0912e-01)	Acc@1  93.75 ( 91.71)	Acc@5  96.88 ( 98.80)
Epoch: [17][30/43]	Time  0.132 ( 0.258)	Data  0.000 ( 0.095)	Loss 2.7755e-01 (2.0739e-01)	Acc@1  90.62 ( 91.73)	Acc@5  98.44 ( 98.79)
Epoch: [17][35/43]	Time  0.689 ( 0.281)	Data  0.523 ( 0.117)	Loss 2.6234e-01 (2.1181e-01)	Acc@1  89.06 ( 91.62)	Acc@5  98.44 ( 98.74)
Epoch: [17][40/43]	Time  0.142 ( 0.271)	Data  0.000 ( 0.110)	Loss 2.6477e-01 (2.1092e-01)	Acc@1  90.62 ( 91.77)	Acc@5 100.00 ( 98.82)
learning rate is: 0.0032832304338101127
Epoch: [18][ 0/43]	Time  1.840 ( 1.840)	Data  1.658 ( 1.658)	Loss 1.5547e-01 (1.5547e-01)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Epoch: [18][ 5/43]	Time  0.167 ( 0.516)	Data  0.000 ( 0.341)	Loss 2.4383e-01 (2.0451e-01)	Acc@1  87.50 ( 89.32)	Acc@5 100.00 ( 99.22)
Epoch: [18][10/43]	Time  0.244 ( 0.392)	Data  0.000 ( 0.214)	Loss 1.5699e-01 (2.1118e-01)	Acc@1  92.19 ( 90.62)	Acc@5 100.00 ( 99.01)
Epoch: [18][15/43]	Time  0.149 ( 0.340)	Data  0.000 ( 0.168)	Loss 3.1954e-01 (2.1952e-01)	Acc@1  87.50 ( 90.82)	Acc@5  96.88 ( 98.73)
Epoch: [18][20/43]	Time  0.444 ( 0.334)	Data  0.276 ( 0.165)	Loss 2.8639e-01 (2.2462e-01)	Acc@1  87.50 ( 90.33)	Acc@5 100.00 ( 98.51)
Epoch: [18][25/43]	Time  0.145 ( 0.318)	Data  0.000 ( 0.150)	Loss 1.9813e-01 (2.2336e-01)	Acc@1  90.62 ( 90.50)	Acc@5 100.00 ( 98.62)
Epoch: [18][30/43]	Time  0.186 ( 0.308)	Data  0.000 ( 0.140)	Loss 1.7985e-01 (2.2378e-01)	Acc@1  92.19 ( 90.68)	Acc@5 100.00 ( 98.69)
Epoch: [18][35/43]	Time  0.172 ( 0.298)	Data  0.000 ( 0.129)	Loss 2.3524e-01 (2.2463e-01)	Acc@1  85.94 ( 90.45)	Acc@5  98.44 ( 98.65)
Epoch: [18][40/43]	Time  0.464 ( 0.293)	Data  0.315 ( 0.125)	Loss 1.9348e-01 (2.2483e-01)	Acc@1  92.19 ( 90.40)	Acc@5  98.44 ( 98.63)
learning rate is: 0.0030862366077815057
Epoch: [19][ 0/43]	Time  1.402 ( 1.402)	Data  1.220 ( 1.220)	Loss 3.3305e-01 (3.3305e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [19][ 5/43]	Time  0.418 ( 0.467)	Data  0.232 ( 0.273)	Loss 2.2616e-01 (2.4357e-01)	Acc@1  89.06 ( 91.41)	Acc@5  98.44 ( 98.18)
Epoch: [19][10/43]	Time  0.154 ( 0.358)	Data  0.001 ( 0.174)	Loss 1.8507e-01 (2.2416e-01)	Acc@1  93.75 ( 91.48)	Acc@5  98.44 ( 98.72)
Epoch: [19][15/43]	Time  0.143 ( 0.314)	Data  0.000 ( 0.136)	Loss 2.6113e-01 (2.2792e-01)	Acc@1  85.94 ( 91.60)	Acc@5  98.44 ( 98.63)
Epoch: [19][20/43]	Time  0.172 ( 0.298)	Data  0.000 ( 0.120)	Loss 2.5970e-01 (2.2606e-01)	Acc@1  92.19 ( 91.67)	Acc@5  96.88 ( 98.66)
Epoch: [19][25/43]	Time  0.209 ( 0.289)	Data  0.053 ( 0.113)	Loss 1.2156e-01 (2.1609e-01)	Acc@1  93.75 ( 91.83)	Acc@5 100.00 ( 98.74)
Epoch: [19][30/43]	Time  0.407 ( 0.288)	Data  0.233 ( 0.113)	Loss 2.7383e-01 (2.1835e-01)	Acc@1  87.50 ( 91.73)	Acc@5 100.00 ( 98.84)
Epoch: [19][35/43]	Time  0.148 ( 0.283)	Data  0.000 ( 0.111)	Loss 2.2462e-01 (2.1568e-01)	Acc@1  90.62 ( 91.75)	Acc@5  98.44 ( 98.87)
Epoch: [19][40/43]	Time  0.169 ( 0.285)	Data  0.000 ( 0.115)	Loss 1.7118e-01 (2.1839e-01)	Acc@1  92.19 ( 91.62)	Acc@5 100.00 ( 98.82)
Test: [ 0/16]	Time  1.527 ( 1.527)	Loss 1.7503e-01 (1.7503e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.422 ( 0.482)	Loss 1.5340e-01 (1.0862e-01)	Acc@1  93.75 ( 95.05)	Acc@5 100.00 ( 99.48)
Test: [10/16]	Time  0.058 ( 0.360)	Loss 3.1635e-01 (1.7695e-01)	Acc@1  85.94 ( 92.33)	Acc@5  96.88 ( 98.86)
Test: [15/16]	Time  0.046 ( 0.314)	Loss 2.8734e-02 (1.7823e-01)	Acc@1 100.00 ( 92.40)	Acc@5 100.00 ( 98.80)
 * Acc@1 92.400 Acc@5 98.800
learning rate is: 0.002901062411314615
Epoch: [20][ 0/43]	Time  1.543 ( 1.543)	Data  1.280 ( 1.280)	Loss 3.0620e-01 (3.0620e-01)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [20][ 5/43]	Time  0.398 ( 0.449)	Data  0.229 ( 0.274)	Loss 1.9821e-01 (2.3020e-01)	Acc@1  90.62 ( 91.15)	Acc@5 100.00 ( 98.96)
Epoch: [20][10/43]	Time  0.202 ( 0.376)	Data  0.000 ( 0.187)	Loss 2.6133e-01 (2.4150e-01)	Acc@1  92.19 ( 91.62)	Acc@5  96.88 ( 98.58)
Epoch: [20][15/43]	Time  0.158 ( 0.330)	Data  0.000 ( 0.144)	Loss 1.7000e-01 (2.2389e-01)	Acc@1  93.75 ( 92.48)	Acc@5 100.00 ( 98.63)
Epoch: [20][20/43]	Time  0.216 ( 0.319)	Data  0.000 ( 0.132)	Loss 1.6501e-01 (2.1682e-01)	Acc@1  93.75 ( 92.56)	Acc@5  98.44 ( 98.59)
Epoch: [20][25/43]	Time  0.488 ( 0.319)	Data  0.317 ( 0.134)	Loss 1.1897e-01 (2.0912e-01)	Acc@1  96.88 ( 92.67)	Acc@5 100.00 ( 98.80)
Epoch: [20][30/43]	Time  0.173 ( 0.308)	Data  0.000 ( 0.125)	Loss 3.2346e-01 (2.1302e-01)	Acc@1  81.25 ( 92.39)	Acc@5  98.44 ( 98.84)
Epoch: [20][35/43]	Time  0.146 ( 0.300)	Data  0.000 ( 0.121)	Loss 1.6584e-01 (2.1328e-01)	Acc@1  89.06 ( 92.27)	Acc@5 100.00 ( 98.70)
Epoch: [20][40/43]	Time  0.146 ( 0.296)	Data  0.000 ( 0.122)	Loss 1.4053e-01 (2.1105e-01)	Acc@1  96.88 ( 92.38)	Acc@5 100.00 ( 98.82)
learning rate is: 0.0027269986666357375
Epoch: [21][ 0/43]	Time  1.719 ( 1.719)	Data  1.336 ( 1.336)	Loss 2.7973e-01 (2.7973e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [21][ 5/43]	Time  0.159 ( 0.507)	Data  0.000 ( 0.303)	Loss 2.6052e-01 (2.8431e-01)	Acc@1  90.62 ( 86.46)	Acc@5  98.44 ( 98.44)
Epoch: [21][10/43]	Time  0.160 ( 0.410)	Data  0.000 ( 0.227)	Loss 1.3468e-01 (2.4139e-01)	Acc@1  93.75 ( 89.63)	Acc@5 100.00 ( 98.44)
Epoch: [21][15/43]	Time  0.168 ( 0.346)	Data  0.000 ( 0.161)	Loss 2.0241e-01 (2.2753e-01)	Acc@1  93.75 ( 90.43)	Acc@5  98.44 ( 98.63)
Epoch: [21][20/43]	Time  0.329 ( 0.319)	Data  0.123 ( 0.139)	Loss 1.9546e-01 (2.3108e-01)	Acc@1  95.31 ( 90.70)	Acc@5  98.44 ( 98.44)
Epoch: [21][25/43]	Time  0.347 ( 0.311)	Data  0.203 ( 0.129)	Loss 2.5475e-01 (2.2565e-01)	Acc@1  90.62 ( 90.75)	Acc@5  98.44 ( 98.62)
Epoch: [21][30/43]	Time  0.154 ( 0.304)	Data  0.000 ( 0.123)	Loss 1.2815e-01 (2.2023e-01)	Acc@1  93.75 ( 90.52)	Acc@5 100.00 ( 98.64)
Epoch: [21][35/43]	Time  0.145 ( 0.300)	Data  0.000 ( 0.121)	Loss 1.6253e-01 (2.1366e-01)	Acc@1  92.19 ( 90.76)	Acc@5 100.00 ( 98.78)
Epoch: [21][40/43]	Time  0.136 ( 0.292)	Data  0.000 ( 0.116)	Loss 2.7253e-01 (2.0926e-01)	Acc@1  90.62 ( 91.12)	Acc@5  98.44 ( 98.78)
learning rate is: 0.0025633787466375936
Epoch: [22][ 0/43]	Time  1.286 ( 1.286)	Data  1.084 ( 1.084)	Loss 1.0399e-01 (1.0399e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [22][ 5/43]	Time  0.199 ( 0.426)	Data  0.000 ( 0.242)	Loss 3.1559e-01 (2.1693e-01)	Acc@1  85.94 ( 90.89)	Acc@5  96.88 ( 98.70)
Epoch: [22][10/43]	Time  0.132 ( 0.343)	Data  0.000 ( 0.163)	Loss 1.5902e-01 (1.9583e-01)	Acc@1  95.31 ( 91.34)	Acc@5  98.44 ( 98.86)
Epoch: [22][15/43]	Time  0.204 ( 0.317)	Data  0.000 ( 0.140)	Loss 1.4285e-01 (1.9074e-01)	Acc@1  95.31 ( 91.99)	Acc@5  98.44 ( 98.83)
Epoch: [22][20/43]	Time  0.618 ( 0.327)	Data  0.440 ( 0.155)	Loss 1.8037e-01 (1.9032e-01)	Acc@1  90.62 ( 92.34)	Acc@5  98.44 ( 98.81)
Epoch: [22][25/43]	Time  0.181 ( 0.315)	Data  0.000 ( 0.143)	Loss 3.5976e-01 (1.9917e-01)	Acc@1  90.62 ( 92.25)	Acc@5  96.88 ( 98.74)
Epoch: [22][30/43]	Time  0.199 ( 0.304)	Data  0.000 ( 0.129)	Loss 1.4768e-01 (1.9407e-01)	Acc@1  96.88 ( 92.79)	Acc@5 100.00 ( 98.94)
Epoch: [22][35/43]	Time  0.148 ( 0.291)	Data  0.000 ( 0.116)	Loss 1.8071e-01 (1.9749e-01)	Acc@1  85.94 ( 92.62)	Acc@5 100.00 ( 98.87)
Epoch: [22][40/43]	Time  0.492 ( 0.286)	Data  0.327 ( 0.111)	Loss 1.2906e-01 (1.9683e-01)	Acc@1  96.88 ( 92.72)	Acc@5 100.00 ( 98.86)
learning rate is: 0.0024095760218393377
Epoch: [23][ 0/43]	Time  1.420 ( 1.420)	Data  1.167 ( 1.167)	Loss 2.9685e-01 (2.9685e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [23][ 5/43]	Time  0.356 ( 0.460)	Data  0.185 ( 0.273)	Loss 2.0196e-01 (2.1366e-01)	Acc@1  90.62 ( 90.89)	Acc@5  98.44 ( 98.96)
Epoch: [23][10/43]	Time  0.155 ( 0.360)	Data  0.000 ( 0.185)	Loss 2.2694e-01 (1.9471e-01)	Acc@1  90.62 ( 92.47)	Acc@5 100.00 ( 99.15)
Epoch: [23][15/43]	Time  0.170 ( 0.316)	Data  0.000 ( 0.138)	Loss 1.9336e-01 (1.9650e-01)	Acc@1  90.62 ( 92.29)	Acc@5 100.00 ( 99.02)
Epoch: [23][20/43]	Time  0.308 ( 0.312)	Data  0.000 ( 0.122)	Loss 2.1949e-01 (1.9400e-01)	Acc@1  87.50 ( 92.11)	Acc@5 100.00 ( 99.18)
Epoch: [23][25/43]	Time  0.285 ( 0.291)	Data  0.092 ( 0.102)	Loss 1.0800e-01 (1.8946e-01)	Acc@1  95.31 ( 92.13)	Acc@5 100.00 ( 99.28)
Epoch: [23][30/43]	Time  0.134 ( 0.277)	Data  0.000 ( 0.092)	Loss 2.1523e-01 (1.8802e-01)	Acc@1  92.19 ( 92.34)	Acc@5  98.44 ( 99.24)
Epoch: [23][35/43]	Time  0.219 ( 0.276)	Data  0.000 ( 0.093)	Loss 2.3665e-01 (1.9149e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 ( 99.18)
Epoch: [23][40/43]	Time  0.482 ( 0.277)	Data  0.349 ( 0.098)	Loss 1.4980e-01 (1.9168e-01)	Acc@1  95.31 ( 92.07)	Acc@5  98.44 ( 99.16)
learning rate is: 0.0022650014605289774
Epoch: [24][ 0/43]	Time  1.570 ( 1.570)	Data  1.353 ( 1.353)	Loss 1.8597e-01 (1.8597e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [24][ 5/43]	Time  0.206 ( 0.423)	Data  0.001 ( 0.235)	Loss 1.5875e-01 (2.1506e-01)	Acc@1  95.31 ( 91.15)	Acc@5 100.00 ( 98.44)
Epoch: [24][10/43]	Time  0.153 ( 0.344)	Data  0.000 ( 0.163)	Loss 1.0918e-01 (1.9007e-01)	Acc@1  96.88 ( 92.61)	Acc@5 100.00 ( 99.01)
Epoch: [24][15/43]	Time  0.380 ( 0.333)	Data  0.180 ( 0.148)	Loss 1.7576e-01 (1.8591e-01)	Acc@1  92.19 ( 92.77)	Acc@5 100.00 ( 99.02)
Epoch: [24][20/43]	Time  0.132 ( 0.316)	Data  0.000 ( 0.130)	Loss 2.4859e-01 (1.9368e-01)	Acc@1  93.75 ( 92.19)	Acc@5  98.44 ( 99.03)
Epoch: [24][25/43]	Time  0.633 ( 0.323)	Data  0.446 ( 0.141)	Loss 2.1259e-01 (1.9429e-01)	Acc@1  93.75 ( 92.31)	Acc@5 100.00 ( 98.92)
Epoch: [24][30/43]	Time  0.191 ( 0.314)	Data  0.000 ( 0.134)	Loss 1.9062e-01 (2.0321e-01)	Acc@1  92.19 ( 91.89)	Acc@5  98.44 ( 98.79)
Epoch: [24][35/43]	Time  0.151 ( 0.302)	Data  0.000 ( 0.122)	Loss 2.5584e-01 (1.9860e-01)	Acc@1  92.19 ( 92.14)	Acc@5 100.00 ( 98.91)
Epoch: [24][40/43]	Time  0.131 ( 0.293)	Data  0.000 ( 0.118)	Loss 1.7284e-01 (2.0063e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 98.89)
Test: [ 0/16]	Time  1.597 ( 1.597)	Loss 1.7222e-01 (1.7222e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.453 ( 0.488)	Loss 1.3544e-01 (9.8687e-02)	Acc@1  93.75 ( 95.31)	Acc@5 100.00 ( 99.48)
Test: [10/16]	Time  0.088 ( 0.375)	Loss 2.9250e-01 (1.6518e-01)	Acc@1  85.94 ( 92.47)	Acc@5  96.88 ( 98.72)
Test: [15/16]	Time  0.054 ( 0.318)	Loss 2.3043e-02 (1.6743e-01)	Acc@1 100.00 ( 92.80)	Acc@5 100.00 ( 98.70)
 * Acc@1 92.800 Acc@5 98.700
learning rate is: 0.0021291013728972387
Epoch: [25][ 0/43]	Time  1.450 ( 1.450)	Data  1.249 ( 1.249)	Loss 9.0887e-02 (9.0887e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [25][ 5/43]	Time  0.177 ( 0.427)	Data  0.008 ( 0.261)	Loss 3.3072e-01 (2.0921e-01)	Acc@1  87.50 ( 92.45)	Acc@5  98.44 ( 98.18)
Epoch: [25][10/43]	Time  0.177 ( 0.361)	Data  0.000 ( 0.196)	Loss 1.6834e-01 (1.7783e-01)	Acc@1  95.31 ( 93.47)	Acc@5 100.00 ( 98.86)
Epoch: [25][15/43]	Time  0.187 ( 0.322)	Data  0.000 ( 0.143)	Loss 2.5608e-01 (1.8531e-01)	Acc@1  92.19 ( 93.07)	Acc@5  96.88 ( 98.63)
Epoch: [25][20/43]	Time  0.206 ( 0.292)	Data  0.055 ( 0.113)	Loss 1.7477e-01 (1.8288e-01)	Acc@1  93.75 ( 93.53)	Acc@5  98.44 ( 98.66)
Epoch: [25][25/43]	Time  0.161 ( 0.283)	Data  0.000 ( 0.106)	Loss 1.4606e-01 (1.7845e-01)	Acc@1  95.31 ( 93.57)	Acc@5  98.44 ( 98.74)
Epoch: [25][30/43]	Time  0.148 ( 0.282)	Data  0.000 ( 0.107)	Loss 1.5126e-01 (1.8423e-01)	Acc@1  95.31 ( 93.40)	Acc@5  98.44 ( 98.69)
Epoch: [25][35/43]	Time  0.186 ( 0.279)	Data  0.000 ( 0.102)	Loss 1.2598e-01 (1.8092e-01)	Acc@1  92.19 ( 93.27)	Acc@5 100.00 ( 98.83)
Epoch: [25][40/43]	Time  0.492 ( 0.282)	Data  0.341 ( 0.108)	Loss 1.1734e-01 (1.7998e-01)	Acc@1  96.88 ( 93.33)	Acc@5 100.00 ( 98.86)
learning rate is: 0.002001355290523404
Epoch: [26][ 0/43]	Time  1.653 ( 1.653)	Data  1.407 ( 1.407)	Loss 2.6647e-01 (2.6647e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [26][ 5/43]	Time  0.198 ( 0.495)	Data  0.000 ( 0.308)	Loss 2.1749e-01 (2.2105e-01)	Acc@1  89.06 ( 91.93)	Acc@5  98.44 ( 98.18)
Epoch: [26][10/43]	Time  0.220 ( 0.385)	Data  0.001 ( 0.200)	Loss 9.2788e-02 (1.9759e-01)	Acc@1  95.31 ( 92.19)	Acc@5 100.00 ( 98.44)
Epoch: [26][15/43]	Time  0.165 ( 0.350)	Data  0.000 ( 0.159)	Loss 1.6581e-01 (1.8959e-01)	Acc@1  93.75 ( 92.48)	Acc@5 100.00 ( 98.73)
Epoch: [26][20/43]	Time  0.252 ( 0.323)	Data  0.056 ( 0.130)	Loss 2.5017e-01 (1.9835e-01)	Acc@1  89.06 ( 91.96)	Acc@5 100.00 ( 98.81)
Epoch: [26][25/43]	Time  0.223 ( 0.308)	Data  0.001 ( 0.115)	Loss 1.7912e-01 (1.9028e-01)	Acc@1  95.31 ( 92.55)	Acc@5  98.44 ( 98.80)
Epoch: [26][30/43]	Time  0.257 ( 0.303)	Data  0.000 ( 0.109)	Loss 1.3189e-01 (1.8245e-01)	Acc@1  96.88 ( 92.84)	Acc@5 100.00 ( 98.89)
Epoch: [26][35/43]	Time  0.255 ( 0.290)	Data  0.000 ( 0.094)	Loss 1.6088e-01 (1.7974e-01)	Acc@1  93.75 ( 92.93)	Acc@5  96.88 ( 98.83)
Epoch: [26][40/43]	Time  0.149 ( 0.276)	Data  0.000 ( 0.083)	Loss 1.6904e-01 (1.8321e-01)	Acc@1  93.75 ( 92.76)	Acc@5  98.44 ( 98.78)
learning rate is: 0.0018812739730919997
Epoch: [27][ 0/43]	Time  1.089 ( 1.089)	Data  0.860 ( 0.860)	Loss 2.7714e-01 (2.7714e-01)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [27][ 5/43]	Time  0.165 ( 0.389)	Data  0.000 ( 0.198)	Loss 1.1052e-01 (1.9865e-01)	Acc@1  92.19 ( 91.67)	Acc@5 100.00 ( 99.48)
Epoch: [27][10/43]	Time  0.149 ( 0.301)	Data  0.000 ( 0.108)	Loss 1.4888e-01 (1.7493e-01)	Acc@1  90.62 ( 92.19)	Acc@5 100.00 ( 99.43)
Epoch: [27][15/43]	Time  0.186 ( 0.272)	Data  0.000 ( 0.077)	Loss 1.6704e-01 (1.7382e-01)	Acc@1  95.31 ( 92.29)	Acc@5 100.00 ( 99.41)
Epoch: [27][20/43]	Time  0.192 ( 0.259)	Data  0.000 ( 0.060)	Loss 1.4770e-01 (1.7471e-01)	Acc@1  93.75 ( 92.41)	Acc@5 100.00 ( 99.33)
Epoch: [27][25/43]	Time  0.177 ( 0.246)	Data  0.000 ( 0.049)	Loss 1.7604e-01 (1.7964e-01)	Acc@1  85.94 ( 92.07)	Acc@5 100.00 ( 99.16)
Epoch: [27][30/43]	Time  0.209 ( 0.241)	Data  0.000 ( 0.041)	Loss 1.3289e-01 (1.7982e-01)	Acc@1  95.31 ( 92.14)	Acc@5  98.44 ( 99.14)
Epoch: [27][35/43]	Time  0.132 ( 0.235)	Data  0.000 ( 0.035)	Loss 2.0865e-01 (1.7568e-01)	Acc@1  92.19 ( 92.14)	Acc@5  96.88 ( 99.13)
Epoch: [27][40/43]	Time  0.202 ( 0.227)	Data  0.000 ( 0.031)	Loss 2.0983e-01 (1.7851e-01)	Acc@1  92.19 ( 92.15)	Acc@5  98.44 ( 99.16)
learning rate is: 0.00176839753470648
Epoch: [28][ 0/43]	Time  1.109 ( 1.109)	Data  0.825 ( 0.825)	Loss 1.3862e-01 (1.3862e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [28][ 5/43]	Time  0.142 ( 0.324)	Data  0.000 ( 0.138)	Loss 2.1529e-01 (1.5920e-01)	Acc@1  95.31 ( 94.53)	Acc@5  96.88 ( 98.70)
Epoch: [28][10/43]	Time  0.158 ( 0.259)	Data  0.000 ( 0.076)	Loss 8.8523e-02 (1.6943e-01)	Acc@1  98.44 ( 93.47)	Acc@5 100.00 ( 99.01)
Epoch: [28][15/43]	Time  0.160 ( 0.242)	Data  0.000 ( 0.052)	Loss 2.1314e-01 (1.8018e-01)	Acc@1  92.19 ( 93.46)	Acc@5 100.00 ( 98.93)
Epoch: [28][20/43]	Time  0.138 ( 0.229)	Data  0.000 ( 0.040)	Loss 1.6022e-01 (1.8568e-01)	Acc@1  93.75 ( 93.08)	Acc@5  98.44 ( 98.74)
Epoch: [28][25/43]	Time  0.204 ( 0.225)	Data  0.000 ( 0.032)	Loss 7.4955e-02 (1.8246e-01)	Acc@1  96.88 ( 93.27)	Acc@5 100.00 ( 98.86)
Epoch: [28][30/43]	Time  0.211 ( 0.222)	Data  0.000 ( 0.027)	Loss 7.9618e-02 (1.7326e-01)	Acc@1  95.31 ( 93.30)	Acc@5 100.00 ( 98.94)
Epoch: [28][35/43]	Time  0.160 ( 0.220)	Data  0.000 ( 0.023)	Loss 3.4243e-01 (1.7216e-01)	Acc@1  89.06 ( 93.32)	Acc@5  96.88 ( 99.00)
Epoch: [28][40/43]	Time  0.129 ( 0.215)	Data  0.000 ( 0.021)	Loss 1.5483e-01 (1.7381e-01)	Acc@1  90.62 ( 93.22)	Acc@5 100.00 ( 98.89)
learning rate is: 0.001662293682624091
Epoch: [29][ 0/43]	Time  1.057 ( 1.057)	Data  0.824 ( 0.824)	Loss 8.4252e-02 (8.4252e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [29][ 5/43]	Time  0.136 ( 0.331)	Data  0.000 ( 0.138)	Loss 2.2631e-01 (1.6864e-01)	Acc@1  90.62 ( 93.23)	Acc@5  96.88 ( 99.22)
Epoch: [29][10/43]	Time  0.154 ( 0.275)	Data  0.000 ( 0.075)	Loss 2.0918e-01 (1.6372e-01)	Acc@1  92.19 ( 93.32)	Acc@5 100.00 ( 99.29)
Epoch: [29][15/43]	Time  0.196 ( 0.249)	Data  0.000 ( 0.052)	Loss 1.9864e-01 (1.8415e-01)	Acc@1  93.75 ( 92.58)	Acc@5  98.44 ( 98.83)
Epoch: [29][20/43]	Time  0.170 ( 0.237)	Data  0.000 ( 0.040)	Loss 1.1359e-01 (1.7250e-01)	Acc@1  98.44 ( 93.23)	Acc@5 100.00 ( 98.96)
Epoch: [29][25/43]	Time  0.192 ( 0.232)	Data  0.000 ( 0.032)	Loss 1.5832e-01 (1.7896e-01)	Acc@1  92.19 ( 92.79)	Acc@5 100.00 ( 98.92)
Epoch: [29][30/43]	Time  0.211 ( 0.227)	Data  0.000 ( 0.027)	Loss 1.4692e-01 (1.7889e-01)	Acc@1  95.31 ( 92.94)	Acc@5 100.00 ( 98.94)
Epoch: [29][35/43]	Time  0.137 ( 0.221)	Data  0.000 ( 0.024)	Loss 9.3328e-02 (1.7978e-01)	Acc@1  95.31 ( 92.71)	Acc@5 100.00 ( 99.00)
Epoch: [29][40/43]	Time  0.173 ( 0.217)	Data  0.000 ( 0.021)	Loss 1.5232e-01 (1.7904e-01)	Acc@1  93.75 ( 92.68)	Acc@5 100.00 ( 99.05)
Test: [ 0/16]	Time  1.041 ( 1.041)	Loss 1.7543e-01 (1.7543e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.073 ( 0.283)	Loss 1.3598e-01 (9.4221e-02)	Acc@1  92.19 ( 96.09)	Acc@5 100.00 ( 99.48)
Test: [10/16]	Time  0.134 ( 0.246)	Loss 3.0085e-01 (1.6396e-01)	Acc@1  84.38 ( 92.47)	Acc@5  96.88 ( 98.72)
Test: [15/16]	Time  0.048 ( 0.220)	Loss 2.0244e-02 (1.6694e-01)	Acc@1 100.00 ( 92.70)	Acc@5 100.00 ( 98.70)
 * Acc@1 92.700 Acc@5 98.700
learning rate is: 0.0015625560616666454
Epoch: [30][ 0/43]	Time  1.134 ( 1.134)	Data  0.880 ( 0.880)	Loss 1.3007e-01 (1.3007e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [30][ 5/43]	Time  0.138 ( 0.339)	Data  0.000 ( 0.147)	Loss 2.6562e-01 (1.5865e-01)	Acc@1  90.62 ( 92.97)	Acc@5  96.88 ( 99.48)
Epoch: [30][10/43]	Time  0.237 ( 0.273)	Data  0.000 ( 0.081)	Loss 1.8375e-01 (1.6125e-01)	Acc@1  90.62 ( 93.89)	Acc@5  98.44 ( 99.01)
Epoch: [30][15/43]	Time  0.256 ( 0.251)	Data  0.000 ( 0.056)	Loss 2.6888e-01 (1.8903e-01)	Acc@1  89.06 ( 93.26)	Acc@5  98.44 ( 98.63)
Epoch: [30][20/43]	Time  0.277 ( 0.241)	Data  0.000 ( 0.042)	Loss 1.1648e-01 (1.8430e-01)	Acc@1  96.88 ( 93.68)	Acc@5 100.00 ( 98.66)
Epoch: [30][25/43]	Time  0.256 ( 0.231)	Data  0.001 ( 0.035)	Loss 1.3119e-01 (1.8713e-01)	Acc@1  96.88 ( 93.39)	Acc@5  98.44 ( 98.62)
Epoch: [30][30/43]	Time  0.166 ( 0.222)	Data  0.000 ( 0.029)	Loss 1.0529e-01 (1.8322e-01)	Acc@1  95.31 ( 93.25)	Acc@5 100.00 ( 98.69)
Epoch: [30][35/43]	Time  0.134 ( 0.223)	Data  0.000 ( 0.025)	Loss 1.4560e-01 (1.8258e-01)	Acc@1  95.31 ( 93.27)	Acc@5  96.88 ( 98.61)
Epoch: [30][40/43]	Time  0.245 ( 0.220)	Data  0.000 ( 0.022)	Loss 2.5834e-01 (1.8211e-01)	Acc@1  90.62 ( 93.33)	Acc@5  98.44 ( 98.67)
learning rate is: 0.0014688026979666467
Epoch: [31][ 0/43]	Time  1.103 ( 1.103)	Data  0.884 ( 0.884)	Loss 1.3973e-01 (1.3973e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [31][ 5/43]	Time  0.187 ( 0.349)	Data  0.000 ( 0.148)	Loss 1.2639e-01 (1.6889e-01)	Acc@1  95.31 ( 93.75)	Acc@5 100.00 ( 99.22)
Epoch: [31][10/43]	Time  0.250 ( 0.277)	Data  0.000 ( 0.081)	Loss 1.9408e-01 (1.6526e-01)	Acc@1  89.06 ( 93.32)	Acc@5 100.00 ( 99.43)
Epoch: [31][15/43]	Time  0.249 ( 0.252)	Data  0.000 ( 0.056)	Loss 5.7202e-02 (1.5001e-01)	Acc@1 100.00 ( 94.04)	Acc@5 100.00 ( 99.41)
Epoch: [31][20/43]	Time  0.155 ( 0.234)	Data  0.000 ( 0.043)	Loss 2.7059e-01 (1.5615e-01)	Acc@1  90.62 ( 94.27)	Acc@5  98.44 ( 99.40)
Epoch: [31][25/43]	Time  0.296 ( 0.234)	Data  0.000 ( 0.035)	Loss 2.4128e-01 (1.5307e-01)	Acc@1  92.19 ( 94.47)	Acc@5  98.44 ( 99.46)
Epoch: [31][30/43]	Time  0.194 ( 0.234)	Data  0.000 ( 0.029)	Loss 2.5704e-01 (1.5632e-01)	Acc@1  87.50 ( 94.05)	Acc@5  98.44 ( 99.40)
Epoch: [31][35/43]	Time  0.229 ( 0.230)	Data  0.000 ( 0.025)	Loss 1.2486e-01 (1.5690e-01)	Acc@1  95.31 ( 94.05)	Acc@5 100.00 ( 99.44)
Epoch: [31][40/43]	Time  0.202 ( 0.224)	Data  0.000 ( 0.022)	Loss 2.4371e-01 (1.5400e-01)	Acc@1  95.31 ( 94.25)	Acc@5  96.88 ( 99.39)
############################################################################################




Epoch: [0][ 0/43]	Time  9.010 ( 9.010)	Data  0.718 ( 0.718)	Loss 1.8249e+01 (1.8249e+01)	Acc@1   1.56 (  1.56)	Acc@5  12.50 ( 12.50)
Epoch: [0][ 5/43]	Time  0.209 ( 1.661)	Data  0.000 ( 0.120)	Loss 1.6532e+01 (1.7618e+01)	Acc@1  15.62 (  7.81)	Acc@5  45.31 ( 24.74)
Epoch: [0][10/43]	Time  0.138 ( 1.001)	Data  0.000 ( 0.066)	Loss 1.3734e+01 (1.6443e+01)	Acc@1  32.81 ( 15.62)	Acc@5  59.38 ( 38.35)
Epoch: [0][15/43]	Time  0.188 ( 0.749)	Data  0.000 ( 0.045)	Loss 1.1128e+01 (1.5034e+01)	Acc@1  42.19 ( 23.54)	Acc@5  71.88 ( 48.73)
Epoch: [0][20/43]	Time  0.222 ( 0.620)	Data  0.000 ( 0.035)	Loss 8.6107e+00 (1.3419e+01)	Acc@1  56.25 ( 31.10)	Acc@5  81.25 ( 56.77)
Epoch: [0][25/43]	Time  0.233 ( 0.541)	Data  0.000 ( 0.028)	Loss 6.0068e+00 (1.2080e+01)	Acc@1  59.38 ( 36.66)	Acc@5  82.81 ( 62.62)
Epoch: [0][30/43]	Time  0.189 ( 0.485)	Data  0.000 ( 0.024)	Loss 4.4412e+00 (1.0961e+01)	Acc@1  68.75 ( 40.98)	Acc@5  89.06 ( 66.89)
Epoch: [0][35/43]	Time  0.190 ( 0.446)	Data  0.000 ( 0.021)	Loss 3.2012e+00 (9.9354e+00)	Acc@1  79.69 ( 45.44)	Acc@5  96.88 ( 70.70)
Epoch: [0][40/43]	Time  0.218 ( 0.413)	Data  0.000 ( 0.018)	Loss 2.4625e+00 (9.1005e+00)	Acc@1  75.00 ( 48.89)	Acc@5  96.88 ( 73.67)
learning rate is: 0.0094
Epoch: [1][ 0/43]	Time  1.049 ( 1.049)	Data  0.790 ( 0.790)	Loss 2.0991e+00 (2.0991e+00)	Acc@1  82.81 ( 82.81)	Acc@5  96.88 ( 96.88)
Epoch: [1][ 5/43]	Time  0.152 ( 0.342)	Data  0.000 ( 0.132)	Loss 1.9707e+00 (2.0838e+00)	Acc@1  84.38 ( 80.73)	Acc@5  98.44 ( 98.18)
Epoch: [1][10/43]	Time  0.170 ( 0.273)	Data  0.000 ( 0.072)	Loss 2.0494e+00 (2.0195e+00)	Acc@1  73.44 ( 80.26)	Acc@5 100.00 ( 98.01)
Epoch: [1][15/43]	Time  0.229 ( 0.254)	Data  0.000 ( 0.050)	Loss 2.0519e+00 (2.0786e+00)	Acc@1  82.81 ( 80.66)	Acc@5  93.75 ( 96.78)
Epoch: [1][20/43]	Time  0.171 ( 0.253)	Data  0.000 ( 0.038)	Loss 1.7800e+00 (2.0628e+00)	Acc@1  82.81 ( 81.18)	Acc@5  98.44 ( 96.88)
Epoch: [1][25/43]	Time  0.215 ( 0.244)	Data  0.000 ( 0.031)	Loss 1.7196e+00 (2.0242e+00)	Acc@1  79.69 ( 81.55)	Acc@5  98.44 ( 97.00)
Epoch: [1][30/43]	Time  0.202 ( 0.237)	Data  0.000 ( 0.026)	Loss 2.4229e+00 (1.9860e+00)	Acc@1  82.81 ( 82.16)	Acc@5  95.31 ( 97.08)
Epoch: [1][35/43]	Time  0.189 ( 0.233)	Data  0.000 ( 0.022)	Loss 1.8813e+00 (1.9430e+00)	Acc@1  85.94 ( 82.47)	Acc@5  96.88 ( 97.18)
Epoch: [1][40/43]	Time  0.132 ( 0.224)	Data  0.000 ( 0.020)	Loss 2.2170e+00 (1.9266e+00)	Acc@1  82.81 ( 82.62)	Acc@5  93.75 ( 97.14)
learning rate is: 0.008836
Epoch: [2][ 0/43]	Time  1.017 ( 1.017)	Data  0.803 ( 0.803)	Loss 1.0136e+00 (1.0136e+00)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [2][ 5/43]	Time  0.183 ( 0.328)	Data  0.000 ( 0.145)	Loss 1.2796e+00 (1.3203e+00)	Acc@1  82.81 ( 86.98)	Acc@5  96.88 ( 97.92)
Epoch: [2][10/43]	Time  0.185 ( 0.270)	Data  0.000 ( 0.079)	Loss 2.1962e+00 (1.3077e+00)	Acc@1  78.12 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [2][15/43]	Time  0.240 ( 0.250)	Data  0.000 ( 0.055)	Loss 1.4508e+00 (1.3454e+00)	Acc@1  90.62 ( 87.40)	Acc@5  96.88 ( 98.14)
Epoch: [2][20/43]	Time  0.180 ( 0.237)	Data  0.000 ( 0.042)	Loss 1.2465e+00 (1.3502e+00)	Acc@1  89.06 ( 86.90)	Acc@5  98.44 ( 98.36)
Epoch: [2][25/43]	Time  0.201 ( 0.230)	Data  0.000 ( 0.034)	Loss 1.7663e+00 (1.3910e+00)	Acc@1  82.81 ( 86.48)	Acc@5  95.31 ( 98.08)
Epoch: [2][30/43]	Time  0.162 ( 0.222)	Data  0.000 ( 0.029)	Loss 1.9601e+00 (1.4245e+00)	Acc@1  75.00 ( 85.84)	Acc@5  95.31 ( 97.83)
Epoch: [2][35/43]	Time  0.255 ( 0.217)	Data  0.000 ( 0.025)	Loss 1.5426e+00 (1.3934e+00)	Acc@1  85.94 ( 86.15)	Acc@5  96.88 ( 97.92)
Epoch: [2][40/43]	Time  0.132 ( 0.210)	Data  0.000 ( 0.022)	Loss 1.5940e+00 (1.3930e+00)	Acc@1  84.38 ( 86.28)	Acc@5  96.88 ( 97.94)
learning rate is: 0.008305839999999998
Epoch: [3][ 0/43]	Time  1.026 ( 1.026)	Data  0.775 ( 0.775)	Loss 7.1030e-01 (7.1030e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [3][ 5/43]	Time  0.186 ( 0.349)	Data  0.000 ( 0.130)	Loss 9.2832e-01 (9.8189e-01)	Acc@1  93.75 ( 90.89)	Acc@5  98.44 ( 98.44)
Epoch: [3][10/43]	Time  0.203 ( 0.291)	Data  0.000 ( 0.071)	Loss 1.4200e+00 (9.7564e-01)	Acc@1  87.50 ( 90.48)	Acc@5  96.88 ( 98.44)
Epoch: [3][15/43]	Time  0.178 ( 0.263)	Data  0.000 ( 0.049)	Loss 9.8359e-01 (9.5548e-01)	Acc@1  93.75 ( 90.72)	Acc@5  98.44 ( 98.54)
Epoch: [3][20/43]	Time  0.183 ( 0.247)	Data  0.000 ( 0.038)	Loss 1.2867e+00 (9.9920e-01)	Acc@1  90.62 ( 90.55)	Acc@5  96.88 ( 98.36)
Epoch: [3][25/43]	Time  0.166 ( 0.239)	Data  0.000 ( 0.030)	Loss 9.7578e-01 (1.0075e+00)	Acc@1  87.50 ( 90.50)	Acc@5  98.44 ( 98.38)
Epoch: [3][30/43]	Time  0.178 ( 0.233)	Data  0.000 ( 0.026)	Loss 8.6695e-01 (1.0535e+00)	Acc@1  89.06 ( 90.12)	Acc@5 100.00 ( 98.34)
Epoch: [3][35/43]	Time  0.181 ( 0.229)	Data  0.000 ( 0.022)	Loss 8.6995e-01 (1.0746e+00)	Acc@1  90.62 ( 89.97)	Acc@5  96.88 ( 98.26)
Epoch: [3][40/43]	Time  0.132 ( 0.224)	Data  0.000 ( 0.019)	Loss 4.9337e-01 (1.0952e+00)	Acc@1  93.75 ( 89.71)	Acc@5 100.00 ( 98.32)
learning rate is: 0.007807489599999998
Epoch: [4][ 0/43]	Time  1.163 ( 1.163)	Data  0.891 ( 0.891)	Loss 6.1056e-01 (6.1056e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [4][ 5/43]	Time  0.142 ( 0.348)	Data  0.000 ( 0.149)	Loss 4.0230e-01 (8.1498e-01)	Acc@1  95.31 ( 91.93)	Acc@5 100.00 ( 98.96)
Epoch: [4][10/43]	Time  0.216 ( 0.281)	Data  0.000 ( 0.082)	Loss 1.0270e+00 (8.1938e-01)	Acc@1  93.75 ( 92.61)	Acc@5  98.44 ( 98.86)
Epoch: [4][15/43]	Time  0.183 ( 0.256)	Data  0.000 ( 0.056)	Loss 7.7508e-01 (9.5820e-01)	Acc@1  92.19 ( 91.11)	Acc@5 100.00 ( 98.63)
Epoch: [4][20/43]	Time  0.231 ( 0.248)	Data  0.000 ( 0.043)	Loss 1.1601e+00 (9.4268e-01)	Acc@1  89.06 ( 91.15)	Acc@5  98.44 ( 98.81)
Epoch: [4][25/43]	Time  0.210 ( 0.240)	Data  0.000 ( 0.035)	Loss 5.2570e-01 (9.2695e-01)	Acc@1  95.31 ( 91.29)	Acc@5 100.00 ( 98.92)
Epoch: [4][30/43]	Time  0.176 ( 0.236)	Data  0.000 ( 0.029)	Loss 4.5091e-01 (8.7346e-01)	Acc@1  95.31 ( 91.73)	Acc@5 100.00 ( 99.09)
Epoch: [4][35/43]	Time  0.192 ( 0.232)	Data  0.000 ( 0.025)	Loss 5.5249e-01 (8.8989e-01)	Acc@1  93.75 ( 91.41)	Acc@5 100.00 ( 99.13)
Epoch: [4][40/43]	Time  0.134 ( 0.226)	Data  0.000 ( 0.022)	Loss 1.3587e+00 (8.8799e-01)	Acc@1  92.19 ( 91.46)	Acc@5  96.88 ( 99.05)
Test: [ 0/16]	Time  1.068 ( 1.068)	Loss 4.8935e-01 (4.8935e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Test: [ 5/16]	Time  0.346 ( 0.345)	Loss 7.7084e-01 (4.1872e-01)	Acc@1  90.62 ( 95.05)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.069 ( 0.267)	Loss 1.9432e+00 (8.0957e-01)	Acc@1  78.12 ( 91.90)	Acc@5  96.88 ( 99.29)
Test: [15/16]	Time  0.440 ( 0.263)	Loss 6.7431e-02 (8.1096e-01)	Acc@1 100.00 ( 91.60)	Acc@5 100.00 ( 99.30)
 * Acc@1 91.600 Acc@5 99.300
learning rate is: 0.007339040223999997
Epoch: [5][ 0/43]	Time  1.090 ( 1.090)	Data  0.777 ( 0.777)	Loss 6.5627e-01 (6.5627e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [5][ 5/43]	Time  0.154 ( 0.350)	Data  0.000 ( 0.130)	Loss 8.3065e-01 (9.4106e-01)	Acc@1  93.75 ( 91.67)	Acc@5  98.44 ( 98.18)
Epoch: [5][10/43]	Time  0.190 ( 0.283)	Data  0.000 ( 0.071)	Loss 7.1777e-01 (9.7760e-01)	Acc@1  89.06 ( 91.19)	Acc@5 100.00 ( 98.58)
Epoch: [5][15/43]	Time  0.162 ( 0.257)	Data  0.000 ( 0.049)	Loss 1.2909e+00 (9.5169e-01)	Acc@1  90.62 ( 91.60)	Acc@5  95.31 ( 98.44)
Epoch: [5][20/43]	Time  0.155 ( 0.243)	Data  0.000 ( 0.037)	Loss 2.1819e+00 (1.0149e+00)	Acc@1  79.69 ( 91.22)	Acc@5  93.75 ( 98.21)
Epoch: [5][25/43]	Time  0.194 ( 0.235)	Data  0.000 ( 0.030)	Loss 4.5041e-01 (9.8520e-01)	Acc@1  92.19 ( 91.59)	Acc@5 100.00 ( 98.26)
Epoch: [5][30/43]	Time  0.167 ( 0.230)	Data  0.000 ( 0.026)	Loss 1.0612e+00 (9.8152e-01)	Acc@1  92.19 ( 91.43)	Acc@5  98.44 ( 98.29)
Epoch: [5][35/43]	Time  0.214 ( 0.224)	Data  0.000 ( 0.022)	Loss 6.4981e-01 (9.6785e-01)	Acc@1  95.31 ( 91.62)	Acc@5  98.44 ( 98.26)
Epoch: [5][40/43]	Time  0.149 ( 0.219)	Data  0.000 ( 0.019)	Loss 3.9435e-01 (9.1431e-01)	Acc@1  95.31 ( 91.92)	Acc@5 100.00 ( 98.44)
learning rate is: 0.006898697810559997
Epoch: [6][ 0/43]	Time  1.108 ( 1.108)	Data  0.823 ( 0.823)	Loss 8.6993e-01 (8.6993e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [6][ 5/43]	Time  0.136 ( 0.322)	Data  0.000 ( 0.138)	Loss 3.0740e-01 (6.9127e-01)	Acc@1  98.44 ( 94.01)	Acc@5 100.00 ( 98.96)
Epoch: [6][10/43]	Time  0.180 ( 0.264)	Data  0.000 ( 0.075)	Loss 8.4816e-01 (7.1666e-01)	Acc@1  95.31 ( 94.03)	Acc@5  96.88 ( 98.86)
Epoch: [6][15/43]	Time  0.202 ( 0.249)	Data  0.000 ( 0.052)	Loss 6.0287e-01 (6.7695e-01)	Acc@1  90.62 ( 94.04)	Acc@5 100.00 ( 99.12)
Epoch: [6][20/43]	Time  0.147 ( 0.236)	Data  0.000 ( 0.040)	Loss 1.0064e+00 (7.2058e-01)	Acc@1  89.06 ( 93.30)	Acc@5 100.00 ( 99.33)
Epoch: [6][25/43]	Time  0.150 ( 0.231)	Data  0.000 ( 0.032)	Loss 5.4620e-01 (7.2800e-01)	Acc@1  96.88 ( 93.57)	Acc@5  98.44 ( 99.10)
Epoch: [6][30/43]	Time  0.255 ( 0.232)	Data  0.000 ( 0.027)	Loss 4.3791e-01 (7.0504e-01)	Acc@1  92.19 ( 93.50)	Acc@5 100.00 ( 99.19)
Epoch: [6][35/43]	Time  0.184 ( 0.225)	Data  0.000 ( 0.023)	Loss 4.2273e-01 (7.0349e-01)	Acc@1  93.75 ( 93.45)	Acc@5 100.00 ( 99.26)
Epoch: [6][40/43]	Time  0.135 ( 0.219)	Data  0.000 ( 0.021)	Loss 9.3942e-01 (7.5097e-01)	Acc@1  95.31 ( 93.29)	Acc@5  98.44 ( 99.01)
learning rate is: 0.006484775941926397
Epoch: [7][ 0/43]	Time  1.052 ( 1.052)	Data  0.797 ( 0.797)	Loss 8.0134e-01 (8.0134e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [7][ 5/43]	Time  0.199 ( 0.344)	Data  0.000 ( 0.133)	Loss 9.6648e-01 (6.9294e-01)	Acc@1  90.62 ( 93.75)	Acc@5  98.44 ( 99.22)
Epoch: [7][10/43]	Time  0.285 ( 0.276)	Data  0.000 ( 0.073)	Loss 7.6403e-01 (6.6330e-01)	Acc@1  90.62 ( 93.75)	Acc@5  98.44 ( 99.29)
Epoch: [7][15/43]	Time  0.214 ( 0.261)	Data  0.000 ( 0.051)	Loss 6.3499e-01 (6.5183e-01)	Acc@1  95.31 ( 93.55)	Acc@5  98.44 ( 99.32)
Epoch: [7][20/43]	Time  0.246 ( 0.248)	Data  0.001 ( 0.039)	Loss 5.9514e-01 (6.2286e-01)	Acc@1  95.31 ( 93.90)	Acc@5 100.00 ( 99.40)
Epoch: [7][25/43]	Time  0.178 ( 0.242)	Data  0.000 ( 0.031)	Loss 7.1145e-01 (6.2100e-01)	Acc@1  93.75 ( 93.99)	Acc@5  98.44 ( 99.40)
Epoch: [7][30/43]	Time  0.161 ( 0.236)	Data  0.000 ( 0.026)	Loss 6.9766e-01 (6.4607e-01)	Acc@1  96.88 ( 93.95)	Acc@5  98.44 ( 99.34)
Epoch: [7][35/43]	Time  0.185 ( 0.233)	Data  0.000 ( 0.023)	Loss 5.6133e-01 (6.5753e-01)	Acc@1  93.75 ( 93.97)	Acc@5 100.00 ( 99.26)
Epoch: [7][40/43]	Time  0.135 ( 0.227)	Data  0.000 ( 0.020)	Loss 5.3616e-01 (6.4059e-01)	Acc@1  92.19 ( 94.09)	Acc@5 100.00 ( 99.28)
learning rate is: 0.006095689385410813
Epoch: [8][ 0/43]	Time  1.075 ( 1.075)	Data  0.786 ( 0.786)	Loss 7.2684e-01 (7.2684e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [8][ 5/43]	Time  0.187 ( 0.344)	Data  0.000 ( 0.131)	Loss 9.2758e-01 (6.8022e-01)	Acc@1  92.19 ( 94.01)	Acc@5  95.31 ( 98.18)
Epoch: [8][10/43]	Time  0.278 ( 0.276)	Data  0.000 ( 0.072)	Loss 9.2697e-01 (7.2928e-01)	Acc@1  87.50 ( 93.18)	Acc@5  98.44 ( 98.58)
Epoch: [8][15/43]	Time  0.201 ( 0.257)	Data  0.000 ( 0.050)	Loss 5.5128e-01 (7.0112e-01)	Acc@1  96.88 ( 93.46)	Acc@5 100.00 ( 98.63)
Epoch: [8][20/43]	Time  0.206 ( 0.243)	Data  0.000 ( 0.038)	Loss 9.4649e-01 (6.7482e-01)	Acc@1  89.06 ( 93.45)	Acc@5 100.00 ( 98.96)
Epoch: [8][25/43]	Time  0.180 ( 0.239)	Data  0.000 ( 0.031)	Loss 1.0496e-01 (6.3659e-01)	Acc@1 100.00 ( 93.93)	Acc@5 100.00 ( 98.98)
Epoch: [8][30/43]	Time  0.176 ( 0.225)	Data  0.000 ( 0.026)	Loss 3.3623e-01 (6.3848e-01)	Acc@1  96.88 ( 94.00)	Acc@5 100.00 ( 98.99)
Epoch: [8][35/43]	Time  0.138 ( 0.219)	Data  0.000 ( 0.023)	Loss 6.3537e-01 (6.1569e-01)	Acc@1  92.19 ( 94.23)	Acc@5 100.00 ( 99.09)
Epoch: [8][40/43]	Time  0.126 ( 0.211)	Data  0.000 ( 0.020)	Loss 1.0199e+00 (6.4059e-01)	Acc@1  89.06 ( 94.02)	Acc@5  96.88 ( 98.97)
learning rate is: 0.0057299480222861646
Epoch: [9][ 0/43]	Time  1.081 ( 1.081)	Data  0.895 ( 0.895)	Loss 6.5955e-01 (6.5955e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [9][ 5/43]	Time  0.159 ( 0.319)	Data  0.000 ( 0.170)	Loss 9.9430e-01 (5.9788e-01)	Acc@1  90.62 ( 94.27)	Acc@5  96.88 ( 98.96)
Epoch: [9][10/43]	Time  0.169 ( 0.251)	Data  0.000 ( 0.094)	Loss 4.3876e-01 (5.6127e-01)	Acc@1  95.31 ( 94.46)	Acc@5 100.00 ( 99.29)
Epoch: [9][15/43]	Time  0.178 ( 0.226)	Data  0.000 ( 0.065)	Loss 6.4287e-01 (6.1130e-01)	Acc@1  95.31 ( 94.14)	Acc@5  98.44 ( 99.41)
Epoch: [9][20/43]	Time  0.262 ( 0.216)	Data  0.085 ( 0.054)	Loss 6.7305e-01 (5.7447e-01)	Acc@1  92.19 ( 94.49)	Acc@5 100.00 ( 99.48)
Epoch: [9][25/43]	Time  0.150 ( 0.205)	Data  0.000 ( 0.044)	Loss 4.1287e-01 (5.9275e-01)	Acc@1  95.31 ( 94.23)	Acc@5 100.00 ( 99.46)
Epoch: [9][30/43]	Time  0.132 ( 0.196)	Data  0.000 ( 0.037)	Loss 7.9885e-01 (5.8247e-01)	Acc@1  93.75 ( 94.30)	Acc@5  96.88 ( 99.40)
Epoch: [9][35/43]	Time  0.142 ( 0.191)	Data  0.000 ( 0.033)	Loss 2.2119e-01 (5.6193e-01)	Acc@1 100.00 ( 94.49)	Acc@5 100.00 ( 99.48)
Epoch: [9][40/43]	Time  0.211 ( 0.190)	Data  0.048 ( 0.032)	Loss 6.5766e-01 (5.6898e-01)	Acc@1  93.75 ( 94.47)	Acc@5  98.44 ( 99.43)
Test: [ 0/16]	Time  1.028 ( 1.028)	Loss 1.1654e+00 (1.1654e+00)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.074 ( 0.298)	Loss 6.7747e-01 (4.9896e-01)	Acc@1  95.31 ( 94.79)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.104 ( 0.269)	Loss 1.4777e+00 (7.6441e-01)	Acc@1  85.94 ( 92.61)	Acc@5  98.44 ( 99.29)
Test: [15/16]	Time  0.048 ( 0.259)	Loss 1.8624e-02 (7.8927e-01)	Acc@1 100.00 ( 92.50)	Acc@5 100.00 ( 99.00)
 * Acc@1 92.500 Acc@5 99.000
learning rate is: 0.005386151140948993
Epoch: [10][ 0/43]	Time  1.437 ( 1.437)	Data  1.163 ( 1.163)	Loss 1.6285e+00 (1.6285e+00)	Acc@1  90.62 ( 90.62)	Acc@5  96.88 ( 96.88)
Epoch: [10][ 5/43]	Time  0.202 ( 0.418)	Data  0.000 ( 0.224)	Loss 7.4489e-01 (7.8407e-01)	Acc@1  90.62 ( 92.19)	Acc@5  98.44 ( 98.70)
Epoch: [10][10/43]	Time  0.169 ( 0.341)	Data  0.000 ( 0.149)	Loss 4.3237e-01 (7.1750e-01)	Acc@1  96.88 ( 92.61)	Acc@5 100.00 ( 99.01)
Epoch: [10][15/43]	Time  0.196 ( 0.305)	Data  0.000 ( 0.106)	Loss 3.5874e-01 (6.2956e-01)	Acc@1  95.31 ( 93.26)	Acc@5  98.44 ( 99.12)
Epoch: [10][20/43]	Time  0.229 ( 0.281)	Data  0.082 ( 0.090)	Loss 1.1688e+00 (6.8083e-01)	Acc@1  90.62 ( 93.15)	Acc@5  96.88 ( 99.03)
Epoch: [10][25/43]	Time  0.160 ( 0.270)	Data  0.000 ( 0.084)	Loss 3.3659e-01 (6.7731e-01)	Acc@1  98.44 ( 92.97)	Acc@5 100.00 ( 99.16)
Epoch: [10][30/43]	Time  0.258 ( 0.263)	Data  0.071 ( 0.079)	Loss 9.8487e-01 (6.7811e-01)	Acc@1  89.06 ( 92.89)	Acc@5 100.00 ( 99.19)
Epoch: [10][35/43]	Time  0.213 ( 0.259)	Data  0.000 ( 0.073)	Loss 2.2194e-01 (6.3788e-01)	Acc@1  95.31 ( 93.27)	Acc@5 100.00 ( 99.31)
Epoch: [10][40/43]	Time  0.346 ( 0.262)	Data  0.174 ( 0.076)	Loss 3.4829e-01 (6.2274e-01)	Acc@1  92.19 ( 93.41)	Acc@5 100.00 ( 99.31)
learning rate is: 0.005062982072492054
Epoch: [11][ 0/43]	Time  1.741 ( 1.741)	Data  1.559 ( 1.559)	Loss 3.1792e-01 (3.1792e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [11][ 5/43]	Time  0.135 ( 0.487)	Data  0.000 ( 0.301)	Loss 3.4164e-01 (6.7913e-01)	Acc@1  96.88 ( 94.79)	Acc@5 100.00 ( 98.96)
Epoch: [11][10/43]	Time  0.197 ( 0.364)	Data  0.000 ( 0.181)	Loss 2.8843e-01 (5.8354e-01)	Acc@1  96.88 ( 95.45)	Acc@5 100.00 ( 99.01)
Epoch: [11][15/43]	Time  0.153 ( 0.331)	Data  0.000 ( 0.153)	Loss 1.0254e+00 (6.0698e-01)	Acc@1  92.19 ( 95.02)	Acc@5  98.44 ( 99.02)
Epoch: [11][20/43]	Time  0.915 ( 0.351)	Data  0.755 ( 0.178)	Loss 6.5534e-01 (5.9465e-01)	Acc@1  95.31 ( 94.79)	Acc@5  96.88 ( 99.03)
Epoch: [11][25/43]	Time  0.165 ( 0.331)	Data  0.000 ( 0.153)	Loss 2.3980e-01 (5.5790e-01)	Acc@1  96.88 ( 95.01)	Acc@5 100.00 ( 99.16)
Epoch: [11][30/43]	Time  0.179 ( 0.308)	Data  0.000 ( 0.131)	Loss 4.9477e-01 (5.4004e-01)	Acc@1  96.88 ( 94.96)	Acc@5  98.44 ( 99.19)
Epoch: [11][35/43]	Time  0.260 ( 0.302)	Data  0.000 ( 0.119)	Loss 2.7647e-01 (5.2017e-01)	Acc@1  96.88 ( 94.92)	Acc@5 100.00 ( 99.26)
Epoch: [11][40/43]	Time  0.429 ( 0.297)	Data  0.228 ( 0.110)	Loss 4.1410e-01 (5.2761e-01)	Acc@1  96.88 ( 94.86)	Acc@5 100.00 ( 99.31)
learning rate is: 0.00475920314814253
Epoch: [12][ 0/43]	Time  1.558 ( 1.558)	Data  1.347 ( 1.347)	Loss 2.6100e-01 (2.6100e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [12][ 5/43]	Time  0.248 ( 0.444)	Data  0.070 ( 0.259)	Loss 1.0015e+00 (5.9104e-01)	Acc@1  92.19 ( 96.09)	Acc@5  96.88 ( 98.44)
Epoch: [12][10/43]	Time  0.172 ( 0.365)	Data  0.000 ( 0.182)	Loss 5.0341e-01 (5.3717e-01)	Acc@1  96.88 ( 95.88)	Acc@5  98.44 ( 98.86)
Epoch: [12][15/43]	Time  0.180 ( 0.342)	Data  0.000 ( 0.156)	Loss 4.6180e-01 (5.3234e-01)	Acc@1  95.31 ( 95.90)	Acc@5 100.00 ( 98.93)
Epoch: [12][20/43]	Time  0.172 ( 0.325)	Data  0.002 ( 0.136)	Loss 4.7316e-01 (4.7485e-01)	Acc@1  95.31 ( 96.21)	Acc@5  98.44 ( 99.11)
Epoch: [12][25/43]	Time  0.508 ( 0.320)	Data  0.305 ( 0.129)	Loss 3.3445e-01 (4.6807e-01)	Acc@1  95.31 ( 96.09)	Acc@5 100.00 ( 99.28)
Epoch: [12][30/43]	Time  0.195 ( 0.304)	Data  0.001 ( 0.110)	Loss 8.5882e-01 (4.6885e-01)	Acc@1  89.06 ( 95.87)	Acc@5  98.44 ( 99.24)
Epoch: [12][35/43]	Time  0.153 ( 0.293)	Data  0.000 ( 0.095)	Loss 2.7627e-01 (4.6889e-01)	Acc@1  95.31 ( 95.88)	Acc@5 100.00 ( 99.22)
Epoch: [12][40/43]	Time  0.387 ( 0.286)	Data  0.195 ( 0.088)	Loss 9.4722e-01 (4.9639e-01)	Acc@1  93.75 ( 95.73)	Acc@5  96.88 ( 99.09)
learning rate is: 0.004473650959253978
Epoch: [13][ 0/43]	Time  1.601 ( 1.601)	Data  1.385 ( 1.385)	Loss 4.2063e-01 (4.2063e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [13][ 5/43]	Time  0.174 ( 0.444)	Data  0.009 ( 0.271)	Loss 1.2134e+00 (6.2123e-01)	Acc@1  92.19 ( 94.27)	Acc@5 100.00 ( 99.48)
Epoch: [13][10/43]	Time  0.170 ( 0.361)	Data  0.000 ( 0.194)	Loss 1.5120e-01 (5.5009e-01)	Acc@1 100.00 ( 95.03)	Acc@5 100.00 ( 99.43)
Epoch: [13][15/43]	Time  0.207 ( 0.321)	Data  0.000 ( 0.149)	Loss 5.0942e-01 (5.1795e-01)	Acc@1  95.31 ( 95.61)	Acc@5  98.44 ( 99.32)
Epoch: [13][20/43]	Time  0.666 ( 0.324)	Data  0.489 ( 0.153)	Loss 2.5921e-01 (4.8254e-01)	Acc@1  96.88 ( 95.54)	Acc@5 100.00 ( 99.48)
Epoch: [13][25/43]	Time  0.163 ( 0.311)	Data  0.000 ( 0.132)	Loss 6.8666e-01 (4.9815e-01)	Acc@1  90.62 ( 95.37)	Acc@5  98.44 ( 99.40)
Epoch: [13][30/43]	Time  0.180 ( 0.292)	Data  0.000 ( 0.111)	Loss 5.9501e-01 (5.1050e-01)	Acc@1  93.75 ( 95.06)	Acc@5  98.44 ( 99.34)
Epoch: [13][35/43]	Time  0.144 ( 0.279)	Data  0.000 ( 0.099)	Loss 1.4509e-01 (5.1112e-01)	Acc@1  98.44 ( 95.18)	Acc@5 100.00 ( 99.26)
Epoch: [13][40/43]	Time  0.261 ( 0.274)	Data  0.112 ( 0.095)	Loss 8.9158e-01 (5.1569e-01)	Acc@1  96.88 ( 95.31)	Acc@5  98.44 ( 99.24)
learning rate is: 0.004205231901698739
Epoch: [14][ 0/43]	Time  1.408 ( 1.408)	Data  1.184 ( 1.184)	Loss 2.5431e-01 (2.5431e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [14][ 5/43]	Time  0.142 ( 0.437)	Data  0.000 ( 0.273)	Loss 8.3382e-01 (4.4608e-01)	Acc@1  89.06 ( 95.05)	Acc@5 100.00 (100.00)
Epoch: [14][10/43]	Time  0.162 ( 0.377)	Data  0.000 ( 0.215)	Loss 2.8993e-01 (4.6647e-01)	Acc@1  96.88 ( 95.31)	Acc@5 100.00 ( 99.72)
Epoch: [14][15/43]	Time  0.183 ( 0.334)	Data  0.001 ( 0.165)	Loss 8.9314e-01 (4.3084e-01)	Acc@1  95.31 ( 95.90)	Acc@5  98.44 ( 99.71)
Epoch: [14][20/43]	Time  0.544 ( 0.318)	Data  0.351 ( 0.149)	Loss 8.7058e-01 (5.7789e-01)	Acc@1  95.31 ( 94.87)	Acc@5  96.88 ( 99.18)
Epoch: [14][25/43]	Time  0.162 ( 0.301)	Data  0.000 ( 0.134)	Loss 4.3957e-01 (5.3946e-01)	Acc@1  92.19 ( 95.07)	Acc@5 100.00 ( 99.34)
Epoch: [14][30/43]	Time  0.192 ( 0.288)	Data  0.000 ( 0.118)	Loss 2.3913e-01 (5.3925e-01)	Acc@1  96.88 ( 95.06)	Acc@5 100.00 ( 99.24)
Epoch: [14][35/43]	Time  0.147 ( 0.280)	Data  0.000 ( 0.109)	Loss 1.2889e-01 (4.8917e-01)	Acc@1  98.44 ( 95.53)	Acc@5 100.00 ( 99.35)
Epoch: [14][40/43]	Time  0.279 ( 0.274)	Data  0.125 ( 0.102)	Loss 3.5405e-01 (4.9762e-01)	Acc@1  93.75 ( 95.39)	Acc@5 100.00 ( 99.39)
Test: [ 0/16]	Time  1.551 ( 1.551)	Loss 1.0652e+00 (1.0652e+00)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.060 ( 0.506)	Loss 7.4291e-01 (4.1396e-01)	Acc@1  92.19 ( 95.83)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.073 ( 0.399)	Loss 1.7512e+00 (6.8439e-01)	Acc@1  87.50 ( 93.47)	Acc@5  95.31 ( 99.01)
Test: [15/16]	Time  0.078 ( 0.341)	Loss 2.9584e-02 (7.3286e-01)	Acc@1 100.00 ( 93.00)	Acc@5 100.00 ( 98.90)
 * Acc@1 93.000 Acc@5 98.900
learning rate is: 0.003952917987596815
Epoch: [15][ 0/43]	Time  1.504 ( 1.504)	Data  1.195 ( 1.195)	Loss 6.2925e-01 (6.2925e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [15][ 5/43]	Time  0.223 ( 0.479)	Data  0.000 ( 0.268)	Loss 3.9645e-01 (4.9229e-01)	Acc@1  96.88 ( 95.83)	Acc@5 100.00 ( 99.48)
Epoch: [15][10/43]	Time  0.166 ( 0.370)	Data  0.000 ( 0.181)	Loss 4.1678e-01 (5.0479e-01)	Acc@1  93.75 ( 95.60)	Acc@5 100.00 ( 99.15)
Epoch: [15][15/43]	Time  0.195 ( 0.331)	Data  0.000 ( 0.149)	Loss 7.0186e-01 (4.9568e-01)	Acc@1  93.75 ( 95.70)	Acc@5  98.44 ( 99.22)
Epoch: [15][20/43]	Time  0.525 ( 0.345)	Data  0.334 ( 0.165)	Loss 1.1461e-01 (4.5994e-01)	Acc@1  98.44 ( 96.06)	Acc@5 100.00 ( 99.26)
Epoch: [15][25/43]	Time  0.172 ( 0.322)	Data  0.000 ( 0.142)	Loss 4.3831e-01 (4.3757e-01)	Acc@1  95.31 ( 96.21)	Acc@5 100.00 ( 99.34)
Epoch: [15][30/43]	Time  0.153 ( 0.310)	Data  0.000 ( 0.135)	Loss 2.9012e-01 (4.1866e-01)	Acc@1  95.31 ( 96.22)	Acc@5 100.00 ( 99.40)
Epoch: [15][35/43]	Time  0.173 ( 0.303)	Data  0.000 ( 0.126)	Loss 2.6277e-01 (4.0027e-01)	Acc@1  96.88 ( 96.40)	Acc@5 100.00 ( 99.48)
Epoch: [15][40/43]	Time  0.383 ( 0.297)	Data  0.229 ( 0.121)	Loss 1.3807e-01 (3.8381e-01)	Acc@1  98.44 ( 96.61)	Acc@5 100.00 ( 99.54)
learning rate is: 0.003715742908341006
Epoch: [16][ 0/43]	Time  1.350 ( 1.350)	Data  1.167 ( 1.167)	Loss 9.3774e-02 (9.3774e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [16][ 5/43]	Time  0.310 ( 0.492)	Data  0.108 ( 0.296)	Loss 4.7376e-01 (3.5424e-01)	Acc@1  95.31 ( 96.61)	Acc@5 100.00 ( 99.74)
Epoch: [16][10/43]	Time  0.143 ( 0.368)	Data  0.000 ( 0.175)	Loss 2.8859e-01 (2.9727e-01)	Acc@1  98.44 ( 97.44)	Acc@5 100.00 ( 99.86)
Epoch: [16][15/43]	Time  0.135 ( 0.321)	Data  0.000 ( 0.137)	Loss 1.7928e-01 (3.6678e-01)	Acc@1  96.88 ( 96.78)	Acc@5 100.00 ( 99.51)
Epoch: [16][20/43]	Time  0.325 ( 0.307)	Data  0.132 ( 0.128)	Loss 1.8385e-01 (4.5534e-01)	Acc@1  98.44 ( 96.13)	Acc@5 100.00 ( 99.40)
Epoch: [16][25/43]	Time  0.179 ( 0.290)	Data  0.000 ( 0.114)	Loss 9.4354e-01 (5.0186e-01)	Acc@1  90.62 ( 95.91)	Acc@5  98.44 ( 99.28)
Epoch: [16][30/43]	Time  0.135 ( 0.275)	Data  0.000 ( 0.101)	Loss 6.9922e-01 (4.8682e-01)	Acc@1  93.75 ( 96.12)	Acc@5  98.44 ( 99.29)
Epoch: [16][35/43]	Time  0.374 ( 0.271)	Data  0.197 ( 0.099)	Loss 4.5055e-01 (4.5652e-01)	Acc@1  95.31 ( 96.35)	Acc@5 100.00 ( 99.35)
Epoch: [16][40/43]	Time  0.130 ( 0.271)	Data  0.000 ( 0.101)	Loss 4.2466e-01 (4.5663e-01)	Acc@1  96.88 ( 96.42)	Acc@5  98.44 ( 99.28)
learning rate is: 0.0034927983338405456
Epoch: [17][ 0/43]	Time  1.630 ( 1.630)	Data  1.436 ( 1.436)	Loss 3.1215e-01 (3.1215e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [17][ 5/43]	Time  0.152 ( 0.475)	Data  0.000 ( 0.310)	Loss 1.3914e-01 (4.4605e-01)	Acc@1 100.00 ( 95.57)	Acc@5 100.00 ( 99.74)
Epoch: [17][10/43]	Time  0.157 ( 0.360)	Data  0.000 ( 0.196)	Loss 3.2461e-01 (4.3293e-01)	Acc@1  95.31 ( 95.88)	Acc@5 100.00 ( 99.57)
Epoch: [17][15/43]	Time  0.273 ( 0.329)	Data  0.000 ( 0.154)	Loss 5.8674e-01 (4.1933e-01)	Acc@1  96.88 ( 96.19)	Acc@5  98.44 ( 99.51)
Epoch: [17][20/43]	Time  0.180 ( 0.309)	Data  0.000 ( 0.126)	Loss 1.0809e+00 (4.4791e-01)	Acc@1  95.31 ( 96.06)	Acc@5  96.88 ( 99.33)
Epoch: [17][25/43]	Time  0.412 ( 0.303)	Data  0.214 ( 0.117)	Loss 3.6622e-01 (4.1269e-01)	Acc@1  98.44 ( 96.33)	Acc@5  98.44 ( 99.40)
Epoch: [17][30/43]	Time  0.141 ( 0.296)	Data  0.000 ( 0.112)	Loss 5.6194e-01 (4.0376e-01)	Acc@1  92.19 ( 96.22)	Acc@5 100.00 ( 99.45)
Epoch: [17][35/43]	Time  0.246 ( 0.290)	Data  0.000 ( 0.104)	Loss 2.8339e-01 (4.0390e-01)	Acc@1  98.44 ( 96.31)	Acc@5 100.00 ( 99.44)
Epoch: [17][40/43]	Time  0.162 ( 0.284)	Data  0.000 ( 0.099)	Loss 4.1683e-01 (3.9620e-01)	Acc@1  93.75 ( 96.27)	Acc@5 100.00 ( 99.50)
learning rate is: 0.0032832304338101127
Epoch: [18][ 0/43]	Time  1.597 ( 1.597)	Data  1.384 ( 1.384)	Loss 1.2889e-01 (1.2889e-01)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [18][ 5/43]	Time  0.160 ( 0.442)	Data  0.000 ( 0.278)	Loss 1.3628e-01 (2.9168e-01)	Acc@1  96.88 ( 97.66)	Acc@5 100.00 ( 99.74)
Epoch: [18][10/43]	Time  0.197 ( 0.332)	Data  0.000 ( 0.164)	Loss 3.2499e-01 (3.7301e-01)	Acc@1  93.75 ( 97.02)	Acc@5 100.00 ( 99.43)
Epoch: [18][15/43]	Time  0.164 ( 0.295)	Data  0.000 ( 0.126)	Loss 5.7229e-01 (4.0253e-01)	Acc@1  95.31 ( 96.68)	Acc@5  98.44 ( 99.41)
Epoch: [18][20/43]	Time  0.409 ( 0.291)	Data  0.167 ( 0.121)	Loss 7.3599e-01 (4.1681e-01)	Acc@1  92.19 ( 96.43)	Acc@5  98.44 ( 99.40)
Epoch: [18][25/43]	Time  0.188 ( 0.275)	Data  0.000 ( 0.104)	Loss 5.0626e-01 (4.2767e-01)	Acc@1  93.75 ( 96.27)	Acc@5 100.00 ( 99.34)
Epoch: [18][30/43]	Time  0.216 ( 0.275)	Data  0.000 ( 0.097)	Loss 3.4712e-01 (4.4543e-01)	Acc@1  95.31 ( 96.17)	Acc@5 100.00 ( 99.24)
Epoch: [18][35/43]	Time  0.146 ( 0.271)	Data  0.000 ( 0.095)	Loss 6.5079e-01 (4.5554e-01)	Acc@1  93.75 ( 95.96)	Acc@5  98.44 ( 99.22)
Epoch: [18][40/43]	Time  0.164 ( 0.275)	Data  0.000 ( 0.100)	Loss 2.7213e-01 (4.5265e-01)	Acc@1  96.88 ( 95.96)	Acc@5 100.00 ( 99.16)
learning rate is: 0.0030862366077815057
Epoch: [19][ 0/43]	Time  1.498 ( 1.498)	Data  1.240 ( 1.240)	Loss 7.5855e-01 (7.5855e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [19][ 5/43]	Time  0.157 ( 0.428)	Data  0.000 ( 0.242)	Loss 6.6120e-01 (5.3520e-01)	Acc@1  95.31 ( 95.05)	Acc@5  98.44 ( 98.70)
Epoch: [19][10/43]	Time  0.141 ( 0.336)	Data  0.000 ( 0.161)	Loss 3.3741e-01 (4.2852e-01)	Acc@1  96.88 ( 95.88)	Acc@5  98.44 ( 99.15)
Epoch: [19][15/43]	Time  0.152 ( 0.292)	Data  0.000 ( 0.121)	Loss 5.2625e-01 (4.3800e-01)	Acc@1  93.75 ( 95.61)	Acc@5 100.00 ( 99.32)
Epoch: [19][20/43]	Time  0.348 ( 0.280)	Data  0.170 ( 0.110)	Loss 1.0689e+00 (4.6399e-01)	Acc@1  93.75 ( 95.61)	Acc@5  98.44 ( 99.33)
Epoch: [19][25/43]	Time  0.429 ( 0.273)	Data  0.246 ( 0.104)	Loss 1.5873e-01 (4.2231e-01)	Acc@1  98.44 ( 95.91)	Acc@5 100.00 ( 99.40)
Epoch: [19][30/43]	Time  0.196 ( 0.267)	Data  0.000 ( 0.095)	Loss 4.5449e-01 (4.2050e-01)	Acc@1  92.19 ( 95.61)	Acc@5 100.00 ( 99.45)
Epoch: [19][35/43]	Time  0.181 ( 0.266)	Data  0.000 ( 0.094)	Loss 4.9796e-01 (4.1940e-01)	Acc@1  95.31 ( 95.62)	Acc@5 100.00 ( 99.52)
Epoch: [19][40/43]	Time  0.729 ( 0.280)	Data  0.577 ( 0.110)	Loss 2.5924e-01 (4.3083e-01)	Acc@1  95.31 ( 95.58)	Acc@5 100.00 ( 99.43)
Test: [ 0/16]	Time  1.537 ( 1.537)	Loss 7.1396e-01 (7.1396e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [ 5/16]	Time  0.056 ( 0.462)	Loss 4.8065e-01 (3.0339e-01)	Acc@1  93.75 ( 95.83)	Acc@5 100.00 (100.00)
Test: [10/16]	Time  0.109 ( 0.354)	Loss 1.5953e+00 (5.9400e-01)	Acc@1  89.06 ( 94.03)	Acc@5  95.31 ( 99.29)
Test: [15/16]	Time  0.056 ( 0.303)	Loss 2.3847e-02 (6.2340e-01)	Acc@1 100.00 ( 94.20)	Acc@5 100.00 ( 99.40)
 * Acc@1 94.200 Acc@5 99.400
learning rate is: 0.002901062411314615
Epoch: [20][ 0/43]	Time  1.639 ( 1.639)	Data  1.429 ( 1.429)	Loss 8.5021e-01 (8.5021e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [20][ 5/43]	Time  0.181 ( 0.444)	Data  0.002 ( 0.265)	Loss 3.3373e-01 (3.9875e-01)	Acc@1  96.88 ( 97.40)	Acc@5 100.00 ( 99.74)
Epoch: [20][10/43]	Time  0.133 ( 0.327)	Data  0.000 ( 0.149)	Loss 8.9176e-01 (5.1116e-01)	Acc@1  93.75 ( 96.73)	Acc@5  96.88 ( 99.15)
Epoch: [20][15/43]	Time  0.152 ( 0.285)	Data  0.000 ( 0.111)	Loss 1.5911e-01 (4.4106e-01)	Acc@1  98.44 ( 96.97)	Acc@5 100.00 ( 99.32)
Epoch: [20][20/43]	Time  0.418 ( 0.288)	Data  0.218 ( 0.109)	Loss 2.9017e-01 (4.1604e-01)	Acc@1  98.44 ( 97.02)	Acc@5  98.44 ( 99.26)
Epoch: [20][25/43]	Time  0.195 ( 0.294)	Data  0.000 ( 0.112)	Loss 1.4455e-01 (3.8654e-01)	Acc@1  98.44 ( 97.24)	Acc@5 100.00 ( 99.40)
Epoch: [20][30/43]	Time  0.235 ( 0.292)	Data  0.000 ( 0.105)	Loss 5.0794e-01 (3.7992e-01)	Acc@1  96.88 ( 97.23)	Acc@5  98.44 ( 99.40)
Epoch: [20][35/43]	Time  0.207 ( 0.286)	Data  0.000 ( 0.097)	Loss 4.1051e-01 (3.7577e-01)	Acc@1  93.75 ( 97.05)	Acc@5  98.44 ( 99.39)
Epoch: [20][40/43]	Time  0.446 ( 0.282)	Data  0.281 ( 0.095)	Loss 2.2486e-01 (3.7966e-01)	Acc@1  98.44 ( 96.99)	Acc@5 100.00 ( 99.39)
learning rate is: 0.0027269986666357375
Epoch: [21][ 0/43]	Time  1.936 ( 1.936)	Data  1.584 ( 1.584)	Loss 3.5617e-01 (3.5617e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [21][ 5/43]	Time  0.166 ( 0.482)	Data  0.000 ( 0.265)	Loss 6.2684e-01 (5.6605e-01)	Acc@1  95.31 ( 93.75)	Acc@5  96.88 ( 98.96)
Epoch: [21][10/43]	Time  0.136 ( 0.353)	Data  0.000 ( 0.161)	Loss 9.5668e-02 (4.6681e-01)	Acc@1 100.00 ( 95.31)	Acc@5 100.00 ( 99.15)
Epoch: [21][15/43]	Time  0.198 ( 0.318)	Data  0.000 ( 0.130)	Loss 3.7311e-01 (4.1850e-01)	Acc@1  98.44 ( 96.00)	Acc@5  98.44 ( 99.22)
Epoch: [21][20/43]	Time  0.312 ( 0.305)	Data  0.083 ( 0.114)	Loss 4.1471e-01 (4.3943e-01)	Acc@1  95.31 ( 95.61)	Acc@5 100.00 ( 99.26)
Epoch: [21][25/43]	Time  0.520 ( 0.311)	Data  0.348 ( 0.123)	Loss 5.6074e-01 (4.2766e-01)	Acc@1  93.75 ( 95.61)	Acc@5  98.44 ( 99.34)
Epoch: [21][30/43]	Time  0.192 ( 0.303)	Data  0.000 ( 0.115)	Loss 1.9281e-01 (4.1889e-01)	Acc@1  96.88 ( 95.77)	Acc@5 100.00 ( 99.40)
Epoch: [21][35/43]	Time  0.189 ( 0.293)	Data  0.000 ( 0.106)	Loss 1.8247e-01 (3.9547e-01)	Acc@1  98.44 ( 96.01)	Acc@5 100.00 ( 99.44)
Epoch: [21][40/43]	Time  0.144 ( 0.281)	Data  0.000 ( 0.095)	Loss 4.2272e-01 (3.9065e-01)	Acc@1  98.44 ( 96.19)	Acc@5  98.44 ( 99.39)
learning rate is: 0.0025633787466375936
Epoch: [22][ 0/43]	Time  1.257 ( 1.257)	Data  1.084 ( 1.084)	Loss 1.3220e-01 (1.3220e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [22][ 5/43]	Time  0.169 ( 0.413)	Data  0.000 ( 0.250)	Loss 5.1314e-01 (3.8674e-01)	Acc@1  95.31 ( 97.40)	Acc@5 100.00 ( 99.74)
Epoch: [22][10/43]	Time  0.439 ( 0.370)	Data  0.242 ( 0.198)	Loss 2.4330e-01 (3.5994e-01)	Acc@1  98.44 ( 97.30)	Acc@5  98.44 ( 99.72)
Epoch: [22][15/43]	Time  0.179 ( 0.333)	Data  0.000 ( 0.151)	Loss 1.5711e-01 (3.2092e-01)	Acc@1  98.44 ( 97.27)	Acc@5 100.00 ( 99.80)
Epoch: [22][20/43]	Time  0.149 ( 0.301)	Data  0.000 ( 0.125)	Loss 4.9674e-01 (3.4885e-01)	Acc@1  95.31 ( 96.95)	Acc@5  98.44 ( 99.63)
Epoch: [22][25/43]	Time  0.149 ( 0.289)	Data  0.000 ( 0.115)	Loss 1.0702e+00 (4.0031e-01)	Acc@1  92.19 ( 96.45)	Acc@5  96.88 ( 99.46)
Epoch: [22][30/43]	Time  0.341 ( 0.282)	Data  0.190 ( 0.106)	Loss 3.4586e-01 (3.6465e-01)	Acc@1  96.88 ( 96.82)	Acc@5 100.00 ( 99.55)
Epoch: [22][35/43]	Time  0.179 ( 0.281)	Data  0.000 ( 0.107)	Loss 2.6317e-01 (3.7259e-01)	Acc@1  95.31 ( 96.70)	Acc@5 100.00 ( 99.48)
Epoch: [22][40/43]	Time  0.272 ( 0.272)	Data  0.129 ( 0.102)	Loss 1.8460e-01 (3.7022e-01)	Acc@1  96.88 ( 96.68)	Acc@5 100.00 ( 99.50)
learning rate is: 0.0024095760218393377
Epoch: [23][ 0/43]	Time  1.365 ( 1.365)	Data  1.167 ( 1.167)	Loss 6.7838e-01 (6.7838e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [23][ 5/43]	Time  0.176 ( 0.426)	Data  0.000 ( 0.261)	Loss 3.9867e-01 (3.8334e-01)	Acc@1  96.88 ( 96.35)	Acc@5 100.00 ( 99.48)
Epoch: [23][10/43]	Time  0.151 ( 0.341)	Data  0.000 ( 0.182)	Loss 1.2955e-01 (3.3817e-01)	Acc@1 100.00 ( 97.44)	Acc@5 100.00 ( 99.43)
Epoch: [23][15/43]	Time  0.144 ( 0.319)	Data  0.000 ( 0.165)	Loss 3.4882e-01 (3.8537e-01)	Acc@1  96.88 ( 96.97)	Acc@5 100.00 ( 99.41)
Epoch: [23][20/43]	Time  0.271 ( 0.313)	Data  0.000 ( 0.151)	Loss 2.8158e-01 (3.7843e-01)	Acc@1  98.44 ( 97.17)	Acc@5 100.00 ( 99.55)
Epoch: [23][25/43]	Time  0.322 ( 0.301)	Data  0.175 ( 0.137)	Loss 5.4828e-02 (3.6354e-01)	Acc@1 100.00 ( 97.18)	Acc@5 100.00 ( 99.64)
Epoch: [23][30/43]	Time  0.160 ( 0.285)	Data  0.000 ( 0.116)	Loss 3.5228e-01 (3.6460e-01)	Acc@1  98.44 ( 97.03)	Acc@5  98.44 ( 99.60)
Epoch: [23][35/43]	Time  0.135 ( 0.275)	Data  0.000 ( 0.107)	Loss 5.3212e-01 (3.6873e-01)	Acc@1  93.75 ( 96.83)	Acc@5 100.00 ( 99.57)
Epoch: [23][40/43]	Time  0.140 ( 0.274)	Data  0.000 ( 0.106)	Loss 2.4926e-01 (3.6861e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 ( 99.58)
learning rate is: 0.0022650014605289774
Epoch: [24][ 0/43]	Time  1.714 ( 1.714)	Data  1.499 ( 1.499)	Loss 4.4976e-01 (4.4976e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [24][ 5/43]	Time  0.152 ( 0.475)	Data  0.000 ( 0.301)	Loss 1.2091e-01 (4.2957e-01)	Acc@1 100.00 ( 96.88)	Acc@5 100.00 ( 99.22)
Epoch: [24][10/43]	Time  0.169 ( 0.360)	Data  0.000 ( 0.190)	Loss 5.9465e-02 (3.7669e-01)	Acc@1 100.00 ( 97.30)	Acc@5 100.00 ( 99.43)
Epoch: [24][15/43]	Time  0.151 ( 0.325)	Data  0.000 ( 0.151)	Loss 1.5874e-01 (3.5750e-01)	Acc@1  96.88 ( 97.17)	Acc@5 100.00 ( 99.51)
Epoch: [24][20/43]	Time  0.597 ( 0.309)	Data  0.428 ( 0.141)	Loss 7.4388e-01 (3.6224e-01)	Acc@1  95.31 ( 97.10)	Acc@5 100.00 ( 99.55)
Epoch: [24][25/43]	Time  0.161 ( 0.290)	Data  0.000 ( 0.124)	Loss 3.5187e-01 (3.5954e-01)	Acc@1  93.75 ( 96.94)	Acc@5 100.00 ( 99.52)
Epoch: [24][30/43]	Time  0.147 ( 0.276)	Data  0.000 ( 0.112)	Loss 3.5731e-01 (3.7928e-01)	Acc@1  96.88 ( 96.62)	Acc@5  98.44 ( 99.45)
Epoch: [24][35/43]	Time  0.155 ( 0.269)	Data  0.000 ( 0.106)	Loss 2.1792e-01 (3.5910e-01)	Acc@1  98.44 ( 96.79)	Acc@5 100.00 ( 99.52)
Epoch: [24][40/43]	Time  0.185 ( 0.270)	Data  0.000 ( 0.105)	Loss 2.2029e-01 (3.8317e-01)	Acc@1  98.44 ( 96.80)	Acc@5 100.00 ( 99.47)
Test: [ 0/16]	Time  1.579 ( 1.579)	Loss 8.1375e-01 (8.1375e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [ 5/16]	Time  0.097 ( 0.457)	Loss 5.9352e-01 (3.4435e-01)	Acc@1  92.19 ( 96.09)	Acc@5 100.00 (100.00)
Test: [10/16]	Time  0.094 ( 0.362)	Loss 1.6653e+00 (6.4966e-01)	Acc@1  87.50 ( 93.89)	Acc@5  95.31 ( 99.15)
Test: [15/16]	Time  0.039 ( 0.320)	Loss 2.1862e-02 (6.7831e-01)	Acc@1 100.00 ( 93.80)	Acc@5 100.00 ( 98.90)
 * Acc@1 93.800 Acc@5 98.900
learning rate is: 0.0021291013728972387
Epoch: [25][ 0/43]	Time  1.276 ( 1.276)	Data  0.994 ( 0.994)	Loss 3.1777e-01 (3.1777e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [25][ 5/43]	Time  0.271 ( 0.401)	Data  0.070 ( 0.197)	Loss 1.0191e+00 (4.3129e-01)	Acc@1  92.19 ( 95.31)	Acc@5  98.44 ( 99.48)
Epoch: [25][10/43]	Time  0.212 ( 0.334)	Data  0.000 ( 0.141)	Loss 2.0705e-01 (3.0961e-01)	Acc@1  96.88 ( 96.59)	Acc@5 100.00 ( 99.72)
Epoch: [25][15/43]	Time  0.215 ( 0.307)	Data  0.000 ( 0.097)	Loss 3.7282e-01 (3.2495e-01)	Acc@1  95.31 ( 96.58)	Acc@5 100.00 ( 99.61)
Epoch: [25][20/43]	Time  0.144 ( 0.277)	Data  0.000 ( 0.074)	Loss 2.3330e-01 (3.4151e-01)	Acc@1  98.44 ( 96.73)	Acc@5 100.00 ( 99.55)
Epoch: [25][25/43]	Time  0.183 ( 0.264)	Data  0.000 ( 0.060)	Loss 2.6585e-01 (3.2900e-01)	Acc@1  98.44 ( 96.88)	Acc@5 100.00 ( 99.58)
Epoch: [25][30/43]	Time  0.285 ( 0.258)	Data  0.000 ( 0.051)	Loss 4.7120e-01 (3.4999e-01)	Acc@1  96.88 ( 96.77)	Acc@5  98.44 ( 99.55)
Epoch: [25][35/43]	Time  0.227 ( 0.250)	Data  0.000 ( 0.044)	Loss 1.4578e-01 (3.3539e-01)	Acc@1  98.44 ( 96.92)	Acc@5 100.00 ( 99.61)
Epoch: [25][40/43]	Time  0.134 ( 0.239)	Data  0.000 ( 0.038)	Loss 4.0749e-01 (3.3592e-01)	Acc@1  96.88 ( 96.91)	Acc@5 100.00 ( 99.62)
learning rate is: 0.002001355290523404
Epoch: [26][ 0/43]	Time  1.200 ( 1.200)	Data  0.938 ( 0.938)	Loss 5.1657e-01 (5.1657e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [26][ 5/43]	Time  0.208 ( 0.381)	Data  0.000 ( 0.157)	Loss 3.4503e-01 (3.4885e-01)	Acc@1  98.44 ( 96.88)	Acc@5  98.44 ( 99.22)
Epoch: [26][10/43]	Time  0.151 ( 0.297)	Data  0.000 ( 0.086)	Loss 7.1974e-02 (3.4015e-01)	Acc@1 100.00 ( 97.30)	Acc@5 100.00 ( 99.29)
Epoch: [26][15/43]	Time  0.171 ( 0.271)	Data  0.000 ( 0.059)	Loss 2.2953e-01 (3.2693e-01)	Acc@1  98.44 ( 97.27)	Acc@5 100.00 ( 99.32)
Epoch: [26][20/43]	Time  0.176 ( 0.257)	Data  0.000 ( 0.045)	Loss 1.6028e-01 (3.1898e-01)	Acc@1  98.44 ( 97.47)	Acc@5 100.00 ( 99.33)
Epoch: [26][25/43]	Time  0.273 ( 0.253)	Data  0.000 ( 0.037)	Loss 1.7539e-01 (3.2294e-01)	Acc@1  98.44 ( 97.42)	Acc@5 100.00 ( 99.28)
Epoch: [26][30/43]	Time  0.222 ( 0.245)	Data  0.000 ( 0.031)	Loss 8.7992e-02 (2.9829e-01)	Acc@1 100.00 ( 97.53)	Acc@5 100.00 ( 99.40)
Epoch: [26][35/43]	Time  0.195 ( 0.241)	Data  0.001 ( 0.027)	Loss 3.1708e-01 (2.9870e-01)	Acc@1  96.88 ( 97.53)	Acc@5 100.00 ( 99.39)
Epoch: [26][40/43]	Time  0.134 ( 0.230)	Data  0.000 ( 0.024)	Loss 2.4662e-01 (3.2305e-01)	Acc@1  98.44 ( 97.37)	Acc@5 100.00 ( 99.31)
learning rate is: 0.0018812739730919997
Epoch: [27][ 0/43]	Time  1.075 ( 1.075)	Data  0.810 ( 0.810)	Loss 4.4988e-01 (4.4988e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [27][ 5/43]	Time  0.186 ( 0.337)	Data  0.000 ( 0.135)	Loss 9.4103e-02 (3.9137e-01)	Acc@1 100.00 ( 96.61)	Acc@5 100.00 ( 99.74)
Epoch: [27][10/43]	Time  0.191 ( 0.273)	Data  0.000 ( 0.074)	Loss 1.7693e-01 (3.3737e-01)	Acc@1  98.44 ( 97.59)	Acc@5 100.00 ( 99.72)
Epoch: [27][15/43]	Time  0.212 ( 0.252)	Data  0.001 ( 0.051)	Loss 1.6287e-01 (3.3288e-01)	Acc@1  98.44 ( 97.56)	Acc@5 100.00 ( 99.61)
Epoch: [27][20/43]	Time  0.189 ( 0.239)	Data  0.000 ( 0.039)	Loss 2.7997e-01 (3.1876e-01)	Acc@1  93.75 ( 97.25)	Acc@5 100.00 ( 99.70)
Epoch: [27][25/43]	Time  0.201 ( 0.232)	Data  0.000 ( 0.032)	Loss 1.3825e-01 (3.2223e-01)	Acc@1 100.00 ( 97.12)	Acc@5 100.00 ( 99.70)
Epoch: [27][30/43]	Time  0.178 ( 0.226)	Data  0.000 ( 0.027)	Loss 1.3329e-01 (3.1659e-01)	Acc@1 100.00 ( 97.08)	Acc@5 100.00 ( 99.75)
Epoch: [27][35/43]	Time  0.162 ( 0.226)	Data  0.000 ( 0.023)	Loss 5.1041e-01 (3.1065e-01)	Acc@1  93.75 ( 97.14)	Acc@5  98.44 ( 99.74)
Epoch: [27][40/43]	Time  0.133 ( 0.220)	Data  0.000 ( 0.020)	Loss 3.4036e-01 (3.1233e-01)	Acc@1  98.44 ( 97.10)	Acc@5  98.44 ( 99.73)
learning rate is: 0.00176839753470648
Epoch: [28][ 0/43]	Time  1.098 ( 1.098)	Data  0.879 ( 0.879)	Loss 9.1092e-02 (9.1092e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [28][ 5/43]	Time  0.186 ( 0.359)	Data  0.000 ( 0.157)	Loss 9.0289e-01 (3.9471e-01)	Acc@1  96.88 ( 97.66)	Acc@5  96.88 ( 98.96)
Epoch: [28][10/43]	Time  0.185 ( 0.297)	Data  0.000 ( 0.086)	Loss 6.9083e-02 (3.4315e-01)	Acc@1 100.00 ( 97.59)	Acc@5 100.00 ( 99.29)
Epoch: [28][15/43]	Time  0.219 ( 0.263)	Data  0.000 ( 0.059)	Loss 2.5059e-01 (3.3310e-01)	Acc@1  95.31 ( 97.46)	Acc@5 100.00 ( 99.41)
Epoch: [28][20/43]	Time  0.170 ( 0.249)	Data  0.000 ( 0.045)	Loss 4.6711e-01 (3.5109e-01)	Acc@1  96.88 ( 97.10)	Acc@5  98.44 ( 99.48)
Epoch: [28][25/43]	Time  0.322 ( 0.247)	Data  0.000 ( 0.037)	Loss 2.3522e-01 (3.4631e-01)	Acc@1  96.88 ( 97.00)	Acc@5 100.00 ( 99.52)
Epoch: [28][30/43]	Time  0.267 ( 0.243)	Data  0.000 ( 0.031)	Loss 7.6880e-02 (3.3249e-01)	Acc@1 100.00 ( 96.98)	Acc@5 100.00 ( 99.55)
Epoch: [28][35/43]	Time  0.201 ( 0.234)	Data  0.000 ( 0.027)	Loss 7.7912e-01 (3.3067e-01)	Acc@1  96.88 ( 97.05)	Acc@5  98.44 ( 99.57)
Epoch: [28][40/43]	Time  0.133 ( 0.227)	Data  0.000 ( 0.023)	Loss 1.4728e-01 (3.3515e-01)	Acc@1  95.31 ( 97.10)	Acc@5 100.00 ( 99.54)
learning rate is: 0.001662293682624091
Epoch: [29][ 0/43]	Time  1.058 ( 1.058)	Data  0.836 ( 0.836)	Loss 1.1491e-01 (1.1491e-01)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [29][ 5/43]	Time  0.159 ( 0.344)	Data  0.000 ( 0.140)	Loss 5.4106e-01 (3.2505e-01)	Acc@1  96.88 ( 97.14)	Acc@5 100.00 (100.00)
Epoch: [29][10/43]	Time  0.275 ( 0.274)	Data  0.000 ( 0.076)	Loss 4.7573e-01 (3.3500e-01)	Acc@1  95.31 ( 97.30)	Acc@5 100.00 ( 99.72)
Epoch: [29][15/43]	Time  0.158 ( 0.253)	Data  0.000 ( 0.053)	Loss 4.4651e-01 (3.8395e-01)	Acc@1  98.44 ( 96.88)	Acc@5  98.44 ( 99.41)
Epoch: [29][20/43]	Time  0.277 ( 0.248)	Data  0.000 ( 0.040)	Loss 1.6363e-01 (3.3582e-01)	Acc@1  98.44 ( 97.17)	Acc@5 100.00 ( 99.55)
Epoch: [29][25/43]	Time  0.158 ( 0.237)	Data  0.000 ( 0.033)	Loss 5.5268e-01 (3.7325e-01)	Acc@1  96.88 ( 96.69)	Acc@5 100.00 ( 99.52)
Epoch: [29][30/43]	Time  0.179 ( 0.231)	Data  0.000 ( 0.028)	Loss 1.5359e-01 (3.6304e-01)	Acc@1  98.44 ( 96.72)	Acc@5 100.00 ( 99.55)
Epoch: [29][35/43]	Time  0.209 ( 0.227)	Data  0.000 ( 0.024)	Loss 1.0863e-01 (3.5858e-01)	Acc@1  98.44 ( 96.70)	Acc@5 100.00 ( 99.57)
Epoch: [29][40/43]	Time  0.217 ( 0.221)	Data  0.000 ( 0.021)	Loss 3.3462e-01 (3.5233e-01)	Acc@1  96.88 ( 96.65)	Acc@5 100.00 ( 99.58)
Test: [ 0/16]	Time  1.068 ( 1.068)	Loss 8.4668e-01 (8.4668e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Test: [ 5/16]	Time  0.224 ( 0.332)	Loss 5.3139e-01 (3.2409e-01)	Acc@1  92.19 ( 96.09)	Acc@5 100.00 ( 99.74)
Test: [10/16]	Time  0.067 ( 0.258)	Loss 1.4366e+00 (5.9453e-01)	Acc@1  90.62 ( 94.18)	Acc@5  96.88 ( 99.29)
Test: [15/16]	Time  0.064 ( 0.231)	Loss 2.6380e-02 (6.3085e-01)	Acc@1 100.00 ( 94.30)	Acc@5 100.00 ( 99.10)
 * Acc@1 94.300 Acc@5 99.100


















 Epoch: [0][ 0/86]	Time  6.710 ( 6.710)	Data  0.381 ( 0.381)	Loss 3.8955e+00 (3.8955e+00)	Acc@1   6.25 (  6.25)	Acc@5  15.62 ( 15.62)
Epoch: [0][20/86]	Time  0.146 ( 0.458)	Data  0.000 ( 0.018)	Loss 3.5835e+00 (3.7849e+00)	Acc@1  25.00 ( 12.65)	Acc@5  46.88 ( 31.99)
Epoch: [0][40/86]	Time  0.163 ( 0.315)	Data  0.000 ( 0.009)	Loss 2.8658e+00 (3.4841e+00)	Acc@1  21.88 ( 24.31)	Acc@5  71.88 ( 46.95)
Epoch: [0][60/86]	Time  0.180 ( 0.263)	Data  0.000 ( 0.006)	Loss 1.9961e+00 (3.1678e+00)	Acc@1  56.25 ( 31.35)	Acc@5  81.25 ( 56.30)
Epoch: [0][80/86]	Time  0.099 ( 0.237)	Data  0.000 ( 0.005)	Loss 1.6754e+00 (2.8418e+00)	Acc@1  65.62 ( 38.12)	Acc@5  93.75 ( 64.27)
learning rate is: 0.0094
Epoch: [1][ 0/86]	Time  0.793 ( 0.793)	Data  0.570 ( 0.570)	Loss 1.3569e+00 (1.3569e+00)	Acc@1  78.12 ( 78.12)	Acc@5 100.00 (100.00)
Epoch: [1][20/86]	Time  0.190 ( 0.188)	Data  0.000 ( 0.027)	Loss 1.1668e+00 (1.2570e+00)	Acc@1  71.88 ( 72.02)	Acc@5  96.88 ( 93.30)
Epoch: [1][40/86]	Time  0.178 ( 0.171)	Data  0.000 ( 0.014)	Loss 1.1454e+00 (1.1885e+00)	Acc@1  65.62 ( 72.94)	Acc@5  90.62 ( 93.22)
Epoch: [1][60/86]	Time  0.148 ( 0.165)	Data  0.000 ( 0.010)	Loss 1.0293e+00 (1.0854e+00)	Acc@1  75.00 ( 74.90)	Acc@5  90.62 ( 93.75)
Epoch: [1][80/86]	Time  0.096 ( 0.161)	Data  0.000 ( 0.007)	Loss 8.5628e-01 (1.0422e+00)	Acc@1  78.12 ( 75.08)	Acc@5  93.75 ( 93.79)
learning rate is: 0.008836
Epoch: [2][ 0/86]	Time  0.872 ( 0.872)	Data  0.639 ( 0.639)	Loss 5.3197e-01 (5.3197e-01)	Acc@1  81.25 ( 81.25)	Acc@5 100.00 (100.00)
Epoch: [2][20/86]	Time  0.164 ( 0.183)	Data  0.000 ( 0.031)	Loss 7.0177e-01 (6.5065e-01)	Acc@1  81.25 ( 82.59)	Acc@5  96.88 ( 96.58)
Epoch: [2][40/86]	Time  0.116 ( 0.171)	Data  0.000 ( 0.016)	Loss 5.3027e-01 (6.5830e-01)	Acc@1  78.12 ( 80.64)	Acc@5  96.88 ( 96.72)
Epoch: [2][60/86]	Time  0.161 ( 0.163)	Data  0.000 ( 0.011)	Loss 8.3752e-01 (6.6641e-01)	Acc@1  75.00 ( 80.99)	Acc@5  93.75 ( 96.52)
Epoch: [2][80/86]	Time  0.089 ( 0.158)	Data  0.000 ( 0.008)	Loss 5.8571e-01 (6.4766e-01)	Acc@1  87.50 ( 81.71)	Acc@5 100.00 ( 96.84)
learning rate is: 0.008305839999999998
Epoch: [3][ 0/86]	Time  0.757 ( 0.757)	Data  0.583 ( 0.583)	Loss 5.1212e-01 (5.1212e-01)	Acc@1  87.50 ( 87.50)	Acc@5  93.75 ( 93.75)
Epoch: [3][20/86]	Time  0.143 ( 0.179)	Data  0.000 ( 0.028)	Loss 6.1810e-01 (5.3478e-01)	Acc@1  75.00 ( 84.82)	Acc@5  96.88 ( 97.17)
Epoch: [3][40/86]	Time  0.161 ( 0.170)	Data  0.000 ( 0.014)	Loss 6.9984e-01 (5.3301e-01)	Acc@1  75.00 ( 84.07)	Acc@5  93.75 ( 97.10)
Epoch: [3][60/86]	Time  0.144 ( 0.165)	Data  0.000 ( 0.010)	Loss 6.2705e-01 (5.4939e-01)	Acc@1  71.88 ( 83.04)	Acc@5 100.00 ( 97.13)
Epoch: [3][80/86]	Time  0.097 ( 0.161)	Data  0.000 ( 0.007)	Loss 6.6815e-01 (5.4376e-01)	Acc@1  81.25 ( 83.37)	Acc@5  96.88 ( 97.11)
learning rate is: 0.007807489599999998
Epoch: [4][ 0/86]	Time  0.768 ( 0.768)	Data  0.590 ( 0.590)	Loss 4.9582e-01 (4.9582e-01)	Acc@1  84.38 ( 84.38)	Acc@5 100.00 (100.00)
Epoch: [4][20/86]	Time  0.142 ( 0.172)	Data  0.000 ( 0.028)	Loss 7.0829e-01 (4.4497e-01)	Acc@1  81.25 ( 86.90)	Acc@5  93.75 ( 97.62)
Epoch: [4][40/86]	Time  0.213 ( 0.168)	Data  0.000 ( 0.015)	Loss 5.8082e-01 (4.5319e-01)	Acc@1  84.38 ( 86.89)	Acc@5  96.88 ( 97.64)
Epoch: [4][60/86]	Time  0.157 ( 0.160)	Data  0.000 ( 0.010)	Loss 5.1500e-01 (4.3572e-01)	Acc@1  93.75 ( 87.65)	Acc@5  93.75 ( 97.85)
Epoch: [4][80/86]	Time  0.098 ( 0.156)	Data  0.000 ( 0.007)	Loss 4.3593e-01 (4.4801e-01)	Acc@1  84.38 ( 86.84)	Acc@5  96.88 ( 97.65)
Test: [ 0/32]	Time  0.708 ( 0.708)	Loss 4.9919e-01 (4.9919e-01)	Acc@1  78.12 ( 78.12)	Acc@5  96.88 ( 96.88)
Test: [ 5/32]	Time  0.069 ( 0.201)	Loss 1.6474e-01 (1.4241e-01)	Acc@1  93.75 ( 94.27)	Acc@5 100.00 ( 99.48)
Test: [10/32]	Time  0.052 ( 0.153)	Loss 4.9339e-01 (1.9291e-01)	Acc@1  78.12 ( 92.33)	Acc@5 100.00 ( 99.72)
Test: [15/32]	Time  0.064 ( 0.136)	Loss 6.1262e-01 (2.5033e-01)	Acc@1  75.00 ( 91.02)	Acc@5  93.75 ( 99.22)
Test: [20/32]	Time  0.065 ( 0.128)	Loss 4.6342e-01 (2.7174e-01)	Acc@1  81.25 ( 90.62)	Acc@5  93.75 ( 98.81)
Test: [25/32]	Time  0.150 ( 0.129)	Loss 3.4757e-01 (2.9206e-01)	Acc@1  90.62 ( 90.14)	Acc@5 100.00 ( 98.68)
Test: [30/32]	Time  0.085 ( 0.126)	Loss 5.3837e-02 (2.8668e-01)	Acc@1 100.00 ( 90.93)	Acc@5 100.00 ( 98.59)