ssh://honglong@172.20.1.100:22/home/honglong/WP/source/anaconda3/envs/tensorflow/bin/python3.5 -u /home/honglong/WP/python/competition/huawei/xi_an/src_v2/main_F.py --data_url ../train_data/train_val --train_url ../wp_01 --deploy_script_path ./deploy_scripts --arch resnet50 --num_classes 54 --workers 0 --epochs 340 --pretrained True --seed 0 --b 64 --lr 0.01 --optim SGD --loss CE --decay_epoch 80 -p 5 --flash 10
Loaded pretrained weights for efficientnet-b1
/home/honglong/WP/python/competition/huawei/xi_an/src_v2/main_F.py:46: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
Loaded pretrained weights for efficientnet-b7
loss is: CE
optim is: SGD
learning rate is: 0.01
Epoch: [0][ 0/51]	Time 19.899 (19.899)	Data  0.901 ( 0.901)	Loss 4.0060e+00 (4.0060e+00)	Acc@1   1.56 (  1.56)	Acc@5   7.81 (  7.81)
Epoch: [0][10/51]	Time  1.242 ( 3.486)	Data  0.467 ( 0.781)	Loss 3.9049e+00 (3.9635e+00)	Acc@1  12.50 (  3.55)	Acc@5  23.44 ( 12.78)
Epoch: [0][20/51]	Time  1.431 ( 2.875)	Data  0.409 ( 0.969)	Loss 3.7473e+00 (3.8901e+00)	Acc@1  21.88 (  9.23)	Acc@5  42.19 ( 23.74)
Epoch: [0][30/51]	Time  3.095 ( 2.794)	Data  1.975 ( 1.174)	Loss 3.5143e+00 (3.7953e+00)	Acc@1  29.69 ( 16.38)	Acc@5  64.06 ( 35.23)
Epoch: [0][40/51]	Time  1.043 ( 2.426)	Data  0.489 ( 1.033)	Loss 3.2757e+00 (3.6786e+00)	Acc@1  50.00 ( 23.63)	Acc@5  76.56 ( 44.55)
Epoch: [0][50/51]	Time 11.791 ( 2.433)	Data  0.896 ( 0.986)	Loss 3.1915e+00 (3.5646e+00)	Acc@1  29.03 ( 28.47)	Acc@5  58.06 ( 50.91)
learning rate is: 0.01
Epoch: [1][ 0/51]	Time  4.448 ( 4.448)	Data  0.519 ( 0.519)	Loss 2.8863e+00 (2.8863e+00)	Acc@1  50.00 ( 50.00)	Acc@5  78.12 ( 78.12)
Epoch: [1][10/51]	Time  1.037 ( 1.840)	Data  0.501 ( 0.872)	Loss 2.4992e+00 (2.6789e+00)	Acc@1  54.69 ( 54.12)	Acc@5  84.38 ( 83.10)
Epoch: [1][20/51]	Time  3.334 ( 2.276)	Data  2.161 ( 1.280)	Loss 2.2502e+00 (2.5299e+00)	Acc@1  56.25 ( 56.18)	Acc@5  84.38 ( 84.82)
Epoch: [1][30/51]	Time  3.101 ( 2.541)	Data  2.057 ( 1.476)	Loss 1.9941e+00 (2.3761e+00)	Acc@1  53.12 ( 58.22)	Acc@5  82.81 ( 85.64)
Epoch: [1][40/51]	Time  2.652 ( 2.457)	Data  1.965 ( 1.460)	Loss 1.7283e+00 (2.2539e+00)	Acc@1  67.19 ( 59.37)	Acc@5  89.06 ( 85.94)
Epoch: [1][50/51]	Time  2.227 ( 2.388)	Data  0.998 ( 1.410)	Loss 2.0265e+00 (2.1383e+00)	Acc@1  64.52 ( 60.88)	Acc@5  80.65 ( 86.94)
learning rate is: 0.01
Epoch: [2][ 0/51]	Time  1.629 ( 1.629)	Data  0.580 ( 0.580)	Loss 1.7494e+00 (1.7494e+00)	Acc@1  56.25 ( 56.25)	Acc@5  85.94 ( 85.94)
Epoch: [2][10/51]	Time  1.044 ( 2.032)	Data  0.511 ( 1.227)	Loss 1.1965e+00 (1.4491e+00)	Acc@1  75.00 ( 68.18)	Acc@5  98.44 ( 92.76)
Epoch: [2][20/51]	Time  1.117 ( 1.831)	Data  0.499 ( 1.075)	Loss 1.1858e+00 (1.3176e+00)	Acc@1  71.88 ( 72.10)	Acc@5  85.94 ( 92.49)
Epoch: [2][30/51]	Time  1.150 ( 1.883)	Data  0.570 ( 1.100)	Loss 1.2702e+00 (1.2536e+00)	Acc@1  70.31 ( 73.59)	Acc@5  93.75 ( 92.84)
Epoch: [2][40/51]	Time  1.412 ( 1.911)	Data  0.601 ( 1.107)	Loss 1.0788e+00 (1.2017e+00)	Acc@1  76.56 ( 74.66)	Acc@5  93.75 ( 93.25)
Epoch: [2][50/51]	Time  0.676 ( 1.825)	Data  0.208 ( 1.043)	Loss 1.2229e+00 (1.1552e+00)	Acc@1  64.52 ( 75.12)	Acc@5  93.55 ( 93.62)
learning rate is: 0.01
Epoch: [3][ 0/51]	Time  1.002 ( 1.002)	Data  0.478 ( 0.478)	Loss 8.7884e-01 (8.7884e-01)	Acc@1  79.69 ( 79.69)	Acc@5  92.19 ( 92.19)
Epoch: [3][10/51]	Time  1.796 ( 1.211)	Data  1.257 ( 0.669)	Loss 9.2509e-01 (8.3962e-01)	Acc@1  76.56 ( 79.97)	Acc@5  89.06 ( 94.89)
Epoch: [3][20/51]	Time  1.521 ( 1.688)	Data  0.632 ( 0.996)	Loss 7.6771e-01 (8.0833e-01)	Acc@1  81.25 ( 80.65)	Acc@5  96.88 ( 95.61)
Epoch: [3][30/51]	Time  3.595 ( 1.858)	Data  2.630 ( 1.123)	Loss 5.3951e-01 (7.7835e-01)	Acc@1  90.62 ( 81.45)	Acc@5 100.00 ( 96.12)
Epoch: [3][40/51]	Time  1.203 ( 1.894)	Data  0.530 ( 1.141)	Loss 9.5994e-01 (7.9566e-01)	Acc@1  76.56 ( 81.06)	Acc@5  90.62 ( 95.50)
Epoch: [3][50/51]	Time  1.664 ( 1.947)	Data  0.742 ( 1.169)	Loss 1.1867e+00 (7.8568e-01)	Acc@1  67.74 ( 81.09)	Acc@5  90.32 ( 95.57)
learning rate is: 0.01
Epoch: [4][ 0/51]	Time  3.218 ( 3.218)	Data  1.997 ( 1.997)	Loss 5.4278e-01 (5.4278e-01)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
Epoch: [4][10/51]	Time  3.418 ( 2.328)	Data  2.312 ( 1.425)	Loss 5.2737e-01 (6.4527e-01)	Acc@1  85.94 ( 84.09)	Acc@5 100.00 ( 97.30)
Epoch: [4][20/51]	Time  1.169 ( 2.571)	Data  0.589 ( 1.613)	Loss 5.4048e-01 (6.1569e-01)	Acc@1  82.81 ( 84.90)	Acc@5 100.00 ( 97.47)
Epoch: [4][30/51]	Time  2.704 ( 2.611)	Data  1.597 ( 1.643)	Loss 3.1399e-01 (6.0774e-01)	Acc@1  92.19 ( 85.43)	Acc@5  98.44 ( 97.28)
Epoch: [4][40/51]	Time  2.929 ( 2.533)	Data  1.674 ( 1.579)	Loss 7.1388e-01 (6.1814e-01)	Acc@1  81.25 ( 85.18)	Acc@5  96.88 ( 96.88)
Epoch: [4][50/51]	Time  0.877 ( 2.424)	Data  0.245 ( 1.464)	Loss 8.4784e-01 (6.1251e-01)	Acc@1  70.97 ( 85.17)	Acc@5  96.77 ( 97.00)
Test: [0/8]	Time  1.285 ( 1.285)	Loss 4.0132e-01 (4.0132e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.625 ( 2.435)	Loss 6.8593e-01 (4.6804e-01)	Acc@1  84.38 ( 89.32)	Acc@5  98.44 ( 99.74)
 * Acc@1 90.600 Acc@5 99.800
learning rate is: 0.01
Epoch: [5][ 0/51]	Time  6.638 ( 6.638)	Data  1.703 ( 1.703)	Loss 4.6414e-01 (4.6414e-01)	Acc@1  84.38 ( 84.38)	Acc@5  98.44 ( 98.44)
Epoch: [5][10/51]	Time  1.246 ( 2.763)	Data  0.630 ( 1.473)	Loss 6.9229e-01 (5.7990e-01)	Acc@1  84.38 ( 83.66)	Acc@5  96.88 ( 97.73)
Epoch: [5][20/51]	Time  1.130 ( 2.192)	Data  0.578 ( 1.197)	Loss 2.7136e-01 (5.3018e-01)	Acc@1 100.00 ( 85.94)	Acc@5 100.00 ( 98.21)
Epoch: [5][30/51]	Time  1.350 ( 1.865)	Data  0.815 ( 1.015)	Loss 4.8569e-01 (5.0894e-01)	Acc@1  89.06 ( 86.69)	Acc@5 100.00 ( 98.39)
Epoch: [5][40/51]	Time  1.253 ( 1.887)	Data  0.451 ( 1.049)	Loss 5.5137e-01 (5.0786e-01)	Acc@1  82.81 ( 86.36)	Acc@5  96.88 ( 98.06)
Epoch: [5][50/51]	Time  1.021 ( 1.848)	Data  0.324 ( 1.036)	Loss 8.5435e-01 (4.9776e-01)	Acc@1  74.19 ( 86.47)	Acc@5  90.32 ( 98.14)
learning rate is: 0.01
Epoch: [6][ 0/51]	Time  1.655 ( 1.655)	Data  0.667 ( 0.667)	Loss 3.3944e-01 (3.3944e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [6][10/51]	Time  1.437 ( 1.491)	Data  0.911 ( 0.824)	Loss 6.7679e-01 (4.3075e-01)	Acc@1  82.81 ( 88.64)	Acc@5  96.88 ( 98.01)
Epoch: [6][20/51]	Time  1.301 ( 1.374)	Data  0.571 ( 0.720)	Loss 6.6246e-01 (4.4416e-01)	Acc@1  82.81 ( 88.24)	Acc@5  95.31 ( 97.92)
Epoch: [6][30/51]	Time  2.062 ( 1.687)	Data  1.015 ( 0.912)	Loss 2.9332e-01 (4.2063e-01)	Acc@1  93.75 ( 89.01)	Acc@5  98.44 ( 98.24)
Epoch: [6][40/51]	Time  3.018 ( 1.778)	Data  1.797 ( 0.959)	Loss 3.5212e-01 (4.2261e-01)	Acc@1  92.19 ( 89.18)	Acc@5  98.44 ( 98.02)
Epoch: [6][50/51]	Time  0.875 ( 1.903)	Data  0.253 ( 1.030)	Loss 6.5283e-01 (4.3475e-01)	Acc@1  77.42 ( 88.61)	Acc@5 100.00 ( 97.90)
learning rate is: 0.01
Epoch: [7][ 0/51]	Time  2.122 ( 2.122)	Data  1.117 ( 1.117)	Loss 4.0418e-01 (4.0418e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [7][10/51]	Time  1.516 ( 1.816)	Data  0.758 ( 0.888)	Loss 4.1663e-01 (4.0399e-01)	Acc@1  89.06 ( 88.64)	Acc@5 100.00 ( 98.15)
Epoch: [7][20/51]	Time  3.351 ( 1.809)	Data  1.990 ( 0.864)	Loss 6.1640e-01 (3.8819e-01)	Acc@1  76.56 ( 89.43)	Acc@5  95.31 ( 98.21)
Epoch: [7][30/51]	Time  3.168 ( 2.306)	Data  1.916 ( 1.249)	Loss 4.5851e-01 (3.9178e-01)	Acc@1  87.50 ( 89.57)	Acc@5 100.00 ( 98.34)
Epoch: [7][40/51]	Time  1.182 ( 2.073)	Data  0.549 ( 1.096)	Loss 2.7309e-01 (3.8017e-01)	Acc@1  92.19 ( 89.63)	Acc@5  98.44 ( 98.40)
Epoch: [7][50/51]	Time  1.656 ( 2.181)	Data  0.624 ( 1.182)	Loss 3.6367e-01 (3.7834e-01)	Acc@1  90.32 ( 89.85)	Acc@5 100.00 ( 98.36)
learning rate is: 0.01
Epoch: [8][ 0/51]	Time  2.912 ( 2.912)	Data  1.752 ( 1.752)	Loss 3.6086e-01 (3.6086e-01)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Epoch: [8][10/51]	Time  2.914 ( 2.221)	Data  1.857 ( 1.322)	Loss 3.3595e-01 (3.2818e-01)	Acc@1  92.19 ( 91.05)	Acc@5  98.44 ( 98.58)
Epoch: [8][20/51]	Time  1.160 ( 1.960)	Data  0.566 ( 1.119)	Loss 4.3152e-01 (3.6176e-01)	Acc@1  87.50 ( 89.81)	Acc@5  96.88 ( 98.66)
Epoch: [8][30/51]	Time  3.184 ( 1.978)	Data  1.884 ( 1.137)	Loss 3.2796e-01 (3.6132e-01)	Acc@1  92.19 ( 90.12)	Acc@5  98.44 ( 98.54)
Epoch: [8][40/51]	Time  3.316 ( 2.222)	Data  2.253 ( 1.311)	Loss 2.7380e-01 (3.6083e-01)	Acc@1  89.06 ( 90.17)	Acc@5  98.44 ( 98.55)
Epoch: [8][50/51]	Time  0.712 ( 2.177)	Data  0.243 ( 1.296)	Loss 3.4636e-01 (3.6300e-01)	Acc@1  96.77 ( 90.22)	Acc@5  96.77 ( 98.48)
learning rate is: 0.01
Epoch: [9][ 0/51]	Time  1.021 ( 1.021)	Data  0.484 ( 0.484)	Loss 2.0311e-01 (2.0311e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [9][10/51]	Time  2.766 ( 2.214)	Data  1.839 ( 1.309)	Loss 1.2175e-01 (3.1933e-01)	Acc@1  98.44 ( 90.91)	Acc@5 100.00 ( 99.15)
Epoch: [9][20/51]	Time  3.053 ( 2.497)	Data  1.910 ( 1.521)	Loss 1.8218e-01 (3.0106e-01)	Acc@1  95.31 ( 91.89)	Acc@5 100.00 ( 98.96)
Epoch: [9][30/51]	Time  2.578 ( 2.558)	Data  1.551 ( 1.579)	Loss 4.6884e-01 (3.0461e-01)	Acc@1  87.50 ( 92.19)	Acc@5  95.31 ( 98.74)
Epoch: [9][40/51]	Time  2.838 ( 2.624)	Data  2.093 ( 1.627)	Loss 3.9783e-01 (3.0776e-01)	Acc@1  85.94 ( 92.07)	Acc@5 100.00 ( 98.82)
Epoch: [9][50/51]	Time  0.775 ( 2.398)	Data  0.247 ( 1.460)	Loss 6.7891e-01 (3.1582e-01)	Acc@1  83.87 ( 91.83)	Acc@5  96.77 ( 98.67)
Test: [0/8]	Time  3.080 ( 3.080)	Loss 2.9059e-01 (2.9059e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  1.114 ( 1.312)	Loss 4.7727e-01 (3.0887e-01)	Acc@1  90.62 ( 92.19)	Acc@5  98.44 ( 99.74)
 * Acc@1 92.800 Acc@5 99.800
learning rate is: 0.01
Epoch: [10][ 0/51]	Time  1.120 ( 1.120)	Data  0.612 ( 0.612)	Loss 4.0444e-01 (4.0444e-01)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
Epoch: [10][10/51]	Time  1.159 ( 1.274)	Data  0.623 ( 0.692)	Loss 2.7115e-01 (3.1879e-01)	Acc@1  90.62 ( 90.20)	Acc@5 100.00 ( 98.58)
Epoch: [10][20/51]	Time  1.102 ( 1.195)	Data  0.533 ( 0.627)	Loss 2.4759e-01 (3.0003e-01)	Acc@1  92.19 ( 91.59)	Acc@5 100.00 ( 98.36)
Epoch: [10][30/51]	Time  3.160 ( 1.438)	Data  1.898 ( 0.796)	Loss 2.7799e-01 (2.9814e-01)	Acc@1  92.19 ( 91.83)	Acc@5 100.00 ( 98.64)
Epoch: [10][40/51]	Time  2.833 ( 1.624)	Data  1.936 ( 0.936)	Loss 3.3282e-01 (2.9780e-01)	Acc@1  93.75 ( 92.23)	Acc@5 100.00 ( 98.59)
Epoch: [10][50/51]	Time  0.995 ( 1.813)	Data  0.521 ( 1.075)	Loss 6.0829e-01 (2.8738e-01)	Acc@1  74.19 ( 92.39)	Acc@5  96.77 ( 98.70)
learning rate is: 0.01
Epoch: [11][ 0/51]	Time  1.463 ( 1.463)	Data  0.814 ( 0.814)	Loss 1.2547e-01 (1.2547e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [11][10/51]	Time  3.028 ( 2.794)	Data  2.126 ( 1.826)	Loss 2.8449e-01 (2.3345e-01)	Acc@1  89.06 ( 93.47)	Acc@5  98.44 ( 99.43)
Epoch: [11][20/51]	Time  2.877 ( 2.830)	Data  1.864 ( 1.854)	Loss 2.4398e-01 (2.3357e-01)	Acc@1  95.31 ( 93.38)	Acc@5  98.44 ( 99.40)
Epoch: [11][30/51]	Time  3.428 ( 2.558)	Data  2.305 ( 1.647)	Loss 4.2736e-01 (2.3874e-01)	Acc@1  89.06 ( 93.65)	Acc@5 100.00 ( 99.24)
Epoch: [11][40/51]	Time  2.978 ( 2.626)	Data  1.844 ( 1.678)	Loss 3.0524e-01 (2.3738e-01)	Acc@1  93.75 ( 93.86)	Acc@5  98.44 ( 99.20)
Epoch: [11][50/51]	Time  2.335 ( 2.589)	Data  1.190 ( 1.650)	Loss 5.9100e-01 (2.3974e-01)	Acc@1  83.87 ( 93.84)	Acc@5  96.77 ( 99.07)
learning rate is: 0.01
Epoch: [12][ 0/51]	Time  2.993 ( 2.993)	Data  1.914 ( 1.914)	Loss 1.2332e-01 (1.2332e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [12][10/51]	Time  2.650 ( 2.765)	Data  1.787 ( 1.714)	Loss 1.7849e-01 (2.1351e-01)	Acc@1  95.31 ( 94.18)	Acc@5 100.00 ( 99.57)
Epoch: [12][20/51]	Time  2.711 ( 2.396)	Data  1.760 ( 1.426)	Loss 1.1117e-01 (2.1940e-01)	Acc@1  98.44 ( 94.12)	Acc@5 100.00 ( 99.40)
Epoch: [12][30/51]	Time  1.196 ( 2.125)	Data  0.614 ( 1.258)	Loss 3.9444e-01 (2.4499e-01)	Acc@1  92.19 ( 93.40)	Acc@5  96.88 ( 98.94)
Epoch: [12][40/51]	Time  1.533 ( 1.940)	Data  0.931 ( 1.138)	Loss 2.6263e-01 (2.4170e-01)	Acc@1  93.75 ( 93.37)	Acc@5  98.44 ( 98.86)
Epoch: [12][50/51]	Time  1.119 ( 1.955)	Data  0.378 ( 1.148)	Loss 1.4040e-01 (2.4826e-01)	Acc@1 100.00 ( 93.41)	Acc@5 100.00 ( 98.79)
learning rate is: 0.01
Epoch: [13][ 0/51]	Time  1.470 ( 1.470)	Data  0.944 ( 0.944)	Loss 2.0628e-01 (2.0628e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [13][10/51]	Time  2.599 ( 2.652)	Data  1.612 ( 1.668)	Loss 1.2832e-01 (2.1888e-01)	Acc@1  96.88 ( 94.32)	Acc@5 100.00 ( 98.86)
Epoch: [13][20/51]	Time  1.508 ( 2.230)	Data  0.958 ( 1.342)	Loss 2.6386e-01 (2.1376e-01)	Acc@1  93.75 ( 94.72)	Acc@5  98.44 ( 98.74)
Epoch: [13][30/51]	Time  2.843 ( 2.087)	Data  2.278 ( 1.261)	Loss 2.2880e-01 (2.2863e-01)	Acc@1  95.31 ( 94.30)	Acc@5 100.00 ( 98.69)
Epoch: [13][40/51]	Time  1.122 ( 2.050)	Data  0.592 ( 1.232)	Loss 1.0119e-01 (2.1414e-01)	Acc@1  98.44 ( 94.59)	Acc@5 100.00 ( 98.78)
Epoch: [13][50/51]	Time  0.848 ( 1.872)	Data  0.229 ( 1.101)	Loss 1.3658e-01 (2.1410e-01)	Acc@1 100.00 ( 94.58)	Acc@5 100.00 ( 98.82)
learning rate is: 0.01
Epoch: [14][ 0/51]	Time  1.177 ( 1.177)	Data  0.605 ( 0.605)	Loss 2.3763e-01 (2.3763e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [14][10/51]	Time  1.377 ( 1.259)	Data  0.524 ( 0.606)	Loss 1.5426e-01 (2.2106e-01)	Acc@1  95.31 ( 94.60)	Acc@5 100.00 ( 99.01)
Epoch: [14][20/51]	Time  1.345 ( 1.272)	Data  0.555 ( 0.599)	Loss 1.0298e-01 (2.3461e-01)	Acc@1  96.88 ( 94.42)	Acc@5 100.00 ( 98.59)
Epoch: [14][30/51]	Time  2.786 ( 1.585)	Data  1.535 ( 0.839)	Loss 1.3221e-01 (2.2261e-01)	Acc@1  98.44 ( 94.66)	Acc@5 100.00 ( 98.79)
Epoch: [14][40/51]	Time  1.340 ( 1.692)	Data  0.574 ( 0.897)	Loss 1.7401e-01 (2.2799e-01)	Acc@1  96.88 ( 94.47)	Acc@5 100.00 ( 98.74)
Epoch: [14][50/51]	Time  1.032 ( 1.627)	Data  0.401 ( 0.839)	Loss 2.6611e-01 (2.3553e-01)	Acc@1  90.32 ( 94.31)	Acc@5 100.00 ( 98.85)
Test: [0/8]	Time  0.836 ( 0.836)	Loss 2.5060e-01 (2.5060e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.784 ( 0.869)	Loss 3.7206e-01 (2.6784e-01)	Acc@1  90.62 ( 93.49)	Acc@5  98.44 ( 99.48)
 * Acc@1 94.200 Acc@5 99.600
learning rate is: 0.01
Epoch: [15][ 0/51]	Time  2.504 ( 2.504)	Data  1.786 ( 1.786)	Loss 1.6719e-01 (1.6719e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [15][10/51]	Time  3.313 ( 2.521)	Data  2.388 ( 1.580)	Loss 1.3926e-01 (1.8934e-01)	Acc@1  96.88 ( 95.17)	Acc@5 100.00 ( 99.43)
Epoch: [15][20/51]	Time  1.774 ( 2.453)	Data  1.037 ( 1.528)	Loss 2.3408e-01 (2.0078e-01)	Acc@1  95.31 ( 94.72)	Acc@5  98.44 ( 99.11)
Epoch: [15][30/51]	Time  2.967 ( 2.445)	Data  1.937 ( 1.519)	Loss 1.7579e-01 (2.1453e-01)	Acc@1  98.44 ( 94.15)	Acc@5 100.00 ( 99.09)
Epoch: [15][40/51]	Time  3.008 ( 2.535)	Data  1.976 ( 1.598)	Loss 2.1259e-01 (2.1896e-01)	Acc@1  93.75 ( 94.17)	Acc@5  98.44 ( 99.12)
Epoch: [15][50/51]	Time  1.241 ( 2.539)	Data  0.298 ( 1.582)	Loss 4.2509e-01 (2.1337e-01)	Acc@1  90.32 ( 94.21)	Acc@5  96.77 ( 99.16)
learning rate is: 0.01
Epoch: [16][ 0/51]	Time  1.847 ( 1.847)	Data  0.786 ( 0.786)	Loss 1.7177e-01 (1.7177e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [16][10/51]	Time  1.127 ( 1.452)	Data  0.601 ( 0.725)	Loss 2.1802e-01 (1.5725e-01)	Acc@1  92.19 ( 96.16)	Acc@5  98.44 ( 99.57)
Epoch: [16][20/51]	Time  1.037 ( 1.310)	Data  0.474 ( 0.657)	Loss 2.6504e-01 (1.7960e-01)	Acc@1  92.19 ( 95.24)	Acc@5 100.00 ( 99.48)
Epoch: [16][30/51]	Time  1.290 ( 1.333)	Data  0.477 ( 0.681)	Loss 2.2241e-01 (1.9005e-01)	Acc@1  95.31 ( 95.01)	Acc@5 100.00 ( 99.45)
Epoch: [16][40/51]	Time  2.716 ( 1.484)	Data  1.767 ( 0.786)	Loss 1.2008e-01 (1.9776e-01)	Acc@1  95.31 ( 94.70)	Acc@5 100.00 ( 99.35)
Epoch: [16][50/51]	Time  0.936 ( 1.651)	Data  0.460 ( 0.911)	Loss 3.6359e-01 (1.9483e-01)	Acc@1  87.10 ( 94.58)	Acc@5 100.00 ( 99.41)
learning rate is: 0.01
Epoch: [17][ 0/51]	Time  1.914 ( 1.914)	Data  0.778 ( 0.778)	Loss 2.7610e-01 (2.7610e-01)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [17][10/51]	Time  1.171 ( 1.826)	Data  0.426 ( 1.030)	Loss 1.5578e-01 (1.8347e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.29)
Epoch: [17][20/51]	Time  2.994 ( 2.033)	Data  1.957 ( 1.194)	Loss 6.0662e-02 (1.7060e-01)	Acc@1 100.00 ( 95.76)	Acc@5 100.00 ( 99.33)
Epoch: [17][30/51]	Time  2.868 ( 2.151)	Data  2.138 ( 1.274)	Loss 1.3472e-01 (1.7608e-01)	Acc@1  98.44 ( 95.56)	Acc@5 100.00 ( 99.24)
Epoch: [17][40/51]	Time  2.130 ( 1.989)	Data  1.330 ( 1.153)	Loss 9.3408e-02 (1.8272e-01)	Acc@1  98.44 ( 95.35)	Acc@5 100.00 ( 99.20)
Epoch: [17][50/51]	Time  0.812 ( 1.900)	Data  0.344 ( 1.105)	Loss 1.2230e-01 (1.8724e-01)	Acc@1 100.00 ( 95.30)	Acc@5 100.00 ( 99.16)
learning rate is: 0.01
Epoch: [18][ 0/51]	Time  1.613 ( 1.613)	Data  1.035 ( 1.035)	Loss 2.9721e-01 (2.9721e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [18][10/51]	Time  2.684 ( 1.783)	Data  2.021 ( 1.096)	Loss 1.5025e-01 (1.9214e-01)	Acc@1  96.88 ( 95.31)	Acc@5  98.44 ( 98.72)
Epoch: [18][20/51]	Time  3.480 ( 2.121)	Data  2.266 ( 1.251)	Loss 1.3080e-01 (1.7388e-01)	Acc@1  98.44 ( 95.83)	Acc@5 100.00 ( 99.11)
Epoch: [18][30/51]	Time  1.130 ( 2.088)	Data  0.443 ( 1.201)	Loss 1.5406e-01 (1.8693e-01)	Acc@1  96.88 ( 95.21)	Acc@5 100.00 ( 98.99)
Epoch: [18][40/51]	Time  3.595 ( 2.140)	Data  2.211 ( 1.220)	Loss 1.7501e-01 (1.8634e-01)	Acc@1  95.31 ( 95.24)	Acc@5 100.00 ( 99.12)
Epoch: [18][50/51]	Time  2.061 ( 2.135)	Data  0.983 ( 1.213)	Loss 1.3212e-01 (1.8007e-01)	Acc@1 100.00 ( 95.39)	Acc@5 100.00 ( 99.16)
learning rate is: 0.01
Epoch: [19][ 0/51]	Time  3.208 ( 3.208)	Data  1.943 ( 1.943)	Loss 2.5276e-01 (2.5276e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [19][10/51]	Time  1.566 ( 2.011)	Data  0.653 ( 1.139)	Loss 1.7083e-01 (1.6413e-01)	Acc@1  93.75 ( 95.31)	Acc@5 100.00 ( 99.43)
Epoch: [19][20/51]	Time  0.987 ( 1.655)	Data  0.419 ( 0.900)	Loss 2.6536e-01 (1.5941e-01)	Acc@1  95.31 ( 95.68)	Acc@5  98.44 ( 99.55)
Epoch: [19][30/51]	Time  1.052 ( 1.851)	Data  0.515 ( 1.059)	Loss 7.3032e-02 (1.7659e-01)	Acc@1 100.00 ( 95.21)	Acc@5 100.00 ( 99.40)
Epoch: [19][40/51]	Time  1.095 ( 1.803)	Data  0.516 ( 1.035)	Loss 5.8093e-02 (1.6794e-01)	Acc@1  98.44 ( 95.43)	Acc@5 100.00 ( 99.39)
Epoch: [19][50/51]	Time  0.734 ( 1.668)	Data  0.230 ( 0.943)	Loss 1.3680e-01 (1.6591e-01)	Acc@1 100.00 ( 95.48)	Acc@5 100.00 ( 99.44)
Test: [0/8]	Time  1.110 ( 1.110)	Loss 1.9033e-01 (1.9033e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.869 ( 1.515)	Loss 3.0086e-01 (2.3648e-01)	Acc@1  90.62 ( 94.27)	Acc@5  98.44 ( 99.22)
 * Acc@1 94.400 Acc@5 99.400
learning rate is: 0.01
Epoch: [20][ 0/51]	Time  1.252 ( 1.252)	Data  0.691 ( 0.691)	Loss 7.1144e-02 (7.1144e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [20][10/51]	Time  1.000 ( 1.796)	Data  0.451 ( 1.080)	Loss 9.9022e-02 (1.1563e-01)	Acc@1  98.44 ( 97.16)	Acc@5 100.00 ( 99.57)
Epoch: [20][20/51]	Time  1.196 ( 2.121)	Data  0.596 ( 1.286)	Loss 1.0891e-01 (1.4180e-01)	Acc@1  96.88 ( 96.28)	Acc@5 100.00 ( 99.40)
Epoch: [20][30/51]	Time  0.995 ( 1.808)	Data  0.468 ( 1.064)	Loss 1.3856e-01 (1.4560e-01)	Acc@1  96.88 ( 96.27)	Acc@5 100.00 ( 99.34)
Epoch: [20][40/51]	Time  2.849 ( 1.999)	Data  1.831 ( 1.192)	Loss 1.9347e-01 (1.4426e-01)	Acc@1  95.31 ( 96.34)	Acc@5 100.00 ( 99.31)
Epoch: [20][50/51]	Time  0.868 ( 1.972)	Data  0.231 ( 1.167)	Loss 2.6656e-01 (1.6188e-01)	Acc@1  93.55 ( 95.67)	Acc@5 100.00 ( 99.20)
learning rate is: 0.01
Epoch: [21][ 0/51]	Time  1.261 ( 1.261)	Data  0.595 ( 0.595)	Loss 8.1672e-02 (8.1672e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [21][10/51]	Time  2.635 ( 1.755)	Data  1.695 ( 1.002)	Loss 2.5029e-01 (1.9079e-01)	Acc@1  92.19 ( 95.17)	Acc@5  95.31 ( 98.30)
Epoch: [21][20/51]	Time  3.102 ( 2.156)	Data  2.049 ( 1.279)	Loss 2.0978e-01 (1.7390e-01)	Acc@1  95.31 ( 95.61)	Acc@5 100.00 ( 98.74)
Epoch: [21][30/51]	Time  1.248 ( 2.002)	Data  0.498 ( 1.176)	Loss 3.4198e-01 (1.6240e-01)	Acc@1  92.19 ( 95.92)	Acc@5  96.88 ( 98.89)
Epoch: [21][40/51]	Time  2.892 ( 2.210)	Data  1.802 ( 1.321)	Loss 1.5223e-01 (1.5996e-01)	Acc@1  96.88 ( 96.04)	Acc@5  98.44 ( 98.97)
Epoch: [21][50/51]	Time  1.662 ( 2.127)	Data  0.826 ( 1.268)	Loss 3.3614e-01 (1.5723e-01)	Acc@1  93.55 ( 96.13)	Acc@5  96.77 ( 99.07)
learning rate is: 0.01
Epoch: [22][ 0/51]	Time  2.422 ( 2.422)	Data  1.623 ( 1.623)	Loss 8.7229e-02 (8.7229e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [22][10/51]	Time  2.991 ( 2.284)	Data  1.993 ( 1.464)	Loss 1.7779e-01 (1.4390e-01)	Acc@1  95.31 ( 95.88)	Acc@5  98.44 ( 99.15)
Epoch: [22][20/51]	Time  1.311 ( 1.867)	Data  0.768 ( 1.134)	Loss 1.6383e-01 (1.5838e-01)	Acc@1  95.31 ( 95.91)	Acc@5  98.44 ( 99.26)
Epoch: [22][30/51]	Time  1.021 ( 1.696)	Data  0.484 ( 0.986)	Loss 1.7908e-01 (1.6648e-01)	Acc@1  95.31 ( 95.77)	Acc@5  96.88 ( 98.94)
Epoch: [22][40/51]	Time  1.078 ( 1.820)	Data  0.445 ( 1.042)	Loss 1.9321e-01 (1.7154e-01)	Acc@1  93.75 ( 95.54)	Acc@5  98.44 ( 98.97)
Epoch: [22][50/51]	Time  0.883 ( 1.733)	Data  0.403 ( 0.985)	Loss 4.7114e-01 (1.6828e-01)	Acc@1  87.10 ( 95.61)	Acc@5  93.55 ( 98.92)
learning rate is: 0.01
Epoch: [23][ 0/51]	Time  1.046 ( 1.046)	Data  0.506 ( 0.506)	Loss 1.5314e-01 (1.5314e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [23][10/51]	Time  1.400 ( 1.343)	Data  0.626 ( 0.567)	Loss 1.1964e-01 (1.3943e-01)	Acc@1  96.88 ( 97.02)	Acc@5 100.00 ( 99.29)
Epoch: [23][20/51]	Time  1.543 ( 2.014)	Data  0.528 ( 1.040)	Loss 2.6206e-01 (1.5688e-01)	Acc@1  95.31 ( 96.58)	Acc@5 100.00 ( 99.11)
Epoch: [23][30/51]	Time  2.910 ( 2.176)	Data  1.890 ( 1.180)	Loss 4.8200e-02 (1.5567e-01)	Acc@1  98.44 ( 96.27)	Acc@5 100.00 ( 99.19)
Epoch: [23][40/51]	Time  2.735 ( 2.327)	Data  1.609 ( 1.308)	Loss 5.6073e-02 (1.4347e-01)	Acc@1 100.00 ( 96.49)	Acc@5 100.00 ( 99.28)
Epoch: [23][50/51]	Time  2.026 ( 2.282)	Data  1.060 ( 1.286)	Loss 1.6626e-01 (1.4019e-01)	Acc@1 100.00 ( 96.53)	Acc@5 100.00 ( 99.38)
learning rate is: 0.01
Epoch: [24][ 0/51]	Time  3.005 ( 3.005)	Data  2.045 ( 2.045)	Loss 1.9941e-01 (1.9941e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [24][10/51]	Time  1.499 ( 1.569)	Data  0.934 ( 0.913)	Loss 1.0208e-01 (1.4960e-01)	Acc@1  95.31 ( 96.16)	Acc@5 100.00 ( 99.01)
Epoch: [24][20/51]	Time  1.186 ( 1.391)	Data  0.668 ( 0.773)	Loss 1.1220e-01 (1.2675e-01)	Acc@1  98.44 ( 96.43)	Acc@5  98.44 ( 99.40)
Epoch: [24][30/51]	Time  2.825 ( 1.616)	Data  1.669 ( 0.921)	Loss 8.3752e-02 (1.1464e-01)	Acc@1  96.88 ( 96.82)	Acc@5 100.00 ( 99.50)
Epoch: [24][40/51]	Time  1.085 ( 1.566)	Data  0.555 ( 0.886)	Loss 1.5798e-01 (1.2257e-01)	Acc@1  98.44 ( 96.80)	Acc@5  98.44 ( 99.50)
Epoch: [24][50/51]	Time  0.691 ( 1.519)	Data  0.212 ( 0.852)	Loss 1.1782e-01 (1.2664e-01)	Acc@1 100.00 ( 96.87)	Acc@5 100.00 ( 99.41)
Test: [0/8]	Time  0.882 ( 0.882)	Loss 1.9383e-01 (1.9383e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.735 ( 0.829)	Loss 3.6868e-01 (2.3735e-01)	Acc@1  92.19 ( 94.27)	Acc@5  98.44 ( 99.74)
 * Acc@1 94.600 Acc@5 99.800
learning rate is: 0.01
Epoch: [25][ 0/51]	Time  1.158 ( 1.158)	Data  0.594 ( 0.594)	Loss 1.3597e-01 (1.3597e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [25][10/51]	Time  1.121 ( 1.618)	Data  0.478 ( 0.787)	Loss 9.9255e-02 (1.1978e-01)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 99.29)
Epoch: [25][20/51]	Time  1.240 ( 1.444)	Data  0.389 ( 0.647)	Loss 1.8497e-01 (1.2548e-01)	Acc@1  95.31 ( 96.35)	Acc@5  96.88 ( 99.33)
Epoch: [25][30/51]	Time  2.726 ( 1.947)	Data  1.699 ( 1.021)	Loss 9.6039e-02 (1.3064e-01)	Acc@1  96.88 ( 96.17)	Acc@5  98.44 ( 99.24)
Epoch: [25][40/51]	Time  1.590 ( 2.090)	Data  0.710 ( 1.148)	Loss 1.8116e-01 (1.2747e-01)	Acc@1  93.75 ( 96.34)	Acc@5  98.44 ( 99.28)
Epoch: [25][50/51]	Time  2.029 ( 2.199)	Data  0.824 ( 1.219)	Loss 1.7792e-01 (1.2429e-01)	Acc@1  93.55 ( 96.38)	Acc@5 100.00 ( 99.38)
learning rate is: 0.01
Epoch: [26][ 0/51]	Time  3.262 ( 3.262)	Data  2.233 ( 2.233)	Loss 1.4241e-01 (1.4241e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [26][10/51]	Time  2.998 ( 2.493)	Data  1.863 ( 1.420)	Loss 2.7303e-02 (1.1523e-01)	Acc@1 100.00 ( 97.02)	Acc@5 100.00 ( 99.29)
Epoch: [26][20/51]	Time  3.135 ( 2.268)	Data  2.181 ( 1.260)	Loss 1.4628e-01 (1.2512e-01)	Acc@1  93.75 ( 96.58)	Acc@5 100.00 ( 99.18)
Epoch: [26][30/51]	Time  3.167 ( 2.450)	Data  1.986 ( 1.404)	Loss 1.5979e-01 (1.2172e-01)	Acc@1  95.31 ( 96.82)	Acc@5  98.44 ( 99.24)
Epoch: [26][40/51]	Time  2.999 ( 2.415)	Data  1.771 ( 1.364)	Loss 4.4307e-02 (1.2698e-01)	Acc@1  98.44 ( 96.53)	Acc@5 100.00 ( 99.20)
Epoch: [26][50/51]	Time  1.294 ( 2.465)	Data  0.337 ( 1.406)	Loss 1.3386e-01 (1.2757e-01)	Acc@1  93.55 ( 96.53)	Acc@5 100.00 ( 99.26)
learning rate is: 0.01
Epoch: [27][ 0/51]	Time  1.566 ( 1.566)	Data  0.483 ( 0.483)	Loss 1.9068e-01 (1.9068e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [27][10/51]	Time  3.172 ( 3.037)	Data  1.900 ( 1.796)	Loss 9.6585e-02 (1.4486e-01)	Acc@1  96.88 ( 95.88)	Acc@5 100.00 ( 99.29)
Epoch: [27][20/51]	Time  3.200 ( 3.054)	Data  1.731 ( 1.797)	Loss 2.3516e-01 (1.5291e-01)	Acc@1  92.19 ( 95.68)	Acc@5 100.00 ( 99.33)
Epoch: [27][30/51]	Time  3.022 ( 2.989)	Data  1.747 ( 1.765)	Loss 1.6462e-01 (1.5536e-01)	Acc@1  93.75 ( 95.67)	Acc@5  98.44 ( 99.24)
Epoch: [27][40/51]	Time  1.431 ( 2.949)	Data  0.669 ( 1.739)	Loss 3.4297e-02 (1.3966e-01)	Acc@1 100.00 ( 96.04)	Acc@5 100.00 ( 99.35)
Epoch: [27][50/51]	Time  1.011 ( 2.710)	Data  0.233 ( 1.558)	Loss 3.2486e-01 (1.3440e-01)	Acc@1  90.32 ( 96.07)	Acc@5  96.77 ( 99.41)
learning rate is: 0.01
Epoch: [28][ 0/51]	Time  1.748 ( 1.748)	Data  0.883 ( 0.883)	Loss 8.1094e-02 (8.1094e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [28][10/51]	Time  1.347 ( 1.537)	Data  0.573 ( 0.711)	Loss 1.3259e-01 (1.0439e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 ( 99.57)
Epoch: [28][20/51]	Time  3.425 ( 1.998)	Data  2.025 ( 1.037)	Loss 7.8533e-02 (1.1684e-01)	Acc@1  95.31 ( 96.80)	Acc@5 100.00 ( 99.55)
Epoch: [28][30/51]	Time  2.799 ( 2.255)	Data  1.614 ( 1.211)	Loss 1.8541e-01 (1.1668e-01)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 99.65)
Epoch: [28][40/51]	Time  1.280 ( 2.444)	Data  0.590 ( 1.358)	Loss 1.6079e-02 (1.1707e-01)	Acc@1 100.00 ( 96.76)	Acc@5 100.00 ( 99.66)
Epoch: [28][50/51]	Time  2.263 ( 2.342)	Data  0.979 ( 1.301)	Loss 4.8034e-01 (1.1854e-01)	Acc@1  83.87 ( 96.66)	Acc@5  96.77 ( 99.60)
learning rate is: 0.01
Epoch: [29][ 0/51]	Time  3.113 ( 3.113)	Data  1.910 ( 1.910)	Loss 1.5712e-01 (1.5712e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [29][10/51]	Time  1.505 ( 2.772)	Data  0.597 ( 1.730)	Loss 9.5552e-02 (1.1937e-01)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.57)
Epoch: [29][20/51]	Time  1.175 ( 2.188)	Data  0.568 ( 1.277)	Loss 2.5062e-02 (9.4058e-02)	Acc@1  98.44 ( 97.77)	Acc@5 100.00 ( 99.63)
Epoch: [29][30/51]	Time  2.979 ( 2.060)	Data  1.895 ( 1.185)	Loss 1.4050e-01 (1.0622e-01)	Acc@1  96.88 ( 97.38)	Acc@5  98.44 ( 99.55)
Epoch: [29][40/51]	Time  2.840 ( 2.214)	Data  1.886 ( 1.316)	Loss 1.6173e-01 (1.0248e-01)	Acc@1  93.75 ( 97.29)	Acc@5 100.00 ( 99.58)
Epoch: [29][50/51]	Time  2.232 ( 2.261)	Data  0.914 ( 1.338)	Loss 2.3973e-01 (1.1061e-01)	Acc@1  96.77 ( 97.12)	Acc@5 100.00 ( 99.50)
Test: [0/8]	Time  2.792 ( 2.792)	Loss 2.3389e-01 (2.3389e-01)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  1.738 ( 2.604)	Loss 3.1657e-01 (2.1206e-01)	Acc@1  90.62 ( 94.01)	Acc@5  98.44 ( 99.22)
 * Acc@1 94.600 Acc@5 99.400
learning rate is: 0.01
Epoch: [30][ 0/51]	Time  1.363 ( 1.363)	Data  0.624 ( 0.624)	Loss 1.4567e-01 (1.4567e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [30][10/51]	Time  2.735 ( 1.883)	Data  1.687 ( 0.964)	Loss 8.2485e-02 (1.6284e-01)	Acc@1  98.44 ( 95.88)	Acc@5 100.00 ( 99.15)
Epoch: [30][20/51]	Time  3.109 ( 2.486)	Data  1.790 ( 1.399)	Loss 9.4435e-02 (1.5244e-01)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 99.40)
Epoch: [30][30/51]	Time  1.564 ( 2.400)	Data  0.609 ( 1.366)	Loss 7.7560e-02 (1.4063e-01)	Acc@1  98.44 ( 96.17)	Acc@5 100.00 ( 99.60)
Epoch: [30][40/51]	Time  1.263 ( 2.309)	Data  0.498 ( 1.278)	Loss 4.9613e-02 (1.4567e-01)	Acc@1  98.44 ( 96.15)	Acc@5 100.00 ( 99.43)
Epoch: [30][50/51]	Time  1.084 ( 2.181)	Data  0.232 ( 1.180)	Loss 4.2752e-01 (1.4010e-01)	Acc@1  90.32 ( 96.29)	Acc@5  96.77 ( 99.41)
learning rate is: 0.01
Epoch: [31][ 0/51]	Time  1.383 ( 1.383)	Data  0.636 ( 0.636)	Loss 5.5980e-02 (5.5980e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [31][10/51]	Time  3.337 ( 2.409)	Data  1.946 ( 1.306)	Loss 9.4971e-02 (1.0249e-01)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.86)
Epoch: [31][20/51]	Time  2.902 ( 2.390)	Data  1.922 ( 1.343)	Loss 8.4907e-02 (1.0695e-01)	Acc@1  98.44 ( 97.17)	Acc@5  98.44 ( 99.48)
Epoch: [31][30/51]	Time  3.112 ( 2.462)	Data  1.958 ( 1.416)	Loss 1.3886e-01 (1.1407e-01)	Acc@1  98.44 ( 96.82)	Acc@5  98.44 ( 99.50)
Epoch: [31][40/51]	Time  1.046 ( 2.343)	Data  0.493 ( 1.365)	Loss 1.7327e-01 (1.1240e-01)	Acc@1  98.44 ( 97.14)	Acc@5  98.44 ( 99.47)
Epoch: [31][50/51]	Time  0.707 ( 2.157)	Data  0.231 ( 1.237)	Loss 1.7789e-01 (1.1192e-01)	Acc@1  93.55 ( 97.21)	Acc@5 100.00 ( 99.47)
learning rate is: 0.01
Epoch: [32][ 0/51]	Time  1.263 ( 1.263)	Data  0.623 ( 0.623)	Loss 9.8431e-02 (9.8431e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [32][10/51]	Time  1.091 ( 1.223)	Data  0.527 ( 0.644)	Loss 7.0733e-02 (1.0663e-01)	Acc@1  98.44 ( 97.44)	Acc@5 100.00 ( 99.29)
Epoch: [32][20/51]	Time  1.297 ( 1.473)	Data  0.461 ( 0.776)	Loss 3.1193e-01 (1.2515e-01)	Acc@1  92.19 ( 96.80)	Acc@5  98.44 ( 99.40)
Epoch: [32][30/51]	Time  1.248 ( 1.649)	Data  0.610 ( 0.874)	Loss 7.8847e-02 (1.1431e-01)	Acc@1  98.44 ( 96.98)	Acc@5 100.00 ( 99.55)
Epoch: [32][40/51]	Time  1.246 ( 1.573)	Data  0.503 ( 0.826)	Loss 7.5905e-02 (1.1050e-01)	Acc@1  98.44 ( 96.99)	Acc@5 100.00 ( 99.54)
Epoch: [32][50/51]	Time  1.712 ( 1.573)	Data  0.856 ( 0.831)	Loss 9.5803e-02 (1.0612e-01)	Acc@1  96.77 ( 97.09)	Acc@5 100.00 ( 99.60)
learning rate is: 0.01
Epoch: [33][ 0/51]	Time  2.693 ( 2.693)	Data  1.938 ( 1.938)	Loss 7.0162e-02 (7.0162e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [33][10/51]	Time  1.099 ( 2.043)	Data  0.478 ( 1.227)	Loss 2.1923e-01 (9.4133e-02)	Acc@1  96.88 ( 97.87)	Acc@5  98.44 ( 99.86)
Epoch: [33][20/51]	Time  1.170 ( 1.755)	Data  0.615 ( 0.988)	Loss 2.1064e-01 (8.9749e-02)	Acc@1  92.19 ( 97.69)	Acc@5  98.44 ( 99.78)
Epoch: [33][30/51]	Time  1.017 ( 1.758)	Data  0.473 ( 1.001)	Loss 1.1252e-01 (9.3246e-02)	Acc@1  95.31 ( 97.48)	Acc@5 100.00 ( 99.75)
Epoch: [33][40/51]	Time  1.233 ( 1.638)	Data  0.547 ( 0.908)	Loss 7.3342e-02 (9.3868e-02)	Acc@1  98.44 ( 97.48)	Acc@5 100.00 ( 99.73)
Epoch: [33][50/51]	Time  1.077 ( 1.635)	Data  0.221 ( 0.892)	Loss 5.3245e-01 (9.7950e-02)	Acc@1  93.55 ( 97.40)	Acc@5  96.77 ( 99.69)
learning rate is: 0.01
Epoch: [34][ 0/51]	Time  1.325 ( 1.325)	Data  0.473 ( 0.473)	Loss 2.0218e-01 (2.0218e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [34][10/51]	Time  3.031 ( 2.626)	Data  2.004 ( 1.534)	Loss 7.0647e-02 (9.1279e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.57)
Epoch: [34][20/51]	Time  3.557 ( 2.507)	Data  2.204 ( 1.428)	Loss 1.5940e-01 (9.1057e-02)	Acc@1  95.31 ( 97.54)	Acc@5  98.44 ( 99.48)
Epoch: [34][30/51]	Time  3.315 ( 2.720)	Data  2.061 ( 1.576)	Loss 2.9741e-01 (9.4761e-02)	Acc@1  92.19 ( 97.58)	Acc@5  96.88 ( 99.40)
Epoch: [34][40/51]	Time  1.537 ( 2.573)	Data  0.763 ( 1.466)	Loss 2.6380e-02 (1.0256e-01)	Acc@1 100.00 ( 97.33)	Acc@5 100.00 ( 99.50)
Epoch: [34][50/51]	Time  1.973 ( 2.366)	Data  0.840 ( 1.304)	Loss 8.7028e-02 (9.9768e-02)	Acc@1  96.77 ( 97.37)	Acc@5 100.00 ( 99.54)
Test: [0/8]	Time  3.280 ( 3.280)	Loss 2.0837e-01 (2.0837e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.324 ( 2.809)	Loss 3.1614e-01 (2.1789e-01)	Acc@1  92.19 ( 93.75)	Acc@5  98.44 ( 99.48)
 * Acc@1 94.600 Acc@5 99.600
learning rate is: 0.01
Epoch: [35][ 0/51]	Time  3.290 ( 3.290)	Data  2.248 ( 2.248)	Loss 4.7257e-02 (4.7257e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [35][10/51]	Time  3.041 ( 2.576)	Data  2.066 ( 1.620)	Loss 1.1127e-01 (1.0271e-01)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.43)
Epoch: [35][20/51]	Time  2.711 ( 2.710)	Data  1.698 ( 1.709)	Loss 1.6143e-01 (1.0973e-01)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 99.55)
Epoch: [35][30/51]	Time  1.052 ( 2.442)	Data  0.509 ( 1.513)	Loss 1.4873e-01 (1.1752e-01)	Acc@1  95.31 ( 96.72)	Acc@5  98.44 ( 99.34)
Epoch: [35][40/51]	Time  0.988 ( 2.145)	Data  0.445 ( 1.284)	Loss 9.0036e-02 (1.1076e-01)	Acc@1  95.31 ( 96.99)	Acc@5 100.00 ( 99.47)
Epoch: [35][50/51]	Time  2.136 ( 2.290)	Data  1.145 ( 1.383)	Loss 2.4837e-01 (1.1228e-01)	Acc@1  93.55 ( 97.09)	Acc@5 100.00 ( 99.47)
learning rate is: 0.01
Epoch: [36][ 0/51]	Time  3.091 ( 3.091)	Data  2.042 ( 2.042)	Loss 1.1036e-01 (1.1036e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [36][10/51]	Time  3.137 ( 1.674)	Data  2.061 ( 0.943)	Loss 1.0430e-01 (1.0281e-01)	Acc@1  96.88 ( 97.02)	Acc@5 100.00 ( 99.57)
Epoch: [36][20/51]	Time  1.295 ( 2.186)	Data  0.452 ( 1.322)	Loss 2.9839e-01 (1.2380e-01)	Acc@1  93.75 ( 96.43)	Acc@5  96.88 ( 99.33)
Epoch: [36][30/51]	Time  1.445 ( 2.091)	Data  0.622 ( 1.259)	Loss 4.4822e-02 (1.1554e-01)	Acc@1 100.00 ( 96.82)	Acc@5 100.00 ( 99.29)
Epoch: [36][40/51]	Time  1.113 ( 2.016)	Data  0.572 ( 1.200)	Loss 1.4377e-01 (1.1831e-01)	Acc@1  95.31 ( 96.68)	Acc@5 100.00 ( 99.31)
Epoch: [36][50/51]	Time  0.642 ( 1.869)	Data  0.188 ( 1.100)	Loss 4.5084e-01 (1.2392e-01)	Acc@1  87.10 ( 96.50)	Acc@5  96.77 ( 99.32)
learning rate is: 0.01
Epoch: [37][ 0/51]	Time  0.984 ( 0.984)	Data  0.460 ( 0.460)	Loss 1.4690e-01 (1.4690e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [37][10/51]	Time  2.631 ( 1.494)	Data  1.480 ( 0.722)	Loss 1.8554e-01 (9.0768e-02)	Acc@1  95.31 ( 97.59)	Acc@5  96.88 ( 99.43)
Epoch: [37][20/51]	Time  3.330 ( 2.070)	Data  2.112 ( 1.125)	Loss 1.3912e-01 (9.8153e-02)	Acc@1  96.88 ( 97.54)	Acc@5  98.44 ( 99.26)
Epoch: [37][30/51]	Time  1.312 ( 2.188)	Data  0.596 ( 1.225)	Loss 1.2091e-01 (9.3860e-02)	Acc@1  96.88 ( 97.63)	Acc@5 100.00 ( 99.45)
Epoch: [37][40/51]	Time  1.238 ( 2.134)	Data  0.481 ( 1.200)	Loss 2.9911e-01 (1.0769e-01)	Acc@1  93.75 ( 97.33)	Acc@5  95.31 ( 99.28)
Epoch: [37][50/51]	Time  0.683 ( 2.030)	Data  0.241 ( 1.139)	Loss 2.1776e-01 (1.0671e-01)	Acc@1  96.77 ( 97.34)	Acc@5 100.00 ( 99.35)
learning rate is: 0.01
Epoch: [38][ 0/51]	Time  1.213 ( 1.213)	Data  0.672 ( 0.672)	Loss 7.2214e-02 (7.2214e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [38][10/51]	Time  3.005 ( 2.004)	Data  1.897 ( 1.199)	Loss 7.0039e-02 (9.6803e-02)	Acc@1  98.44 ( 97.30)	Acc@5 100.00 ( 99.29)
Epoch: [38][20/51]	Time  2.906 ( 2.221)	Data  1.924 ( 1.319)	Loss 1.0612e-01 (1.0182e-01)	Acc@1  95.31 ( 97.17)	Acc@5 100.00 ( 99.48)
Epoch: [38][30/51]	Time  1.044 ( 2.245)	Data  0.386 ( 1.337)	Loss 5.4270e-02 (1.0400e-01)	Acc@1  98.44 ( 97.28)	Acc@5 100.00 ( 99.45)
Epoch: [38][40/51]	Time  2.857 ( 2.132)	Data  1.877 ( 1.263)	Loss 1.9302e-01 (1.0528e-01)	Acc@1  95.31 ( 97.37)	Acc@5  98.44 ( 99.47)
Epoch: [38][50/51]	Time  1.025 ( 2.217)	Data  0.305 ( 1.305)	Loss 1.3222e-02 (9.5736e-02)	Acc@1 100.00 ( 97.62)	Acc@5 100.00 ( 99.57)
learning rate is: 0.01
Epoch: [39][ 0/51]	Time  1.235 ( 1.235)	Data  0.434 ( 0.434)	Loss 4.1524e-02 (4.1524e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [39][10/51]	Time  1.537 ( 1.629)	Data  0.767 ( 0.763)	Loss 3.4452e-02 (6.3017e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [39][20/51]	Time  1.070 ( 1.972)	Data  0.539 ( 1.044)	Loss 6.6696e-02 (7.0929e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.78)
Epoch: [39][30/51]	Time  3.486 ( 2.122)	Data  2.421 ( 1.190)	Loss 2.0220e-01 (8.3445e-02)	Acc@1  96.88 ( 98.14)	Acc@5  98.44 ( 99.65)
Epoch: [39][40/51]	Time  3.154 ( 2.271)	Data  1.916 ( 1.282)	Loss 5.0947e-02 (9.4490e-02)	Acc@1  98.44 ( 97.83)	Acc@5 100.00 ( 99.62)
Epoch: [39][50/51]	Time  2.360 ( 2.285)	Data  1.474 ( 1.288)	Loss 3.4428e-01 (1.0092e-01)	Acc@1  90.32 ( 97.40)	Acc@5  96.77 ( 99.57)
Test: [0/8]	Time  3.136 ( 3.136)	Loss 2.0943e-01 (2.0943e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.726 ( 2.614)	Loss 2.5698e-01 (1.9822e-01)	Acc@1  95.31 ( 94.53)	Acc@5  98.44 ( 99.48)
 * Acc@1 95.000 Acc@5 99.600
learning rate is: 0.01
Epoch: [40][ 0/51]	Time  1.146 ( 1.146)	Data  0.525 ( 0.525)	Loss 1.0911e-01 (1.0911e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [40][10/51]	Time  1.762 ( 1.750)	Data  0.683 ( 0.872)	Loss 7.8815e-02 (1.0284e-01)	Acc@1  98.44 ( 97.02)	Acc@5  98.44 ( 99.57)
Epoch: [40][20/51]	Time  3.750 ( 2.444)	Data  2.665 ( 1.409)	Loss 1.5626e-01 (1.0399e-01)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 99.63)
Epoch: [40][30/51]	Time  1.598 ( 2.356)	Data  0.704 ( 1.352)	Loss 1.9639e-01 (9.8185e-02)	Acc@1  95.31 ( 97.28)	Acc@5 100.00 ( 99.70)
Epoch: [40][40/51]	Time  1.836 ( 2.264)	Data  0.827 ( 1.267)	Loss 1.6597e-01 (1.0042e-01)	Acc@1  96.88 ( 97.33)	Acc@5  98.44 ( 99.66)
Epoch: [40][50/51]	Time  1.922 ( 2.292)	Data  0.905 ( 1.279)	Loss 1.2524e-01 (9.9727e-02)	Acc@1  96.77 ( 97.21)	Acc@5 100.00 ( 99.69)
learning rate is: 0.01
Epoch: [41][ 0/51]	Time  3.328 ( 3.328)	Data  2.103 ( 2.103)	Loss 2.1221e-01 (2.1221e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [41][10/51]	Time  1.422 ( 2.051)	Data  0.620 ( 1.141)	Loss 1.3399e-01 (1.2752e-01)	Acc@1  93.75 ( 96.45)	Acc@5 100.00 ( 99.43)
Epoch: [41][20/51]	Time  3.009 ( 2.092)	Data  1.673 ( 1.151)	Loss 1.6989e-01 (1.2151e-01)	Acc@1  93.75 ( 96.43)	Acc@5  98.44 ( 99.48)
Epoch: [41][30/51]	Time  1.099 ( 1.839)	Data  0.499 ( 0.999)	Loss 6.0438e-02 (1.0801e-01)	Acc@1  96.88 ( 96.93)	Acc@5 100.00 ( 99.55)
Epoch: [41][40/51]	Time  2.487 ( 1.842)	Data  1.717 ( 1.006)	Loss 9.9942e-02 (1.0110e-01)	Acc@1  96.88 ( 97.10)	Acc@5 100.00 ( 99.62)
Epoch: [41][50/51]	Time  2.062 ( 2.001)	Data  0.848 ( 1.108)	Loss 1.8571e-01 (1.0036e-01)	Acc@1  93.55 ( 97.12)	Acc@5 100.00 ( 99.60)
learning rate is: 0.01
Epoch: [42][ 0/51]	Time  3.621 ( 3.621)	Data  2.248 ( 2.248)	Loss 1.5570e-02 (1.5570e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [42][10/51]	Time  3.469 ( 2.056)	Data  2.139 ( 1.117)	Loss 5.4332e-02 (9.0465e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [42][20/51]	Time  2.798 ( 1.861)	Data  1.597 ( 0.973)	Loss 1.0049e-01 (1.0764e-01)	Acc@1  98.44 ( 97.54)	Acc@5  98.44 ( 99.48)
Epoch: [42][30/51]	Time  1.301 ( 1.983)	Data  0.501 ( 1.066)	Loss 5.9631e-02 (9.9864e-02)	Acc@1  98.44 ( 97.48)	Acc@5 100.00 ( 99.60)
Epoch: [42][40/51]	Time  2.414 ( 2.075)	Data  1.857 ( 1.137)	Loss 9.7495e-02 (9.6664e-02)	Acc@1  96.88 ( 97.41)	Acc@5 100.00 ( 99.62)
Epoch: [42][50/51]	Time  0.990 ( 1.919)	Data  0.342 ( 1.040)	Loss 7.6845e-02 (9.3601e-02)	Acc@1 100.00 ( 97.59)	Acc@5 100.00 ( 99.57)
learning rate is: 0.01
Epoch: [43][ 0/51]	Time  1.036 ( 1.036)	Data  0.482 ( 0.482)	Loss 3.7437e-02 (3.7437e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [43][10/51]	Time  3.050 ( 1.620)	Data  2.040 ( 0.881)	Loss 1.8855e-01 (1.0412e-01)	Acc@1  96.88 ( 97.44)	Acc@5  96.88 ( 99.57)
Epoch: [43][20/51]	Time  3.266 ( 2.131)	Data  1.907 ( 1.194)	Loss 7.2380e-02 (1.0724e-01)	Acc@1  96.88 ( 97.25)	Acc@5 100.00 ( 99.18)
Epoch: [43][30/51]	Time  1.432 ( 2.290)	Data  0.518 ( 1.342)	Loss 3.5600e-02 (1.0462e-01)	Acc@1 100.00 ( 97.43)	Acc@5 100.00 ( 99.29)
Epoch: [43][40/51]	Time  3.665 ( 2.305)	Data  2.285 ( 1.356)	Loss 1.3754e-01 (1.0972e-01)	Acc@1  96.88 ( 97.18)	Acc@5  98.44 ( 99.24)
Epoch: [43][50/51]	Time  0.971 ( 2.271)	Data  0.441 ( 1.350)	Loss 1.7602e-01 (1.1138e-01)	Acc@1  96.77 ( 97.12)	Acc@5 100.00 ( 99.35)
learning rate is: 0.01
Epoch: [44][ 0/51]	Time  3.169 ( 3.169)	Data  1.989 ( 1.989)	Loss 7.4703e-02 (7.4703e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [44][10/51]	Time  1.215 ( 1.822)	Data  0.674 ( 1.104)	Loss 1.7279e-02 (8.0498e-02)	Acc@1 100.00 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [44][20/51]	Time  1.507 ( 1.917)	Data  0.813 ( 1.165)	Loss 1.0150e-01 (8.7433e-02)	Acc@1  96.88 ( 97.84)	Acc@5 100.00 ( 99.78)
Epoch: [44][30/51]	Time  1.175 ( 1.681)	Data  0.593 ( 0.993)	Loss 1.2797e-01 (9.1929e-02)	Acc@1  96.88 ( 97.83)	Acc@5  98.44 ( 99.70)
Epoch: [44][40/51]	Time  2.449 ( 1.770)	Data  1.836 ( 1.065)	Loss 6.7667e-02 (8.5891e-02)	Acc@1  98.44 ( 97.94)	Acc@5 100.00 ( 99.73)
Epoch: [44][50/51]	Time  1.086 ( 1.686)	Data  0.356 ( 0.985)	Loss 2.5286e-01 (9.0118e-02)	Acc@1  90.32 ( 97.74)	Acc@5  96.77 ( 99.66)
Test: [0/8]	Time  3.199 ( 3.199)	Loss 2.1865e-01 (2.1865e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  1.128 ( 1.252)	Loss 2.3207e-01 (1.9846e-01)	Acc@1  95.31 ( 94.01)	Acc@5  98.44 ( 99.74)
 * Acc@1 94.400 Acc@5 99.800
learning rate is: 0.01
Epoch: [45][ 0/51]	Time  2.958 ( 2.958)	Data  1.758 ( 1.758)	Loss 1.0258e-01 (1.0258e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [45][10/51]	Time  3.191 ( 2.815)	Data  2.106 ( 1.670)	Loss 4.3304e-02 (9.0556e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.72)
Epoch: [45][20/51]	Time  1.203 ( 2.610)	Data  0.653 ( 1.580)	Loss 1.3809e-01 (8.4982e-02)	Acc@1  96.88 ( 98.07)	Acc@5  98.44 ( 99.55)
Epoch: [45][30/51]	Time  2.791 ( 2.459)	Data  1.656 ( 1.496)	Loss 6.5475e-02 (8.4852e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.60)
Epoch: [45][40/51]	Time  1.078 ( 2.467)	Data  0.541 ( 1.518)	Loss 6.2435e-02 (7.9965e-02)	Acc@1  96.88 ( 98.17)	Acc@5 100.00 ( 99.66)
Epoch: [45][50/51]	Time  2.181 ( 2.266)	Data  1.222 ( 1.360)	Loss 1.3608e-01 (8.2864e-02)	Acc@1  93.55 ( 97.86)	Acc@5 100.00 ( 99.72)
learning rate is: 0.01
Epoch: [46][ 0/51]	Time  1.553 ( 1.553)	Data  0.877 ( 0.877)	Loss 1.1615e-01 (1.1615e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [46][10/51]	Time  2.784 ( 1.725)	Data  1.743 ( 0.971)	Loss 3.0216e-02 (9.1687e-02)	Acc@1 100.00 ( 97.44)	Acc@5 100.00 ( 99.57)
Epoch: [46][20/51]	Time  1.200 ( 1.789)	Data  0.445 ( 0.982)	Loss 4.2657e-02 (8.0949e-02)	Acc@1  98.44 ( 97.77)	Acc@5 100.00 ( 99.70)
Epoch: [46][30/51]	Time  3.089 ( 1.855)	Data  2.391 ( 1.039)	Loss 2.5699e-02 (7.4675e-02)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.75)
Epoch: [46][40/51]	Time  1.206 ( 1.683)	Data  0.652 ( 0.924)	Loss 2.4223e-02 (7.0984e-02)	Acc@1  98.44 ( 98.09)	Acc@5 100.00 ( 99.77)
Epoch: [46][50/51]	Time  2.091 ( 1.755)	Data  0.810 ( 0.958)	Loss 3.4294e-02 (7.0841e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.81)
learning rate is: 0.01
Epoch: [47][ 0/51]	Time  3.307 ( 3.307)	Data  2.075 ( 2.075)	Loss 4.5895e-02 (4.5895e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [47][10/51]	Time  2.305 ( 2.273)	Data  1.056 ( 1.211)	Loss 4.4416e-02 (8.2551e-02)	Acc@1  98.44 ( 97.59)	Acc@5 100.00 ( 99.57)
Epoch: [47][20/51]	Time  3.148 ( 2.500)	Data  2.051 ( 1.439)	Loss 8.8772e-02 (8.7303e-02)	Acc@1  98.44 ( 97.62)	Acc@5  98.44 ( 99.55)
Epoch: [47][30/51]	Time  2.341 ( 2.286)	Data  1.449 ( 1.263)	Loss 1.6795e-01 (9.1236e-02)	Acc@1  95.31 ( 97.48)	Acc@5  98.44 ( 99.45)
Epoch: [47][40/51]	Time  3.015 ( 2.283)	Data  1.925 ( 1.299)	Loss 8.5244e-02 (8.9114e-02)	Acc@1  98.44 ( 97.60)	Acc@5  98.44 ( 99.43)
Epoch: [47][50/51]	Time  0.989 ( 2.262)	Data  0.318 ( 1.292)	Loss 2.1447e-01 (9.7045e-02)	Acc@1  90.32 ( 97.37)	Acc@5 100.00 ( 99.35)
learning rate is: 0.01
Epoch: [48][ 0/51]	Time  1.273 ( 1.273)	Data  0.689 ( 0.689)	Loss 3.7402e-01 (3.7402e-01)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [48][10/51]	Time  3.036 ( 1.422)	Data  2.112 ( 0.727)	Loss 1.5469e-01 (8.8720e-02)	Acc@1  95.31 ( 97.44)	Acc@5  98.44 ( 99.57)
Epoch: [48][20/51]	Time  1.659 ( 1.536)	Data  0.769 ( 0.820)	Loss 6.6363e-02 (8.2655e-02)	Acc@1  98.44 ( 97.77)	Acc@5 100.00 ( 99.63)
Epoch: [48][30/51]	Time  1.380 ( 1.716)	Data  0.507 ( 0.961)	Loss 3.2558e-02 (8.1338e-02)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 ( 99.65)
Epoch: [48][40/51]	Time  2.876 ( 1.799)	Data  1.697 ( 1.015)	Loss 6.3199e-02 (7.9228e-02)	Acc@1  98.44 ( 97.83)	Acc@5 100.00 ( 99.66)
Epoch: [48][50/51]	Time  1.163 ( 1.713)	Data  0.707 ( 0.950)	Loss 2.4721e-01 (8.1274e-02)	Acc@1  90.32 ( 97.65)	Acc@5 100.00 ( 99.69)
learning rate is: 0.01
Epoch: [49][ 0/51]	Time  1.137 ( 1.137)	Data  0.558 ( 0.558)	Loss 7.0604e-02 (7.0604e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [49][10/51]	Time  1.230 ( 1.400)	Data  0.587 ( 0.768)	Loss 9.9835e-02 (6.9638e-02)	Acc@1  96.88 ( 97.73)	Acc@5  98.44 ( 99.72)
Epoch: [49][20/51]	Time  2.740 ( 1.374)	Data  1.756 ( 0.715)	Loss 5.2111e-02 (7.6370e-02)	Acc@1  98.44 ( 97.69)	Acc@5 100.00 ( 99.70)
Epoch: [49][30/51]	Time  2.602 ( 1.468)	Data  1.670 ( 0.782)	Loss 7.6081e-02 (8.6539e-02)	Acc@1  98.44 ( 97.48)	Acc@5 100.00 ( 99.65)
Epoch: [49][40/51]	Time  1.059 ( 1.433)	Data  0.435 ( 0.762)	Loss 3.1129e-02 (8.3120e-02)	Acc@1 100.00 ( 97.64)	Acc@5 100.00 ( 99.70)
Epoch: [49][50/51]	Time  0.815 ( 1.462)	Data  0.333 ( 0.775)	Loss 2.1596e-01 (8.3645e-02)	Acc@1  96.77 ( 97.65)	Acc@5  96.77 ( 99.66)
Test: [0/8]	Time  0.918 ( 0.918)	Loss 2.3794e-01 (2.3794e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.497 ( 2.366)	Loss 2.2791e-01 (1.8783e-01)	Acc@1  95.31 ( 95.05)	Acc@5  98.44 ( 99.74)
 * Acc@1 95.200 Acc@5 99.800
learning rate is: 0.01
Epoch: [50][ 0/51]	Time  1.130 ( 1.130)	Data  0.520 ( 0.520)	Loss 1.2956e-01 (1.2956e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [50][10/51]	Time  1.062 ( 1.611)	Data  0.476 ( 0.919)	Loss 2.8971e-02 (8.7938e-02)	Acc@1 100.00 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [50][20/51]	Time  2.862 ( 1.994)	Data  1.798 ( 1.165)	Loss 7.5197e-02 (7.3735e-02)	Acc@1  96.88 ( 98.07)	Acc@5 100.00 ( 99.93)
Epoch: [50][30/51]	Time  1.056 ( 2.084)	Data  0.514 ( 1.218)	Loss 2.0930e-01 (7.5728e-02)	Acc@1  96.88 ( 98.19)	Acc@5  96.88 ( 99.75)
Epoch: [50][40/51]	Time  3.296 ( 2.190)	Data  2.165 ( 1.281)	Loss 1.3647e-01 (7.7101e-02)	Acc@1  96.88 ( 98.17)	Acc@5 100.00 ( 99.70)
Epoch: [50][50/51]	Time  1.283 ( 2.037)	Data  0.518 ( 1.158)	Loss 1.0510e-01 (8.1223e-02)	Acc@1  93.55 ( 97.96)	Acc@5 100.00 ( 99.75)
learning rate is: 0.01
Epoch: [51][ 0/51]	Time  1.583 ( 1.583)	Data  0.777 ( 0.777)	Loss 2.3558e-01 (2.3558e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [51][10/51]	Time  2.817 ( 2.860)	Data  1.762 ( 1.786)	Loss 4.0503e-02 (9.3061e-02)	Acc@1 100.00 ( 98.01)	Acc@5 100.00 ( 99.29)
Epoch: [51][20/51]	Time  1.800 ( 2.572)	Data  0.785 ( 1.514)	Loss 2.4452e-02 (7.2053e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.40)
Epoch: [51][30/51]	Time  3.120 ( 2.491)	Data  1.936 ( 1.453)	Loss 1.4444e-01 (7.7569e-02)	Acc@1  95.31 ( 98.24)	Acc@5  98.44 ( 99.50)
Epoch: [51][40/51]	Time  1.809 ( 2.542)	Data  0.642 ( 1.493)	Loss 1.2528e-01 (7.6043e-02)	Acc@1  95.31 ( 98.17)	Acc@5  98.44 ( 99.54)
Epoch: [51][50/51]	Time  0.831 ( 2.300)	Data  0.292 ( 1.308)	Loss 3.2510e-01 (7.6604e-02)	Acc@1  93.55 ( 98.14)	Acc@5  93.55 ( 99.54)
learning rate is: 0.01
Epoch: [52][ 0/51]	Time  1.175 ( 1.175)	Data  0.555 ( 0.555)	Loss 9.2788e-02 (9.2788e-02)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [52][10/51]	Time  1.337 ( 1.639)	Data  0.518 ( 0.819)	Loss 1.0795e-01 (7.8334e-02)	Acc@1  98.44 ( 98.30)	Acc@5  98.44 ( 99.72)
Epoch: [52][20/51]	Time  1.284 ( 1.833)	Data  0.515 ( 0.933)	Loss 6.3667e-02 (9.6331e-02)	Acc@1  98.44 ( 97.92)	Acc@5 100.00 ( 99.33)
Epoch: [52][30/51]	Time  1.619 ( 1.975)	Data  0.795 ( 1.049)	Loss 1.3864e-01 (9.7107e-02)	Acc@1  96.88 ( 97.78)	Acc@5  98.44 ( 99.34)
Epoch: [52][40/51]	Time  3.074 ( 1.915)	Data  1.825 ( 1.001)	Loss 4.3195e-02 (9.2833e-02)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 99.39)
Epoch: [52][50/51]	Time  1.106 ( 1.936)	Data  0.463 ( 1.025)	Loss 1.7680e-01 (9.4894e-02)	Acc@1  93.55 ( 97.65)	Acc@5 100.00 ( 99.41)
learning rate is: 0.01
Epoch: [53][ 0/51]	Time  1.346 ( 1.346)	Data  0.679 ( 0.679)	Loss 3.8509e-02 (3.8509e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [53][10/51]	Time  1.593 ( 2.407)	Data  0.777 ( 1.325)	Loss 1.2658e-02 (8.0223e-02)	Acc@1 100.00 ( 97.87)	Acc@5 100.00 ( 99.43)
Epoch: [53][20/51]	Time  1.183 ( 2.434)	Data  0.547 ( 1.380)	Loss 1.2398e-01 (9.1206e-02)	Acc@1  96.88 ( 97.32)	Acc@5 100.00 ( 99.55)
Epoch: [53][30/51]	Time  1.361 ( 2.105)	Data  0.815 ( 1.159)	Loss 1.4334e-01 (8.8148e-02)	Acc@1  96.88 ( 97.53)	Acc@5  98.44 ( 99.55)
Epoch: [53][40/51]	Time  1.252 ( 1.998)	Data  0.612 ( 1.084)	Loss 1.0263e-01 (8.7759e-02)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 ( 99.50)
Epoch: [53][50/51]	Time  2.054 ( 2.026)	Data  0.971 ( 1.088)	Loss 1.7161e-01 (8.7194e-02)	Acc@1  93.55 ( 97.49)	Acc@5 100.00 ( 99.57)
learning rate is: 0.01
Epoch: [54][ 0/51]	Time  2.966 ( 2.966)	Data  1.902 ( 1.902)	Loss 7.4211e-02 (7.4211e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [54][10/51]	Time  3.276 ( 2.986)	Data  2.024 ( 1.868)	Loss 2.0439e-01 (9.2609e-02)	Acc@1  96.88 ( 97.44)	Acc@5  98.44 ( 99.43)
Epoch: [54][20/51]	Time  2.581 ( 2.905)	Data  1.609 ( 1.828)	Loss 3.2643e-02 (8.1584e-02)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 99.55)
Epoch: [54][30/51]	Time  3.072 ( 2.741)	Data  1.845 ( 1.675)	Loss 8.0779e-02 (8.1789e-02)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.50)
Epoch: [54][40/51]	Time  3.112 ( 2.639)	Data  1.984 ( 1.600)	Loss 1.5422e-01 (8.2815e-02)	Acc@1  95.31 ( 97.87)	Acc@5 100.00 ( 99.54)
Epoch: [54][50/51]	Time  1.123 ( 2.514)	Data  0.439 ( 1.497)	Loss 2.6783e-01 (7.9294e-02)	Acc@1  90.32 ( 97.90)	Acc@5  96.77 ( 99.60)
Test: [0/8]	Time  0.962 ( 0.962)	Loss 1.5599e-01 (1.5599e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  1.043 ( 0.980)	Loss 2.2626e-01 (1.7379e-01)	Acc@1  92.19 ( 95.83)	Acc@5  98.44 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.01
Epoch: [55][ 0/51]	Time  1.110 ( 1.110)	Data  0.427 ( 0.427)	Loss 3.0006e-02 (3.0006e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [55][10/51]	Time  1.440 ( 1.709)	Data  0.871 ( 0.935)	Loss 1.6605e-01 (8.6864e-02)	Acc@1  95.31 ( 97.44)	Acc@5  98.44 ( 99.72)
Epoch: [55][20/51]	Time  0.946 ( 1.738)	Data  0.380 ( 0.981)	Loss 1.8596e-01 (8.7562e-02)	Acc@1  93.75 ( 97.69)	Acc@5  98.44 ( 99.48)
Epoch: [55][30/51]	Time  1.345 ( 1.639)	Data  0.478 ( 0.891)	Loss 3.8490e-02 (7.3448e-02)	Acc@1 100.00 ( 98.19)	Acc@5 100.00 ( 99.60)
Epoch: [55][40/51]	Time  3.518 ( 1.882)	Data  2.220 ( 1.035)	Loss 1.0092e-01 (7.3999e-02)	Acc@1  96.88 ( 98.29)	Acc@5 100.00 ( 99.58)
Epoch: [55][50/51]	Time  1.326 ( 2.103)	Data  0.528 ( 1.188)	Loss 1.3940e-01 (7.4067e-02)	Acc@1  96.77 ( 98.27)	Acc@5 100.00 ( 99.60)
learning rate is: 0.01
Epoch: [56][ 0/51]	Time  1.633 ( 1.633)	Data  0.884 ( 0.884)	Loss 2.4971e-02 (2.4971e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [56][10/51]	Time  1.515 ( 2.334)	Data  0.571 ( 1.321)	Loss 1.4595e-01 (8.9823e-02)	Acc@1  96.88 ( 97.30)	Acc@5  98.44 ( 99.57)
Epoch: [56][20/51]	Time  1.084 ( 2.195)	Data  0.558 ( 1.269)	Loss 2.5267e-02 (6.8881e-02)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.78)
Epoch: [56][30/51]	Time  1.213 ( 1.873)	Data  0.562 ( 1.060)	Loss 2.7355e-02 (6.4028e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.70)
Epoch: [56][40/51]	Time  3.154 ( 1.860)	Data  2.283 ( 1.052)	Loss 8.9080e-02 (6.6780e-02)	Acc@1  96.88 ( 98.13)	Acc@5  98.44 ( 99.70)
Epoch: [56][50/51]	Time  1.924 ( 2.051)	Data  0.906 ( 1.201)	Loss 9.1527e-02 (7.0682e-02)	Acc@1 100.00 ( 98.08)	Acc@5 100.00 ( 99.75)
learning rate is: 0.01
Epoch: [57][ 0/51]	Time  1.224 ( 1.224)	Data  0.431 ( 0.431)	Loss 3.2481e-02 (3.2481e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [57][10/51]	Time  1.642 ( 1.913)	Data  0.722 ( 1.055)	Loss 1.2912e-02 (5.0742e-02)	Acc@1 100.00 ( 99.43)	Acc@5 100.00 ( 99.72)
Epoch: [57][20/51]	Time  2.871 ( 2.233)	Data  1.784 ( 1.321)	Loss 1.3088e-01 (6.4012e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 ( 99.78)
Epoch: [57][30/51]	Time  1.781 ( 2.144)	Data  1.242 ( 1.257)	Loss 3.4325e-02 (6.0412e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [57][40/51]	Time  1.038 ( 2.045)	Data  0.447 ( 1.200)	Loss 4.9713e-02 (5.7888e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [57][50/51]	Time  1.914 ( 2.029)	Data  0.992 ( 1.177)	Loss 6.5397e-02 (5.7962e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.81)
learning rate is: 0.01
Epoch: [58][ 0/51]	Time  1.295 ( 1.295)	Data  0.761 ( 0.761)	Loss 7.7875e-02 (7.7875e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [58][10/51]	Time  1.168 ( 1.139)	Data  0.614 ( 0.540)	Loss 1.6758e-01 (8.2688e-02)	Acc@1  95.31 ( 97.44)	Acc@5 100.00 (100.00)
Epoch: [58][20/51]	Time  3.090 ( 1.566)	Data  1.655 ( 0.807)	Loss 4.4546e-02 (8.2760e-02)	Acc@1  98.44 ( 97.62)	Acc@5 100.00 ( 99.85)
Epoch: [58][30/51]	Time  3.037 ( 1.917)	Data  1.931 ( 1.071)	Loss 9.5236e-02 (7.6779e-02)	Acc@1  95.31 ( 97.68)	Acc@5 100.00 ( 99.80)
Epoch: [58][40/51]	Time  2.661 ( 2.102)	Data  1.793 ( 1.216)	Loss 5.6765e-02 (8.1683e-02)	Acc@1  98.44 ( 97.56)	Acc@5 100.00 ( 99.73)
Epoch: [58][50/51]	Time  2.194 ( 2.226)	Data  1.050 ( 1.309)	Loss 5.3140e-02 (7.5874e-02)	Acc@1 100.00 ( 97.80)	Acc@5 100.00 ( 99.72)
learning rate is: 0.01
Epoch: [59][ 0/51]	Time  1.379 ( 1.379)	Data  0.516 ( 0.516)	Loss 8.3744e-02 (8.3744e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [59][10/51]	Time  1.774 ( 1.832)	Data  0.683 ( 0.973)	Loss 1.0412e-01 (5.1631e-02)	Acc@1  93.75 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [59][20/51]	Time  1.191 ( 2.461)	Data  0.428 ( 1.429)	Loss 1.0167e-01 (4.8619e-02)	Acc@1  98.44 ( 98.59)	Acc@5  98.44 ( 99.85)
Epoch: [59][30/51]	Time  1.896 ( 2.151)	Data  0.735 ( 1.179)	Loss 2.7831e-02 (5.2505e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.80)
Epoch: [59][40/51]	Time  1.238 ( 2.078)	Data  0.559 ( 1.147)	Loss 1.9137e-02 (5.8490e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.73)
Epoch: [59][50/51]	Time  1.938 ( 2.008)	Data  0.941 ( 1.097)	Loss 1.2842e-01 (6.8330e-02)	Acc@1  93.55 ( 98.30)	Acc@5 100.00 ( 99.69)
Test: [0/8]	Time  2.944 ( 2.944)	Loss 1.7574e-01 (1.7574e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.296 ( 2.710)	Loss 2.9248e-01 (2.0426e-01)	Acc@1  92.19 ( 94.53)	Acc@5  98.44 ( 99.48)
 * Acc@1 95.000 Acc@5 99.600
learning rate is: 0.01
Epoch: [60][ 0/51]	Time  2.798 ( 2.798)	Data  1.809 ( 1.809)	Loss 3.3410e-02 (3.3410e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [60][10/51]	Time  3.089 ( 2.665)	Data  1.801 ( 1.702)	Loss 1.3745e-01 (6.6478e-02)	Acc@1  95.31 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [60][20/51]	Time  1.253 ( 2.456)	Data  0.648 ( 1.518)	Loss 9.6343e-02 (6.7946e-02)	Acc@1  98.44 ( 98.07)	Acc@5  98.44 ( 99.78)
Epoch: [60][30/51]	Time  1.436 ( 2.442)	Data  0.794 ( 1.493)	Loss 1.2786e-02 (7.0952e-02)	Acc@1 100.00 ( 97.98)	Acc@5 100.00 ( 99.65)
Epoch: [60][40/51]	Time  1.331 ( 2.237)	Data  0.684 ( 1.335)	Loss 8.9605e-03 (6.9503e-02)	Acc@1 100.00 ( 98.02)	Acc@5 100.00 ( 99.66)
Epoch: [60][50/51]	Time  0.971 ( 2.106)	Data  0.224 ( 1.233)	Loss 2.1854e-01 (7.3713e-02)	Acc@1  93.55 ( 97.96)	Acc@5 100.00 ( 99.66)
learning rate is: 0.01
Epoch: [61][ 0/51]	Time  3.085 ( 3.085)	Data  1.997 ( 1.997)	Loss 2.9156e-02 (2.9156e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [61][10/51]	Time  1.199 ( 1.978)	Data  0.599 ( 1.183)	Loss 5.4665e-02 (7.2807e-02)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.57)
Epoch: [61][20/51]	Time  1.482 ( 2.109)	Data  0.639 ( 1.255)	Loss 1.2421e-01 (7.2316e-02)	Acc@1  96.88 ( 97.99)	Acc@5  98.44 ( 99.70)
Epoch: [61][30/51]	Time  3.135 ( 2.345)	Data  2.032 ( 1.419)	Loss 1.0658e-01 (6.9935e-02)	Acc@1  96.88 ( 98.08)	Acc@5 100.00 ( 99.70)
Epoch: [61][40/51]	Time  1.524 ( 2.426)	Data  0.758 ( 1.455)	Loss 2.0705e-01 (7.5379e-02)	Acc@1  95.31 ( 97.98)	Acc@5  98.44 ( 99.66)
Epoch: [61][50/51]	Time  2.513 ( 2.493)	Data  1.180 ( 1.471)	Loss 2.0690e-02 (7.6452e-02)	Acc@1 100.00 ( 97.96)	Acc@5 100.00 ( 99.63)
learning rate is: 0.01
Epoch: [62][ 0/51]	Time  2.773 ( 2.773)	Data  1.752 ( 1.752)	Loss 5.2886e-02 (5.2886e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [62][10/51]	Time  2.777 ( 2.819)	Data  1.811 ( 1.635)	Loss 7.8529e-02 (5.5154e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 99.57)
Epoch: [62][20/51]	Time  1.354 ( 2.422)	Data  0.460 ( 1.362)	Loss 5.9423e-03 (6.4993e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.55)
Epoch: [62][30/51]	Time  1.238 ( 2.038)	Data  0.544 ( 1.132)	Loss 6.1832e-02 (7.5782e-02)	Acc@1  96.88 ( 97.88)	Acc@5 100.00 ( 99.55)
Epoch: [62][40/51]	Time  2.616 ( 1.945)	Data  1.630 ( 1.084)	Loss 2.6426e-02 (6.5310e-02)	Acc@1  98.44 ( 98.17)	Acc@5 100.00 ( 99.62)
Epoch: [62][50/51]	Time  0.643 ( 1.774)	Data  0.184 ( 0.972)	Loss 1.2940e-01 (7.0521e-02)	Acc@1  96.77 ( 98.05)	Acc@5 100.00 ( 99.60)
learning rate is: 0.01
Epoch: [63][ 0/51]	Time  1.289 ( 1.289)	Data  0.498 ( 0.498)	Loss 1.4565e-01 (1.4565e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [63][10/51]	Time  3.486 ( 2.509)	Data  2.264 ( 1.542)	Loss 1.3769e-02 (8.6108e-02)	Acc@1 100.00 ( 97.87)	Acc@5 100.00 ( 99.43)
Epoch: [63][20/51]	Time  1.088 ( 2.525)	Data  0.501 ( 1.572)	Loss 1.2798e-01 (8.8060e-02)	Acc@1  96.88 ( 97.47)	Acc@5  98.44 ( 99.48)
Epoch: [63][30/51]	Time  2.805 ( 2.459)	Data  1.799 ( 1.520)	Loss 6.2467e-02 (7.9909e-02)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 ( 99.60)
Epoch: [63][40/51]	Time  1.023 ( 2.253)	Data  0.479 ( 1.359)	Loss 5.8222e-02 (7.7936e-02)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 99.58)
Epoch: [63][50/51]	Time  0.912 ( 2.123)	Data  0.192 ( 1.256)	Loss 3.4632e-01 (7.9908e-02)	Acc@1  93.55 ( 97.83)	Acc@5  96.77 ( 99.63)
learning rate is: 0.01
Epoch: [64][ 0/51]	Time  1.122 ( 1.122)	Data  0.581 ( 0.581)	Loss 1.8937e-01 (1.8937e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [64][10/51]	Time  2.912 ( 1.297)	Data  1.926 ( 0.651)	Loss 1.2235e-02 (4.9334e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [64][20/51]	Time  2.743 ( 1.756)	Data  1.702 ( 0.986)	Loss 2.9034e-02 (5.0304e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.93)
Epoch: [64][30/51]	Time  2.869 ( 1.951)	Data  1.769 ( 1.111)	Loss 1.1272e-01 (5.2288e-02)	Acc@1  96.88 ( 98.54)	Acc@5  98.44 ( 99.85)
Epoch: [64][40/51]	Time  1.890 ( 1.949)	Data  0.685 ( 1.090)	Loss 5.5081e-02 (5.9131e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.73)
Epoch: [64][50/51]	Time  1.289 ( 2.029)	Data  0.530 ( 1.146)	Loss 2.0915e-01 (5.8740e-02)	Acc@1  93.55 ( 98.58)	Acc@5 100.00 ( 99.69)
Test: [0/8]	Time  1.042 ( 1.042)	Loss 1.8274e-01 (1.8274e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.953 ( 0.921)	Loss 2.6540e-01 (1.9332e-01)	Acc@1  92.19 ( 94.01)	Acc@5 100.00 ( 99.74)
 * Acc@1 94.800 Acc@5 99.800
learning rate is: 0.01
Epoch: [65][ 0/51]	Time  2.846 ( 2.846)	Data  1.643 ( 1.643)	Loss 1.7454e-02 (1.7454e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [65][10/51]	Time  1.100 ( 1.763)	Data  0.548 ( 0.995)	Loss 6.4732e-03 (7.0537e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.57)
Epoch: [65][20/51]	Time  1.239 ( 1.535)	Data  0.690 ( 0.852)	Loss 1.4059e-01 (6.9438e-02)	Acc@1  93.75 ( 98.07)	Acc@5 100.00 ( 99.63)
Epoch: [65][30/51]	Time  1.547 ( 1.420)	Data  0.667 ( 0.764)	Loss 1.0279e-01 (7.0507e-02)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.60)
Epoch: [65][40/51]	Time  2.905 ( 1.772)	Data  1.995 ( 0.996)	Loss 4.6881e-03 (6.9203e-02)	Acc@1 100.00 ( 97.94)	Acc@5 100.00 ( 99.66)
Epoch: [65][50/51]	Time  1.875 ( 2.003)	Data  0.869 ( 1.151)	Loss 8.3938e-02 (6.8925e-02)	Acc@1  96.77 ( 97.99)	Acc@5 100.00 ( 99.66)
learning rate is: 0.01
Epoch: [66][ 0/51]	Time  3.292 ( 3.292)	Data  2.037 ( 2.037)	Loss 2.0382e-02 (2.0382e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [66][10/51]	Time  1.042 ( 2.324)	Data  0.488 ( 1.413)	Loss 7.8771e-02 (8.3053e-02)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.43)
Epoch: [66][20/51]	Time  3.257 ( 2.201)	Data  2.067 ( 1.300)	Loss 8.0288e-02 (8.1520e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.55)
Epoch: [66][30/51]	Time  2.611 ( 2.514)	Data  1.833 ( 1.514)	Loss 1.3157e-01 (7.7639e-02)	Acc@1  96.88 ( 98.24)	Acc@5  98.44 ( 99.60)
Epoch: [66][40/51]	Time  1.557 ( 2.525)	Data  0.706 ( 1.497)	Loss 8.0070e-03 (8.7766e-02)	Acc@1 100.00 ( 97.90)	Acc@5 100.00 ( 99.43)
Epoch: [66][50/51]	Time  2.021 ( 2.463)	Data  0.889 ( 1.440)	Loss 3.5637e-02 (8.8201e-02)	Acc@1  96.77 ( 97.90)	Acc@5 100.00 ( 99.47)
learning rate is: 0.01
Epoch: [67][ 0/51]	Time  3.071 ( 3.071)	Data  2.115 ( 2.115)	Loss 1.2541e-01 (1.2541e-01)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 96.88)
Epoch: [67][10/51]	Time  1.363 ( 2.021)	Data  0.545 ( 1.074)	Loss 1.2214e-01 (8.8132e-02)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 99.57)
Epoch: [67][20/51]	Time  1.053 ( 2.017)	Data  0.495 ( 1.136)	Loss 3.1820e-02 (8.4758e-02)	Acc@1 100.00 ( 97.32)	Acc@5 100.00 ( 99.70)
Epoch: [67][30/51]	Time  1.410 ( 1.733)	Data  0.588 ( 0.944)	Loss 2.6594e-02 (8.3018e-02)	Acc@1 100.00 ( 97.63)	Acc@5 100.00 ( 99.60)
Epoch: [67][40/51]	Time  3.475 ( 1.825)	Data  2.298 ( 1.005)	Loss 4.2789e-02 (7.3837e-02)	Acc@1  98.44 ( 97.94)	Acc@5 100.00 ( 99.66)
Epoch: [67][50/51]	Time  1.171 ( 1.726)	Data  0.325 ( 0.934)	Loss 1.9816e-01 (7.0288e-02)	Acc@1  96.77 ( 98.05)	Acc@5  96.77 ( 99.66)
learning rate is: 0.01
Epoch: [68][ 0/51]	Time  3.006 ( 3.006)	Data  1.878 ( 1.878)	Loss 4.6275e-02 (4.6275e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [68][10/51]	Time  1.105 ( 1.500)	Data  0.424 ( 0.747)	Loss 6.2638e-02 (8.0290e-02)	Acc@1  96.88 ( 97.59)	Acc@5 100.00 ( 99.57)
Epoch: [68][20/51]	Time  1.202 ( 1.482)	Data  0.664 ( 0.763)	Loss 4.9984e-02 (6.7148e-02)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 ( 99.78)
Epoch: [68][30/51]	Time  1.348 ( 1.406)	Data  0.606 ( 0.726)	Loss 6.3376e-02 (6.7099e-02)	Acc@1  96.88 ( 98.29)	Acc@5 100.00 ( 99.80)
Epoch: [68][40/51]	Time  1.090 ( 1.448)	Data  0.507 ( 0.742)	Loss 2.8479e-02 (6.6780e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.77)
Epoch: [68][50/51]	Time  1.076 ( 1.502)	Data  0.417 ( 0.790)	Loss 2.7343e-01 (6.3877e-02)	Acc@1  90.32 ( 98.30)	Acc@5  96.77 ( 99.78)
learning rate is: 0.01
Epoch: [69][ 0/51]	Time  1.274 ( 1.274)	Data  0.738 ( 0.738)	Loss 2.6213e-01 (2.6213e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [69][10/51]	Time  1.470 ( 1.855)	Data  0.463 ( 1.026)	Loss 2.1444e-01 (1.3431e-01)	Acc@1  93.75 ( 96.16)	Acc@5  98.44 ( 99.43)
Epoch: [69][20/51]	Time  1.041 ( 1.548)	Data  0.513 ( 0.792)	Loss 9.9039e-02 (1.0229e-01)	Acc@1  95.31 ( 97.17)	Acc@5 100.00 ( 99.48)
Epoch: [69][30/51]	Time  1.334 ( 1.697)	Data  0.763 ( 0.929)	Loss 3.0973e-02 (9.1888e-02)	Acc@1 100.00 ( 97.48)	Acc@5 100.00 ( 99.45)
Epoch: [69][40/51]	Time  1.262 ( 1.612)	Data  0.515 ( 0.868)	Loss 1.7434e-02 (8.5215e-02)	Acc@1 100.00 ( 97.71)	Acc@5 100.00 ( 99.50)
Epoch: [69][50/51]	Time  2.077 ( 1.710)	Data  0.923 ( 0.923)	Loss 2.7923e-01 (8.5834e-02)	Acc@1  93.55 ( 97.77)	Acc@5  96.77 ( 99.44)
Test: [0/8]	Time  3.895 ( 3.895)	Loss 1.3926e-01 (1.3926e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  2.449 ( 2.891)	Loss 2.5101e-01 (1.7192e-01)	Acc@1  93.75 ( 95.31)	Acc@5 100.00 ( 99.74)
 * Acc@1 95.400 Acc@5 99.800
learning rate is: 0.01
Epoch: [70][ 0/51]	Time  1.697 ( 1.697)	Data  0.643 ( 0.643)	Loss 1.3559e-01 (1.3559e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [70][10/51]	Time  1.440 ( 2.244)	Data  0.677 ( 1.266)	Loss 3.8305e-02 (4.5690e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [70][20/51]	Time  1.398 ( 2.039)	Data  0.485 ( 1.044)	Loss 1.1088e-02 (5.2254e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [70][30/51]	Time  1.352 ( 2.088)	Data  0.611 ( 1.107)	Loss 3.4935e-02 (4.6116e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.75)
Epoch: [70][40/51]	Time  1.737 ( 2.044)	Data  0.980 ( 1.085)	Loss 5.5164e-02 (5.4240e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 ( 99.70)
Epoch: [70][50/51]	Time  1.398 ( 1.988)	Data  0.421 ( 1.044)	Loss 3.4608e-02 (5.2034e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.72)
learning rate is: 0.01
Epoch: [71][ 0/51]	Time  1.200 ( 1.200)	Data  0.462 ( 0.462)	Loss 6.2730e-02 (6.2730e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [71][10/51]	Time  3.010 ( 2.044)	Data  2.224 ( 1.113)	Loss 3.9947e-03 (5.3876e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [71][20/51]	Time  1.496 ( 2.095)	Data  0.758 ( 1.142)	Loss 1.0886e-01 (5.5052e-02)	Acc@1  95.31 ( 98.36)	Acc@5 100.00 ( 99.78)
Epoch: [71][30/51]	Time  1.208 ( 1.941)	Data  0.641 ( 1.039)	Loss 6.0368e-02 (5.2227e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.85)
Epoch: [71][40/51]	Time  1.138 ( 1.837)	Data  0.601 ( 0.986)	Loss 5.2772e-02 (4.9054e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.89)
Epoch: [71][50/51]	Time  2.311 ( 1.906)	Data  0.996 ( 1.041)	Loss 1.4868e-01 (5.0250e-02)	Acc@1  93.55 ( 98.51)	Acc@5 100.00 ( 99.88)
learning rate is: 0.01
Epoch: [72][ 0/51]	Time  2.938 ( 2.938)	Data  1.679 ( 1.679)	Loss 2.6490e-02 (2.6490e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [72][10/51]	Time  1.399 ( 1.924)	Data  0.877 ( 1.085)	Loss 1.9649e-02 (4.6751e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [72][20/51]	Time  0.960 ( 1.752)	Data  0.419 ( 0.981)	Loss 2.3987e-02 (4.7318e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.78)
Epoch: [72][30/51]	Time  1.468 ( 1.654)	Data  0.942 ( 0.942)	Loss 2.6075e-02 (5.2801e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.80)
Epoch: [72][40/51]	Time  2.675 ( 1.562)	Data  1.703 ( 0.868)	Loss 4.3132e-02 (5.2489e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.81)
Epoch: [72][50/51]	Time  2.212 ( 1.668)	Data  1.191 ( 0.927)	Loss 8.4881e-02 (5.4705e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.78)
learning rate is: 0.01
Epoch: [73][ 0/51]	Time  2.861 ( 2.861)	Data  1.612 ( 1.612)	Loss 6.0596e-02 (6.0596e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [73][10/51]	Time  2.945 ( 2.814)	Data  1.892 ( 1.803)	Loss 8.4261e-02 (5.4809e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [73][20/51]	Time  1.100 ( 2.245)	Data  0.568 ( 1.360)	Loss 7.1209e-02 (7.3833e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.78)
Epoch: [73][30/51]	Time  1.837 ( 2.220)	Data  1.070 ( 1.317)	Loss 1.0293e-01 (6.7581e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 ( 99.75)
Epoch: [73][40/51]	Time  3.161 ( 2.063)	Data  1.794 ( 1.170)	Loss 8.1919e-02 (6.8414e-02)	Acc@1  98.44 ( 98.32)	Acc@5  98.44 ( 99.73)
Epoch: [73][50/51]	Time  2.235 ( 2.140)	Data  1.335 ( 1.220)	Loss 2.1472e-01 (6.8933e-02)	Acc@1  96.77 ( 98.24)	Acc@5 100.00 ( 99.72)
learning rate is: 0.01
Epoch: [74][ 0/51]	Time  1.428 ( 1.428)	Data  0.699 ( 0.699)	Loss 5.1546e-02 (5.1546e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [74][10/51]	Time  1.030 ( 1.552)	Data  0.439 ( 0.745)	Loss 5.4144e-03 (3.8305e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [74][20/51]	Time  1.222 ( 1.632)	Data  0.391 ( 0.844)	Loss 2.6259e-02 (4.5385e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.93)
Epoch: [74][30/51]	Time  0.995 ( 1.775)	Data  0.457 ( 0.943)	Loss 1.2476e-02 (4.4823e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.90)
Epoch: [74][40/51]	Time  2.843 ( 1.942)	Data  1.542 ( 1.060)	Loss 1.2329e-01 (4.6426e-02)	Acc@1  98.44 ( 98.59)	Acc@5  98.44 ( 99.85)
Epoch: [74][50/51]	Time  1.256 ( 2.011)	Data  0.270 ( 1.101)	Loss 1.6168e-01 (5.0069e-02)	Acc@1  93.55 ( 98.48)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  1.363 ( 1.363)	Loss 1.4101e-01 (1.4101e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.767 ( 1.764)	Loss 2.4127e-01 (1.8725e-01)	Acc@1  93.75 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.01
Epoch: [75][ 0/51]	Time  1.369 ( 1.369)	Data  0.619 ( 0.619)	Loss 8.8618e-02 (8.8618e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [75][10/51]	Time  1.414 ( 1.591)	Data  0.452 ( 0.775)	Loss 1.9679e-02 (8.4375e-02)	Acc@1 100.00 ( 97.73)	Acc@5 100.00 ( 99.57)
Epoch: [75][20/51]	Time  1.499 ( 1.509)	Data  0.688 ( 0.709)	Loss 1.5574e-02 (7.3268e-02)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 99.70)
Epoch: [75][30/51]	Time  1.111 ( 1.622)	Data  0.425 ( 0.789)	Loss 3.5306e-02 (8.4153e-02)	Acc@1  98.44 ( 97.63)	Acc@5 100.00 ( 99.60)
Epoch: [75][40/51]	Time  3.143 ( 1.661)	Data  1.851 ( 0.819)	Loss 1.0231e-01 (7.5137e-02)	Acc@1  96.88 ( 97.98)	Acc@5  98.44 ( 99.58)
Epoch: [75][50/51]	Time  2.073 ( 1.899)	Data  0.831 ( 0.987)	Loss 1.5099e-01 (7.5697e-02)	Acc@1  96.77 ( 97.99)	Acc@5 100.00 ( 99.60)
learning rate is: 0.01
Epoch: [76][ 0/51]	Time  3.369 ( 3.369)	Data  1.906 ( 1.906)	Loss 6.2755e-03 (6.2755e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [76][10/51]	Time  2.621 ( 2.673)	Data  1.791 ( 1.586)	Loss 2.5381e-02 (7.3695e-02)	Acc@1 100.00 ( 97.73)	Acc@5 100.00 (100.00)
Epoch: [76][20/51]	Time  1.359 ( 2.346)	Data  0.569 ( 1.318)	Loss 1.0520e-01 (6.4335e-02)	Acc@1  96.88 ( 97.84)	Acc@5  98.44 ( 99.93)
Epoch: [76][30/51]	Time  1.294 ( 2.059)	Data  0.485 ( 1.102)	Loss 1.2766e-01 (6.4232e-02)	Acc@1  98.44 ( 98.03)	Acc@5  98.44 ( 99.85)
Epoch: [76][40/51]	Time  3.245 ( 2.003)	Data  1.972 ( 1.058)	Loss 2.0313e-01 (6.8201e-02)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.81)
Epoch: [76][50/51]	Time  0.987 ( 2.019)	Data  0.211 ( 1.071)	Loss 2.3247e-01 (6.9715e-02)	Acc@1  90.32 ( 98.02)	Acc@5 100.00 ( 99.75)
learning rate is: 0.01
Epoch: [77][ 0/51]	Time  1.336 ( 1.336)	Data  0.559 ( 0.559)	Loss 2.3600e-02 (2.3600e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [77][10/51]	Time  1.188 ( 2.003)	Data  0.481 ( 1.057)	Loss 2.0829e-01 (7.1772e-02)	Acc@1  95.31 ( 97.73)	Acc@5  98.44 ( 99.86)
Epoch: [77][20/51]	Time  1.253 ( 1.805)	Data  0.736 ( 0.978)	Loss 2.8183e-02 (5.8987e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.85)
Epoch: [77][30/51]	Time  3.433 ( 2.100)	Data  2.272 ( 1.205)	Loss 3.6012e-02 (6.3590e-02)	Acc@1  98.44 ( 98.19)	Acc@5 100.00 ( 99.70)
Epoch: [77][40/51]	Time  3.719 ( 2.368)	Data  2.482 ( 1.408)	Loss 2.8649e-02 (5.7905e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.77)
Epoch: [77][50/51]	Time  2.110 ( 2.344)	Data  0.915 ( 1.382)	Loss 1.3879e-01 (5.6574e-02)	Acc@1  93.55 ( 98.45)	Acc@5 100.00 ( 99.75)
learning rate is: 0.01
Epoch: [78][ 0/51]	Time  3.593 ( 3.593)	Data  2.452 ( 2.452)	Loss 1.0738e-01 (1.0738e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [78][10/51]	Time  1.212 ( 2.618)	Data  0.540 ( 1.635)	Loss 1.8791e-02 (5.9952e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.57)
Epoch: [78][20/51]	Time  2.996 ( 2.410)	Data  1.800 ( 1.448)	Loss 1.1892e-02 (5.3169e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [78][30/51]	Time  2.656 ( 2.595)	Data  1.634 ( 1.568)	Loss 6.0094e-03 (5.0894e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.80)
Epoch: [78][40/51]	Time  1.751 ( 2.491)	Data  0.567 ( 1.466)	Loss 2.1748e-02 (4.8566e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 ( 99.81)
Epoch: [78][50/51]	Time  1.808 ( 2.406)	Data  0.824 ( 1.418)	Loss 1.4786e-01 (5.5384e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.81)
learning rate is: 0.01
Epoch: [79][ 0/51]	Time  2.777 ( 2.777)	Data  1.650 ( 1.650)	Loss 3.9722e-02 (3.9722e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [79][10/51]	Time  2.777 ( 3.082)	Data  1.556 ( 1.956)	Loss 3.3158e-02 (2.9982e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [79][20/51]	Time  1.338 ( 2.585)	Data  0.727 ( 1.606)	Loss 1.1672e-01 (4.9629e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.78)
Epoch: [79][30/51]	Time  1.114 ( 2.193)	Data  0.586 ( 1.314)	Loss 1.9799e-02 (4.7647e-02)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [79][40/51]	Time  2.824 ( 2.075)	Data  1.691 ( 1.224)	Loss 4.4534e-02 (4.7954e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.81)
Epoch: [79][50/51]	Time  1.308 ( 1.907)	Data  0.309 ( 1.100)	Loss 1.6484e-01 (5.4435e-02)	Acc@1  96.77 ( 98.58)	Acc@5  96.77 ( 99.72)
Test: [0/8]	Time  3.092 ( 3.092)	Loss 1.1291e-01 (1.1291e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  3.023 ( 2.815)	Loss 2.4158e-01 (1.7949e-01)	Acc@1  95.31 ( 94.79)	Acc@5 100.00 ( 99.74)
 * Acc@1 95.000 Acc@5 99.800
learning rate is: 0.001
Epoch: [80][ 0/51]	Time  1.871 ( 1.871)	Data  0.580 ( 0.580)	Loss 6.9772e-02 (6.9772e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [80][10/51]	Time  1.058 ( 1.283)	Data  0.527 ( 0.606)	Loss 1.0749e-01 (6.2604e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 99.72)
Epoch: [80][20/51]	Time  2.614 ( 1.432)	Data  1.735 ( 0.717)	Loss 2.4556e-02 (7.0159e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.48)
Epoch: [80][30/51]	Time  2.794 ( 1.587)	Data  1.756 ( 0.822)	Loss 5.6561e-02 (6.5240e-02)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.50)
Epoch: [80][40/51]	Time  0.987 ( 1.488)	Data  0.424 ( 0.756)	Loss 1.1190e-01 (6.5629e-02)	Acc@1  96.88 ( 98.48)	Acc@5  98.44 ( 99.50)
Epoch: [80][50/51]	Time  0.792 ( 1.452)	Data  0.332 ( 0.734)	Loss 4.1408e-02 (6.5285e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.54)
learning rate is: 0.001
Epoch: [81][ 0/51]	Time  0.970 ( 0.970)	Data  0.426 ( 0.426)	Loss 1.0734e-01 (1.0734e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [81][10/51]	Time  2.726 ( 1.872)	Data  1.605 ( 1.060)	Loss 2.5511e-02 (6.1782e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.72)
Epoch: [81][20/51]	Time  1.574 ( 1.930)	Data  0.671 ( 1.107)	Loss 7.8825e-02 (5.2338e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [81][30/51]	Time  2.759 ( 1.903)	Data  1.829 ( 1.106)	Loss 2.2550e-02 (5.0947e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [81][40/51]	Time  1.457 ( 1.873)	Data  0.748 ( 1.071)	Loss 8.9350e-02 (5.4348e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.77)
Epoch: [81][50/51]	Time  2.117 ( 1.777)	Data  1.189 ( 1.001)	Loss 2.6119e-01 (5.7019e-02)	Acc@1  96.77 ( 98.36)	Acc@5  96.77 ( 99.69)
learning rate is: 0.001
Epoch: [82][ 0/51]	Time  2.635 ( 2.635)	Data  1.724 ( 1.724)	Loss 3.6902e-02 (3.6902e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [82][10/51]	Time  1.607 ( 1.640)	Data  0.556 ( 0.898)	Loss 2.8772e-02 (5.0198e-02)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [82][20/51]	Time  1.298 ( 1.943)	Data  0.501 ( 1.094)	Loss 1.7373e-02 (5.2776e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.78)
Epoch: [82][30/51]	Time  2.965 ( 2.050)	Data  1.840 ( 1.164)	Loss 4.4777e-03 (5.2163e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.85)
Epoch: [82][40/51]	Time  2.676 ( 2.246)	Data  1.779 ( 1.296)	Loss 1.0523e-01 (5.8654e-02)	Acc@1  98.44 ( 98.48)	Acc@5  98.44 ( 99.73)
Epoch: [82][50/51]	Time  2.091 ( 2.289)	Data  0.872 ( 1.311)	Loss 1.6421e-01 (5.8490e-02)	Acc@1  96.77 ( 98.36)	Acc@5  96.77 ( 99.72)
learning rate is: 0.001
Epoch: [83][ 0/51]	Time  3.286 ( 3.286)	Data  2.113 ( 2.113)	Loss 1.4928e-01 (1.4928e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [83][10/51]	Time  1.756 ( 2.133)	Data  0.787 ( 1.235)	Loss 1.8973e-01 (7.5736e-02)	Acc@1  95.31 ( 98.01)	Acc@5  98.44 ( 99.72)
Epoch: [83][20/51]	Time  1.160 ( 1.985)	Data  0.630 ( 1.167)	Loss 5.6602e-02 (5.7832e-02)	Acc@1  95.31 ( 98.44)	Acc@5 100.00 ( 99.78)
Epoch: [83][30/51]	Time  1.095 ( 1.759)	Data  0.536 ( 1.004)	Loss 6.0673e-02 (6.4834e-02)	Acc@1  96.88 ( 98.19)	Acc@5 100.00 ( 99.70)
Epoch: [83][40/51]	Time  1.242 ( 1.631)	Data  0.526 ( 0.922)	Loss 4.9758e-03 (6.0405e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.70)
Epoch: [83][50/51]	Time  2.546 ( 1.762)	Data  1.125 ( 1.001)	Loss 9.0003e-02 (5.9704e-02)	Acc@1  96.77 ( 98.36)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [84][ 0/51]	Time  3.146 ( 3.146)	Data  1.980 ( 1.980)	Loss 1.3774e-02 (1.3774e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [84][10/51]	Time  1.370 ( 2.354)	Data  0.581 ( 1.321)	Loss 3.3819e-02 (5.7428e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [84][20/51]	Time  1.172 ( 2.109)	Data  0.634 ( 1.154)	Loss 9.2026e-03 (5.8850e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [84][30/51]	Time  1.201 ( 1.821)	Data  0.588 ( 0.986)	Loss 2.0523e-02 (5.3519e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.90)
Epoch: [84][40/51]	Time  1.104 ( 1.713)	Data  0.466 ( 0.922)	Loss 2.5870e-02 (5.1076e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.89)
Epoch: [84][50/51]	Time  2.022 ( 1.702)	Data  0.971 ( 0.912)	Loss 3.6456e-01 (5.8410e-02)	Acc@1  93.55 ( 98.36)	Acc@5  93.55 ( 99.81)
Test: [0/8]	Time  3.136 ( 3.136)	Loss 1.1943e-01 (1.1943e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  1.068 ( 1.908)	Loss 2.2584e-01 (1.7769e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.001
Epoch: [85][ 0/51]	Time  2.506 ( 2.506)	Data  1.550 ( 1.550)	Loss 8.6675e-03 (8.6675e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [85][10/51]	Time  1.318 ( 1.955)	Data  0.738 ( 1.134)	Loss 1.6014e-02 (3.5230e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [85][20/51]	Time  2.686 ( 2.109)	Data  1.759 ( 1.242)	Loss 8.0537e-02 (3.9411e-02)	Acc@1  98.44 ( 99.26)	Acc@5 100.00 ( 99.85)
Epoch: [85][30/51]	Time  3.463 ( 2.406)	Data  2.351 ( 1.467)	Loss 8.8432e-02 (4.2485e-02)	Acc@1  96.88 ( 98.94)	Acc@5 100.00 ( 99.90)
Epoch: [85][40/51]	Time  2.669 ( 2.320)	Data  1.358 ( 1.371)	Loss 6.4492e-02 (4.9710e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.81)
Epoch: [85][50/51]	Time  1.269 ( 2.277)	Data  0.239 ( 1.329)	Loss 2.5947e-01 (5.1168e-02)	Acc@1  93.55 ( 98.70)	Acc@5  96.77 ( 99.81)
learning rate is: 0.001
Epoch: [86][ 0/51]	Time  2.984 ( 2.984)	Data  1.848 ( 1.848)	Loss 8.1713e-03 (8.1713e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [86][10/51]	Time  2.909 ( 2.107)	Data  1.852 ( 1.138)	Loss 1.3982e-02 (4.0679e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [86][20/51]	Time  1.171 ( 2.079)	Data  0.413 ( 1.124)	Loss 5.1739e-02 (4.4980e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [86][30/51]	Time  1.239 ( 1.893)	Data  0.484 ( 0.992)	Loss 7.1442e-02 (5.3942e-02)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.70)
Epoch: [86][40/51]	Time  3.548 ( 1.843)	Data  2.224 ( 0.947)	Loss 5.2506e-02 (5.1256e-02)	Acc@1  98.44 ( 98.51)	Acc@5  98.44 ( 99.73)
Epoch: [86][50/51]	Time  2.565 ( 2.108)	Data  1.310 ( 1.140)	Loss 1.2575e-02 (5.3101e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [87][ 0/51]	Time  3.293 ( 3.293)	Data  2.097 ( 2.097)	Loss 2.2142e-02 (2.2142e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [87][10/51]	Time  1.620 ( 1.869)	Data  0.733 ( 1.015)	Loss 1.7460e-01 (5.1839e-02)	Acc@1  93.75 ( 98.72)	Acc@5  98.44 ( 99.72)
Epoch: [87][20/51]	Time  1.460 ( 2.126)	Data  0.646 ( 1.168)	Loss 4.6953e-02 (4.7153e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.70)
Epoch: [87][30/51]	Time  3.023 ( 2.243)	Data  1.823 ( 1.227)	Loss 3.9563e-02 (4.6154e-02)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 ( 99.80)
Epoch: [87][40/51]	Time  1.678 ( 2.291)	Data  0.560 ( 1.263)	Loss 1.2774e-02 (4.6821e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.85)
Epoch: [87][50/51]	Time  0.884 ( 2.259)	Data  0.223 ( 1.266)	Loss 7.7361e-02 (5.4335e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [88][ 0/51]	Time  1.250 ( 1.250)	Data  0.622 ( 0.622)	Loss 1.4478e-01 (1.4478e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [88][10/51]	Time  1.242 ( 1.584)	Data  0.589 ( 0.841)	Loss 5.2317e-02 (4.1334e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [88][20/51]	Time  2.011 ( 1.529)	Data  1.268 ( 0.808)	Loss 1.0020e-01 (5.5220e-02)	Acc@1  98.44 ( 98.59)	Acc@5  98.44 ( 99.70)
Epoch: [88][30/51]	Time  1.293 ( 1.459)	Data  0.460 ( 0.762)	Loss 8.9953e-03 (5.7014e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [88][40/51]	Time  1.496 ( 1.620)	Data  0.746 ( 0.875)	Loss 1.6890e-02 (5.4584e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.77)
Epoch: [88][50/51]	Time  0.789 ( 1.605)	Data  0.261 ( 0.851)	Loss 2.0797e-01 (5.1712e-02)	Acc@1  96.77 ( 98.70)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [89][ 0/51]	Time  1.103 ( 1.103)	Data  0.482 ( 0.482)	Loss 9.6042e-03 (9.6042e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [89][10/51]	Time  1.361 ( 1.227)	Data  0.460 ( 0.564)	Loss 7.0964e-02 (5.7615e-02)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [89][20/51]	Time  0.954 ( 1.478)	Data  0.392 ( 0.764)	Loss 1.9759e-01 (6.3932e-02)	Acc@1  95.31 ( 98.14)	Acc@5  98.44 ( 99.85)
Epoch: [89][30/51]	Time  1.257 ( 1.479)	Data  0.722 ( 0.755)	Loss 3.7827e-03 (6.2235e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 ( 99.80)
Epoch: [89][40/51]	Time  1.524 ( 1.509)	Data  0.790 ( 0.774)	Loss 9.9039e-03 (5.4822e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.81)
Epoch: [89][50/51]	Time  2.016 ( 1.703)	Data  0.914 ( 0.893)	Loss 2.3251e-01 (6.4154e-02)	Acc@1  93.55 ( 98.45)	Acc@5  96.77 ( 99.69)
Test: [0/8]	Time  2.825 ( 2.825)	Loss 1.1979e-01 (1.1979e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.527 ( 2.734)	Loss 2.1525e-01 (1.7510e-01)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.800 Acc@5 99.600
learning rate is: 0.001
Epoch: [90][ 0/51]	Time  1.179 ( 1.179)	Data  0.633 ( 0.633)	Loss 3.7711e-02 (3.7711e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [90][10/51]	Time  1.614 ( 1.683)	Data  0.800 ( 0.858)	Loss 1.2496e-02 (4.1751e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [90][20/51]	Time  1.542 ( 1.574)	Data  0.697 ( 0.760)	Loss 5.9873e-02 (5.1385e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 (100.00)
Epoch: [90][30/51]	Time  2.970 ( 1.744)	Data  1.919 ( 0.917)	Loss 5.1876e-02 (5.2062e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.90)
Epoch: [90][40/51]	Time  1.387 ( 1.763)	Data  0.474 ( 0.928)	Loss 1.2655e-01 (5.1456e-02)	Acc@1  95.31 ( 98.51)	Acc@5 100.00 ( 99.89)
Epoch: [90][50/51]	Time  0.908 ( 1.711)	Data  0.257 ( 0.878)	Loss 1.8106e-01 (4.9040e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.91)
learning rate is: 0.001
Epoch: [91][ 0/51]	Time  1.198 ( 1.198)	Data  0.458 ( 0.458)	Loss 1.8465e-02 (1.8465e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [91][10/51]	Time  2.814 ( 1.944)	Data  1.887 ( 1.059)	Loss 8.8696e-02 (6.0080e-02)	Acc@1  96.88 ( 98.58)	Acc@5  98.44 ( 99.57)
Epoch: [91][20/51]	Time  3.197 ( 2.466)	Data  1.899 ( 1.432)	Loss 8.9014e-02 (6.1635e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.70)
Epoch: [91][30/51]	Time  3.087 ( 2.453)	Data  1.856 ( 1.438)	Loss 8.3012e-02 (5.7082e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.80)
Epoch: [91][40/51]	Time  1.574 ( 2.396)	Data  0.844 ( 1.385)	Loss 4.8365e-02 (6.1278e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.77)
Epoch: [91][50/51]	Time  1.072 ( 2.195)	Data  0.568 ( 1.239)	Loss 1.5773e-01 (6.2728e-02)	Acc@1  93.55 ( 98.30)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [92][ 0/51]	Time  1.154 ( 1.154)	Data  0.607 ( 0.607)	Loss 9.0898e-02 (9.0898e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [92][10/51]	Time  3.002 ( 1.373)	Data  1.952 ( 0.678)	Loss 6.7182e-02 (5.3362e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [92][20/51]	Time  1.030 ( 1.855)	Data  0.469 ( 1.029)	Loss 1.0141e-02 (5.7570e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [92][30/51]	Time  3.260 ( 2.033)	Data  1.944 ( 1.160)	Loss 7.1285e-02 (5.5654e-02)	Acc@1  96.88 ( 98.49)	Acc@5  98.44 ( 99.70)
Epoch: [92][40/51]	Time  3.236 ( 2.031)	Data  2.176 ( 1.144)	Loss 1.9010e-02 (4.8563e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.73)
Epoch: [92][50/51]	Time  1.096 ( 1.986)	Data  0.394 ( 1.105)	Loss 1.2655e-01 (5.5233e-02)	Acc@1  96.77 ( 98.58)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [93][ 0/51]	Time  1.048 ( 1.048)	Data  0.507 ( 0.507)	Loss 2.5149e-02 (2.5149e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [93][10/51]	Time  1.146 ( 1.317)	Data  0.495 ( 0.698)	Loss 8.3859e-02 (5.4313e-02)	Acc@1  96.88 ( 98.30)	Acc@5  98.44 ( 99.57)
Epoch: [93][20/51]	Time  1.104 ( 1.253)	Data  0.541 ( 0.661)	Loss 5.8048e-02 (5.0405e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [93][30/51]	Time  2.664 ( 1.496)	Data  1.715 ( 0.827)	Loss 1.7023e-02 (5.4444e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.50)
Epoch: [93][40/51]	Time  2.781 ( 1.787)	Data  1.863 ( 1.031)	Loss 4.9847e-02 (5.3175e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.58)
Epoch: [93][50/51]	Time  1.119 ( 1.904)	Data  0.372 ( 1.092)	Loss 3.6349e-01 (5.1841e-02)	Acc@1  93.55 ( 98.55)	Acc@5  93.55 ( 99.60)
learning rate is: 0.001
Epoch: [94][ 0/51]	Time  3.159 ( 3.159)	Data  1.980 ( 1.980)	Loss 3.5534e-02 (3.5534e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [94][10/51]	Time  1.316 ( 2.151)	Data  0.527 ( 1.214)	Loss 6.7945e-03 (4.2852e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [94][20/51]	Time  2.978 ( 2.038)	Data  1.568 ( 1.075)	Loss 9.3405e-02 (5.1823e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.85)
Epoch: [94][30/51]	Time  1.286 ( 2.010)	Data  0.474 ( 1.069)	Loss 1.1342e-01 (4.9993e-02)	Acc@1  96.88 ( 98.54)	Acc@5  98.44 ( 99.85)
Epoch: [94][40/51]	Time  1.354 ( 2.053)	Data  0.585 ( 1.097)	Loss 4.7897e-03 (5.3544e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.85)
Epoch: [94][50/51]	Time  0.951 ( 1.942)	Data  0.178 ( 1.020)	Loss 1.3597e-01 (5.5245e-02)	Acc@1  93.55 ( 98.42)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  0.835 ( 0.835)	Loss 1.1374e-01 (1.1374e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.177 ( 1.346)	Loss 2.0829e-01 (1.7119e-01)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.800 Acc@5 99.600
learning rate is: 0.001
Epoch: [95][ 0/51]	Time  3.374 ( 3.374)	Data  2.183 ( 2.183)	Loss 4.6160e-02 (4.6160e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [95][10/51]	Time  1.496 ( 2.502)	Data  0.713 ( 1.404)	Loss 1.6319e-02 (5.2922e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.57)
Epoch: [95][20/51]	Time  1.394 ( 2.497)	Data  0.452 ( 1.411)	Loss 1.0701e-01 (6.0927e-02)	Acc@1  96.88 ( 98.29)	Acc@5 100.00 ( 99.63)
Epoch: [95][30/51]	Time  3.362 ( 2.767)	Data  2.221 ( 1.637)	Loss 1.0851e-02 (6.0265e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.60)
Epoch: [95][40/51]	Time  1.846 ( 2.561)	Data  1.167 ( 1.503)	Loss 4.0210e-02 (6.1793e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 ( 99.62)
Epoch: [95][50/51]	Time  1.001 ( 2.447)	Data  0.254 ( 1.422)	Loss 7.9337e-02 (6.4930e-02)	Acc@1  96.77 ( 98.17)	Acc@5 100.00 ( 99.57)
learning rate is: 0.001
Epoch: [96][ 0/51]	Time  1.038 ( 1.038)	Data  0.505 ( 0.505)	Loss 8.8592e-03 (8.8592e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [96][10/51]	Time  1.737 ( 1.788)	Data  0.665 ( 0.969)	Loss 1.2903e-02 (4.8665e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [96][20/51]	Time  1.315 ( 1.833)	Data  0.496 ( 0.975)	Loss 3.4962e-02 (3.8793e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [96][30/51]	Time  3.290 ( 2.058)	Data  2.019 ( 1.130)	Loss 6.9356e-02 (4.1969e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [96][40/51]	Time  1.727 ( 2.307)	Data  0.752 ( 1.318)	Loss 2.2550e-02 (4.1556e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.81)
Epoch: [96][50/51]	Time  1.176 ( 2.348)	Data  0.500 ( 1.359)	Loss 1.4412e-01 (5.3328e-02)	Acc@1  96.77 ( 98.58)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [97][ 0/51]	Time  1.806 ( 1.806)	Data  0.870 ( 0.870)	Loss 4.0208e-02 (4.0208e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [97][10/51]	Time  2.756 ( 2.675)	Data  1.802 ( 1.618)	Loss 2.3313e-03 (6.1122e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [97][20/51]	Time  3.077 ( 2.408)	Data  1.935 ( 1.440)	Loss 2.0725e-02 (5.7990e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.63)
Epoch: [97][30/51]	Time  1.136 ( 2.168)	Data  0.498 ( 1.273)	Loss 6.4997e-02 (5.6429e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [97][40/51]	Time  2.804 ( 2.002)	Data  1.778 ( 1.152)	Loss 3.0006e-02 (5.7989e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.66)
Epoch: [97][50/51]	Time  2.026 ( 2.119)	Data  0.900 ( 1.240)	Loss 3.1034e-02 (5.7086e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.66)
learning rate is: 0.001
Epoch: [98][ 0/51]	Time  2.936 ( 2.936)	Data  1.914 ( 1.914)	Loss 1.0670e-01 (1.0670e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [98][10/51]	Time  1.694 ( 1.991)	Data  0.792 ( 1.099)	Loss 1.3875e-02 (3.8796e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [98][20/51]	Time  1.042 ( 1.860)	Data  0.512 ( 1.048)	Loss 4.0000e-02 (4.8626e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [98][30/51]	Time  1.367 ( 1.761)	Data  0.543 ( 0.937)	Loss 8.6507e-02 (5.1118e-02)	Acc@1  98.44 ( 98.74)	Acc@5  98.44 ( 99.85)
Epoch: [98][40/51]	Time  3.287 ( 1.754)	Data  1.945 ( 0.936)	Loss 1.0962e-02 (4.9019e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.85)
Epoch: [98][50/51]	Time  1.836 ( 1.881)	Data  0.858 ( 1.036)	Loss 2.7067e-01 (5.1506e-02)	Acc@1  93.55 ( 98.76)	Acc@5  96.77 ( 99.81)
learning rate is: 0.001
Epoch: [99][ 0/51]	Time  2.040 ( 2.040)	Data  0.839 ( 0.839)	Loss 1.0747e-01 (1.0747e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [99][10/51]	Time  2.876 ( 2.911)	Data  1.761 ( 1.779)	Loss 1.0326e-01 (7.3601e-02)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.29)
Epoch: [99][20/51]	Time  3.129 ( 2.890)	Data  2.022 ( 1.761)	Loss 3.1335e-02 (6.4813e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.55)
Epoch: [99][30/51]	Time  2.920 ( 2.687)	Data  1.915 ( 1.608)	Loss 1.0225e-01 (6.8752e-02)	Acc@1  96.88 ( 98.03)	Acc@5 100.00 ( 99.60)
Epoch: [99][40/51]	Time  1.232 ( 2.562)	Data  0.462 ( 1.515)	Loss 6.8174e-02 (6.4143e-02)	Acc@1  96.88 ( 98.13)	Acc@5 100.00 ( 99.62)
Epoch: [99][50/51]	Time  1.092 ( 2.371)	Data  0.340 ( 1.369)	Loss 4.3090e-02 (5.7587e-02)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 ( 99.66)
Test: [0/8]	Time  0.838 ( 0.838)	Loss 1.2822e-01 (1.2822e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.281 ( 2.047)	Loss 2.1009e-01 (1.7467e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.001
Epoch: [100][ 0/51]	Time  1.490 ( 1.490)	Data  0.518 ( 0.518)	Loss 9.6177e-02 (9.6177e-02)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [100][10/51]	Time  3.083 ( 2.371)	Data  2.072 ( 1.366)	Loss 2.2543e-02 (7.1212e-02)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.57)
Epoch: [100][20/51]	Time  1.081 ( 2.141)	Data  0.488 ( 1.189)	Loss 3.7532e-02 (5.9475e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.63)
Epoch: [100][30/51]	Time  3.373 ( 2.119)	Data  1.998 ( 1.171)	Loss 9.7766e-02 (5.0959e-02)	Acc@1  98.44 ( 98.79)	Acc@5  98.44 ( 99.65)
Epoch: [100][40/51]	Time  1.121 ( 2.162)	Data  0.565 ( 1.205)	Loss 5.3800e-02 (5.6161e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.62)
Epoch: [100][50/51]	Time  1.113 ( 2.014)	Data  0.355 ( 1.090)	Loss 1.0398e-01 (5.8580e-02)	Acc@1  93.55 ( 98.67)	Acc@5 100.00 ( 99.63)
learning rate is: 0.001
Epoch: [101][ 0/51]	Time  1.380 ( 1.380)	Data  0.757 ( 0.757)	Loss 2.8158e-01 (2.8158e-01)	Acc@1  95.31 ( 95.31)	Acc@5  95.31 ( 95.31)
Epoch: [101][10/51]	Time  1.425 ( 1.718)	Data  0.451 ( 0.839)	Loss 6.6806e-02 (8.4110e-02)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.29)
Epoch: [101][20/51]	Time  1.009 ( 2.133)	Data  0.460 ( 1.178)	Loss 4.0577e-02 (7.2620e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.40)
Epoch: [101][30/51]	Time  2.585 ( 2.302)	Data  1.864 ( 1.331)	Loss 3.8323e-02 (6.4895e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.50)
Epoch: [101][40/51]	Time  1.314 ( 2.076)	Data  0.511 ( 1.151)	Loss 6.9353e-02 (5.6277e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.62)
Epoch: [101][50/51]	Time  1.224 ( 2.067)	Data  0.495 ( 1.127)	Loss 1.7355e-01 (6.1267e-02)	Acc@1  96.77 ( 98.45)	Acc@5 100.00 ( 99.66)
learning rate is: 0.001
Epoch: [102][ 0/51]	Time  1.833 ( 1.833)	Data  1.091 ( 1.091)	Loss 3.8213e-02 (3.8213e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [102][10/51]	Time  1.037 ( 1.458)	Data  0.492 ( 0.784)	Loss 1.3948e-02 (7.9768e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.72)
Epoch: [102][20/51]	Time  1.085 ( 1.375)	Data  0.496 ( 0.674)	Loss 2.3268e-02 (6.6142e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.85)
Epoch: [102][30/51]	Time  2.700 ( 1.574)	Data  1.698 ( 0.811)	Loss 3.1571e-02 (6.2988e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.85)
Epoch: [102][40/51]	Time  3.075 ( 1.657)	Data  2.014 ( 0.871)	Loss 7.5037e-02 (5.8012e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.85)
Epoch: [102][50/51]	Time  1.040 ( 1.822)	Data  0.278 ( 0.984)	Loss 7.6194e-02 (5.7125e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [103][ 0/51]	Time  3.467 ( 3.467)	Data  2.070 ( 2.070)	Loss 3.2644e-02 (3.2644e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [103][10/51]	Time  1.237 ( 2.473)	Data  0.480 ( 1.371)	Loss 9.6219e-02 (6.5103e-02)	Acc@1  96.88 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [103][20/51]	Time  2.832 ( 2.259)	Data  1.769 ( 1.252)	Loss 4.8566e-02 (6.5111e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.70)
Epoch: [103][30/51]	Time  3.262 ( 2.208)	Data  2.119 ( 1.221)	Loss 6.2938e-02 (7.1111e-02)	Acc@1  98.44 ( 98.19)	Acc@5 100.00 ( 99.60)
Epoch: [103][40/51]	Time  3.076 ( 2.052)	Data  1.741 ( 1.115)	Loss 1.5654e-02 (6.6609e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.58)
Epoch: [103][50/51]	Time  1.932 ( 2.124)	Data  0.901 ( 1.180)	Loss 2.1920e-01 (6.4728e-02)	Acc@1  93.55 ( 98.42)	Acc@5  96.77 ( 99.57)
learning rate is: 0.001
Epoch: [104][ 0/51]	Time  1.879 ( 1.879)	Data  0.811 ( 0.811)	Loss 3.0694e-02 (3.0694e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [104][10/51]	Time  3.238 ( 2.414)	Data  1.936 ( 1.350)	Loss 4.7026e-02 (5.6732e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.72)
Epoch: [104][20/51]	Time  2.832 ( 2.463)	Data  1.944 ( 1.402)	Loss 8.7664e-02 (5.7020e-02)	Acc@1  96.88 ( 98.21)	Acc@5 100.00 ( 99.63)
Epoch: [104][30/51]	Time  1.645 ( 2.549)	Data  0.679 ( 1.502)	Loss 5.6964e-02 (5.7022e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 ( 99.70)
Epoch: [104][40/51]	Time  1.530 ( 2.289)	Data  0.772 ( 1.294)	Loss 6.0589e-02 (5.7241e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.73)
Epoch: [104][50/51]	Time  0.990 ( 2.098)	Data  0.235 ( 1.145)	Loss 3.5441e-02 (5.4263e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  0.813 ( 0.813)	Loss 1.1972e-01 (1.1972e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.706 ( 0.820)	Loss 1.9321e-01 (1.6960e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.001
Epoch: [105][ 0/51]	Time  1.459 ( 1.459)	Data  0.810 ( 0.810)	Loss 8.6834e-03 (8.6834e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [105][10/51]	Time  2.972 ( 2.760)	Data  1.848 ( 1.703)	Loss 1.4858e-02 (3.0011e-02)	Acc@1 100.00 ( 99.43)	Acc@5 100.00 ( 99.86)
Epoch: [105][20/51]	Time  3.029 ( 2.858)	Data  1.770 ( 1.737)	Loss 1.0014e-01 (3.8411e-02)	Acc@1  96.88 ( 99.03)	Acc@5 100.00 ( 99.93)
Epoch: [105][30/51]	Time  3.178 ( 2.867)	Data  2.022 ( 1.736)	Loss 1.1847e-01 (3.8196e-02)	Acc@1  98.44 ( 99.09)	Acc@5  98.44 ( 99.85)
Epoch: [105][40/51]	Time  1.408 ( 2.543)	Data  0.744 ( 1.514)	Loss 4.9897e-03 (3.9038e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.85)
Epoch: [105][50/51]	Time  0.945 ( 2.454)	Data  0.461 ( 1.451)	Loss 1.0299e-01 (3.8993e-02)	Acc@1  96.77 ( 99.01)	Acc@5 100.00 ( 99.88)
learning rate is: 0.001
Epoch: [106][ 0/51]	Time  1.641 ( 1.641)	Data  0.735 ( 0.735)	Loss 5.1103e-02 (5.1103e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [106][10/51]	Time  3.093 ( 2.753)	Data  1.808 ( 1.655)	Loss 1.9220e-02 (4.0417e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [106][20/51]	Time  1.295 ( 2.825)	Data  0.530 ( 1.700)	Loss 1.8574e-02 (4.1579e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.93)
Epoch: [106][30/51]	Time  3.217 ( 2.490)	Data  1.996 ( 1.411)	Loss 8.2616e-02 (4.3782e-02)	Acc@1  98.44 ( 98.79)	Acc@5  98.44 ( 99.90)
Epoch: [106][40/51]	Time  1.876 ( 2.451)	Data  0.960 ( 1.396)	Loss 5.6581e-03 (4.4638e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.85)
Epoch: [106][50/51]	Time  1.929 ( 2.372)	Data  0.883 ( 1.350)	Loss 1.4230e-01 (4.7710e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [107][ 0/51]	Time  3.230 ( 3.230)	Data  2.103 ( 2.103)	Loss 7.6310e-02 (7.6310e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [107][10/51]	Time  1.739 ( 2.820)	Data  0.763 ( 1.708)	Loss 2.2701e-02 (6.9055e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.57)
Epoch: [107][20/51]	Time  3.378 ( 2.326)	Data  2.440 ( 1.334)	Loss 4.4523e-02 (6.0480e-02)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 ( 99.70)
Epoch: [107][30/51]	Time  1.497 ( 2.301)	Data  0.734 ( 1.362)	Loss 3.9259e-02 (6.0064e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.75)
Epoch: [107][40/51]	Time  2.465 ( 2.099)	Data  1.323 ( 1.212)	Loss 1.6259e-02 (5.3303e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.81)
Epoch: [107][50/51]	Time  0.835 ( 1.954)	Data  0.287 ( 1.125)	Loss 1.7692e-01 (5.5626e-02)	Acc@1  93.55 ( 98.30)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [108][ 0/51]	Time  1.203 ( 1.203)	Data  0.440 ( 0.440)	Loss 4.7729e-03 (4.7729e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [108][10/51]	Time  3.057 ( 2.841)	Data  2.089 ( 1.779)	Loss 1.1680e-02 (3.8351e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [108][20/51]	Time  2.684 ( 2.481)	Data  1.767 ( 1.535)	Loss 1.9216e-02 (3.8489e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [108][30/51]	Time  1.149 ( 2.244)	Data  0.572 ( 1.355)	Loss 1.2202e-01 (4.1544e-02)	Acc@1  96.88 ( 98.69)	Acc@5  98.44 ( 99.85)
Epoch: [108][40/51]	Time  1.129 ( 2.019)	Data  0.586 ( 1.203)	Loss 2.3736e-02 (4.5670e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.85)
Epoch: [108][50/51]	Time  0.777 ( 1.906)	Data  0.290 ( 1.125)	Loss 3.4505e-01 (4.8503e-02)	Acc@1  93.55 ( 98.55)	Acc@5  96.77 ( 99.85)
learning rate is: 0.001
Epoch: [109][ 0/51]	Time  1.089 ( 1.089)	Data  0.531 ( 0.531)	Loss 3.4083e-02 (3.4083e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [109][10/51]	Time  1.212 ( 1.172)	Data  0.670 ( 0.578)	Loss 6.9865e-03 (5.8951e-02)	Acc@1 100.00 ( 97.87)	Acc@5 100.00 ( 99.86)
Epoch: [109][20/51]	Time  2.966 ( 1.806)	Data  1.771 ( 0.996)	Loss 8.6488e-02 (5.8967e-02)	Acc@1  98.44 ( 98.07)	Acc@5 100.00 ( 99.78)
Epoch: [109][30/51]	Time  1.094 ( 1.825)	Data  0.447 ( 0.980)	Loss 5.1690e-02 (6.3004e-02)	Acc@1  96.88 ( 97.83)	Acc@5 100.00 ( 99.70)
Epoch: [109][40/51]	Time  2.835 ( 1.872)	Data  1.675 ( 1.006)	Loss 4.4120e-03 (5.6174e-02)	Acc@1 100.00 ( 98.17)	Acc@5 100.00 ( 99.73)
Epoch: [109][50/51]	Time  2.243 ( 2.084)	Data  0.947 ( 1.154)	Loss 1.5926e-01 (5.5075e-02)	Acc@1  93.55 ( 98.27)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  2.987 ( 2.987)	Loss 1.2433e-01 (1.2433e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Test: [5/8]	Time  0.828 ( 1.878)	Loss 2.0603e-01 (1.7403e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.74)
 * Acc@1 95.600 Acc@5 99.800
learning rate is: 0.001
Epoch: [110][ 0/51]	Time  1.531 ( 1.531)	Data  0.502 ( 0.502)	Loss 4.2419e-02 (4.2419e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [110][10/51]	Time  3.180 ( 2.249)	Data  2.190 ( 1.303)	Loss 2.2753e-02 (5.2898e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [110][20/51]	Time  1.224 ( 2.001)	Data  0.608 ( 1.130)	Loss 3.8481e-02 (5.6241e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [110][30/51]	Time  1.022 ( 1.899)	Data  0.452 ( 1.050)	Loss 6.7938e-02 (5.9388e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.80)
Epoch: [110][40/51]	Time  2.937 ( 2.111)	Data  1.729 ( 1.220)	Loss 2.0818e-02 (5.8395e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.85)
Epoch: [110][50/51]	Time  0.714 ( 2.009)	Data  0.216 ( 1.156)	Loss 7.5481e-03 (5.8694e-02)	Acc@1 100.00 ( 98.24)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [111][ 0/51]	Time  1.207 ( 1.207)	Data  0.632 ( 0.632)	Loss 7.5000e-02 (7.5000e-02)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [111][10/51]	Time  2.952 ( 2.084)	Data  1.837 ( 1.239)	Loss 1.8142e-02 (3.5340e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [111][20/51]	Time  3.040 ( 1.999)	Data  2.136 ( 1.171)	Loss 2.7559e-02 (4.0883e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.70)
Epoch: [111][30/51]	Time  1.790 ( 1.996)	Data  1.038 ( 1.159)	Loss 7.3321e-02 (5.1103e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [111][40/51]	Time  1.591 ( 2.101)	Data  0.836 ( 1.218)	Loss 1.5911e-01 (6.0191e-02)	Acc@1  96.88 ( 98.51)	Acc@5  98.44 ( 99.66)
Epoch: [111][50/51]	Time  1.339 ( 2.055)	Data  0.455 ( 1.165)	Loss 1.9107e-01 (6.1502e-02)	Acc@1  96.77 ( 98.45)	Acc@5  96.77 ( 99.60)
learning rate is: 0.001
Epoch: [112][ 0/51]	Time  3.057 ( 3.057)	Data  1.823 ( 1.823)	Loss 4.1643e-02 (4.1643e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [112][10/51]	Time  1.172 ( 1.575)	Data  0.608 ( 0.860)	Loss 3.2950e-02 (5.4054e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [112][20/51]	Time  1.161 ( 1.385)	Data  0.621 ( 0.736)	Loss 3.9474e-02 (5.4669e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [112][30/51]	Time  1.637 ( 1.512)	Data  0.747 ( 0.799)	Loss 1.4904e-01 (6.5406e-02)	Acc@1  96.88 ( 98.24)	Acc@5  98.44 ( 99.70)
Epoch: [112][40/51]	Time  1.441 ( 1.632)	Data  0.676 ( 0.860)	Loss 2.6477e-02 (5.8840e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.70)
Epoch: [112][50/51]	Time  0.886 ( 1.614)	Data  0.420 ( 0.841)	Loss 9.8396e-02 (5.9565e-02)	Acc@1  96.77 ( 98.33)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [113][ 0/51]	Time  1.072 ( 1.072)	Data  0.523 ( 0.523)	Loss 1.1916e-01 (1.1916e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [113][10/51]	Time  1.782 ( 2.533)	Data  0.642 ( 1.411)	Loss 1.0118e-02 (4.2609e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [113][20/51]	Time  3.443 ( 2.451)	Data  2.268 ( 1.369)	Loss 3.2897e-02 (5.2678e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.78)
Epoch: [113][30/51]	Time  1.987 ( 2.405)	Data  1.186 ( 1.348)	Loss 2.8649e-02 (4.8892e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 ( 99.85)
Epoch: [113][40/51]	Time  2.975 ( 2.231)	Data  1.688 ( 1.229)	Loss 3.2516e-02 (4.7352e-02)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 ( 99.89)
Epoch: [113][50/51]	Time  1.110 ( 2.145)	Data  0.370 ( 1.173)	Loss 1.3494e-02 (4.9818e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [114][ 0/51]	Time  1.146 ( 1.146)	Data  0.430 ( 0.430)	Loss 2.7037e-03 (2.7037e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [114][10/51]	Time  1.155 ( 1.157)	Data  0.487 ( 0.533)	Loss 1.5375e-02 (6.4465e-02)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.43)
Epoch: [114][20/51]	Time  1.093 ( 1.585)	Data  0.467 ( 0.839)	Loss 5.6095e-03 (4.4717e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.70)
Epoch: [114][30/51]	Time  2.648 ( 1.699)	Data  1.622 ( 0.936)	Loss 1.7558e-02 (4.2806e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 ( 99.75)
Epoch: [114][40/51]	Time  1.536 ( 1.610)	Data  0.621 ( 0.874)	Loss 1.6479e-01 (4.6506e-02)	Acc@1  96.88 ( 98.82)	Acc@5  98.44 ( 99.77)
Epoch: [114][50/51]	Time  1.166 ( 1.572)	Data  0.452 ( 0.855)	Loss 1.2214e-01 (4.9415e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.72)
Test: [0/8]	Time  0.947 ( 0.947)	Loss 1.2715e-01 (1.2715e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.885 ( 1.098)	Loss 1.8452e-01 (1.7254e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.001
Epoch: [115][ 0/51]	Time  1.172 ( 1.172)	Data  0.472 ( 0.472)	Loss 1.0946e-01 (1.0946e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [115][10/51]	Time  1.070 ( 1.537)	Data  0.444 ( 0.749)	Loss 4.2108e-02 (6.0978e-02)	Acc@1  96.88 ( 98.15)	Acc@5 100.00 (100.00)
Epoch: [115][20/51]	Time  1.120 ( 1.390)	Data  0.473 ( 0.668)	Loss 7.9908e-02 (6.6614e-02)	Acc@1  96.88 ( 98.07)	Acc@5 100.00 ( 99.93)
Epoch: [115][30/51]	Time  0.989 ( 1.555)	Data  0.451 ( 0.807)	Loss 1.8503e-02 (6.7897e-02)	Acc@1 100.00 ( 98.03)	Acc@5 100.00 ( 99.80)
Epoch: [115][40/51]	Time  1.171 ( 1.531)	Data  0.628 ( 0.792)	Loss 3.7404e-02 (5.9542e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.85)
Epoch: [115][50/51]	Time  1.991 ( 1.611)	Data  0.978 ( 0.843)	Loss 2.3291e-01 (6.0630e-02)	Acc@1  93.55 ( 98.24)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [116][ 0/51]	Time  3.016 ( 3.016)	Data  1.875 ( 1.875)	Loss 4.3548e-02 (4.3548e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [116][10/51]	Time  1.290 ( 2.067)	Data  0.467 ( 1.113)	Loss 9.6154e-03 (7.4957e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [116][20/51]	Time  1.216 ( 1.951)	Data  0.574 ( 1.072)	Loss 9.2492e-02 (6.9727e-02)	Acc@1  95.31 ( 97.92)	Acc@5 100.00 ( 99.70)
Epoch: [116][30/51]	Time  1.128 ( 1.695)	Data  0.481 ( 0.903)	Loss 3.1284e-02 (6.7192e-02)	Acc@1 100.00 ( 98.03)	Acc@5 100.00 ( 99.75)
Epoch: [116][40/51]	Time  1.601 ( 1.757)	Data  0.961 ( 0.945)	Loss 1.4899e-02 (6.0971e-02)	Acc@1 100.00 ( 98.25)	Acc@5 100.00 ( 99.77)
Epoch: [116][50/51]	Time  2.107 ( 1.969)	Data  0.915 ( 1.098)	Loss 5.1483e-02 (6.0763e-02)	Acc@1 100.00 ( 98.27)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [117][ 0/51]	Time  2.961 ( 2.961)	Data  1.968 ( 1.968)	Loss 1.1446e-02 (1.1446e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [117][10/51]	Time  1.950 ( 1.773)	Data  1.297 ( 0.980)	Loss 1.0386e-01 (6.0318e-02)	Acc@1  98.44 ( 98.72)	Acc@5  98.44 ( 99.43)
Epoch: [117][20/51]	Time  3.039 ( 1.627)	Data  1.895 ( 0.839)	Loss 5.2799e-03 (4.3489e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.70)
Epoch: [117][30/51]	Time  1.317 ( 1.716)	Data  0.680 ( 0.902)	Loss 1.2764e-01 (4.3891e-02)	Acc@1  96.88 ( 98.94)	Acc@5  98.44 ( 99.75)
Epoch: [117][40/51]	Time  1.516 ( 1.694)	Data  0.451 ( 0.866)	Loss 1.4100e-01 (4.4841e-02)	Acc@1  96.88 ( 98.93)	Acc@5  98.44 ( 99.70)
Epoch: [117][50/51]	Time  1.047 ( 1.644)	Data  0.241 ( 0.831)	Loss 3.9395e-02 (4.5502e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [118][ 0/51]	Time  1.306 ( 1.306)	Data  0.521 ( 0.521)	Loss 5.4235e-03 (5.4235e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [118][10/51]	Time  3.163 ( 2.177)	Data  2.197 ( 1.208)	Loss 2.9941e-02 (2.8888e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [118][20/51]	Time  3.312 ( 2.282)	Data  2.099 ( 1.352)	Loss 8.8727e-03 (3.8036e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [118][30/51]	Time  1.504 ( 2.049)	Data  0.959 ( 1.210)	Loss 2.7094e-02 (5.2788e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.80)
Epoch: [118][40/51]	Time  1.169 ( 1.849)	Data  0.514 ( 1.078)	Loss 1.7382e-02 (5.1844e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.73)
Epoch: [118][50/51]	Time  0.744 ( 1.894)	Data  0.231 ( 1.108)	Loss 1.2550e-01 (5.2580e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [119][ 0/51]	Time  0.994 ( 0.994)	Data  0.462 ( 0.462)	Loss 3.5549e-02 (3.5549e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [119][10/51]	Time  1.107 ( 1.460)	Data  0.497 ( 0.787)	Loss 4.1195e-02 (3.5147e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [119][20/51]	Time  1.016 ( 1.622)	Data  0.441 ( 0.922)	Loss 3.0245e-02 (4.0131e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [119][30/51]	Time  1.170 ( 1.457)	Data  0.612 ( 0.792)	Loss 2.5077e-02 (4.3843e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.90)
Epoch: [119][40/51]	Time  1.634 ( 1.434)	Data  1.019 ( 0.767)	Loss 3.2355e-02 (4.2622e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.89)
Epoch: [119][50/51]	Time  0.965 ( 1.535)	Data  0.219 ( 0.831)	Loss 3.2412e-02 (4.4078e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.88)
Test: [0/8]	Time  0.866 ( 0.866)	Loss 1.3962e-01 (1.3962e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.320 ( 1.270)	Loss 1.8736e-01 (1.7302e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.001
Epoch: [120][ 0/51]	Time  3.359 ( 3.359)	Data  2.046 ( 2.046)	Loss 3.5954e-01 (3.5954e-01)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [120][10/51]	Time  1.060 ( 2.489)	Data  0.430 ( 1.407)	Loss 7.6580e-02 (9.4394e-02)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 99.43)
Epoch: [120][20/51]	Time  1.044 ( 1.967)	Data  0.487 ( 1.053)	Loss 1.2602e-01 (7.2031e-02)	Acc@1  96.88 ( 98.21)	Acc@5  98.44 ( 99.63)
Epoch: [120][30/51]	Time  1.600 ( 1.989)	Data  0.637 ( 1.083)	Loss 1.0803e-02 (6.4240e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.75)
Epoch: [120][40/51]	Time  1.110 ( 1.924)	Data  0.559 ( 1.026)	Loss 1.2080e-02 (6.2131e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.81)
Epoch: [120][50/51]	Time  2.356 ( 1.851)	Data  1.136 ( 0.970)	Loss 3.1717e-02 (5.7673e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [121][ 0/51]	Time  1.838 ( 1.838)	Data  0.911 ( 0.911)	Loss 2.4382e-02 (2.4382e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [121][10/51]	Time  1.528 ( 2.044)	Data  0.754 ( 1.114)	Loss 4.3466e-03 (4.4997e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [121][20/51]	Time  1.249 ( 1.823)	Data  0.478 ( 0.917)	Loss 1.6940e-02 (4.2267e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [121][30/51]	Time  0.955 ( 1.670)	Data  0.435 ( 0.818)	Loss 1.3645e-02 (4.2927e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.80)
Epoch: [121][40/51]	Time  3.211 ( 1.851)	Data  2.147 ( 0.974)	Loss 1.5131e-02 (4.1067e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.85)
Epoch: [121][50/51]	Time  0.731 ( 1.940)	Data  0.234 ( 1.059)	Loss 4.7068e-02 (4.1943e-02)	Acc@1 100.00 ( 98.98)	Acc@5 100.00 ( 99.88)
learning rate is: 0.001
Epoch: [122][ 0/51]	Time  1.006 ( 1.006)	Data  0.459 ( 0.459)	Loss 4.5493e-03 (4.5493e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [122][10/51]	Time  3.068 ( 1.831)	Data  2.084 ( 1.006)	Loss 4.4271e-03 (3.2886e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [122][20/51]	Time  1.550 ( 1.723)	Data  0.872 ( 0.957)	Loss 4.8196e-02 (4.4012e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.85)
Epoch: [122][30/51]	Time  2.676 ( 1.875)	Data  1.773 ( 1.074)	Loss 9.9118e-02 (5.1113e-02)	Acc@1  96.88 ( 98.84)	Acc@5 100.00 ( 99.80)
Epoch: [122][40/51]	Time  2.750 ( 2.045)	Data  1.786 ( 1.182)	Loss 1.0807e-02 (5.2882e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.73)
Epoch: [122][50/51]	Time  2.076 ( 2.159)	Data  1.245 ( 1.275)	Loss 3.5646e-01 (5.5197e-02)	Acc@1  90.32 ( 98.67)	Acc@5  96.77 ( 99.69)
learning rate is: 0.001
Epoch: [123][ 0/51]	Time  3.376 ( 3.376)	Data  2.248 ( 2.248)	Loss 3.5896e-02 (3.5896e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [123][10/51]	Time  1.271 ( 1.857)	Data  0.494 ( 1.011)	Loss 7.3513e-02 (4.9214e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [123][20/51]	Time  1.257 ( 1.651)	Data  0.604 ( 0.875)	Loss 2.4411e-02 (5.1958e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.93)
Epoch: [123][30/51]	Time  1.077 ( 1.676)	Data  0.446 ( 0.920)	Loss 1.2534e-01 (5.2655e-02)	Acc@1  96.88 ( 98.34)	Acc@5  98.44 ( 99.85)
Epoch: [123][40/51]	Time  3.326 ( 1.692)	Data  2.234 ( 0.927)	Loss 1.0525e-02 (4.9150e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [123][50/51]	Time  1.446 ( 1.729)	Data  0.593 ( 0.964)	Loss 1.5648e-01 (5.3709e-02)	Acc@1  93.55 ( 98.45)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [124][ 0/51]	Time  3.062 ( 3.062)	Data  2.134 ( 2.134)	Loss 3.1833e-02 (3.1833e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [124][10/51]	Time  2.599 ( 2.295)	Data  1.827 ( 1.336)	Loss 1.4503e-01 (5.7389e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.72)
Epoch: [124][20/51]	Time  1.256 ( 1.948)	Data  0.456 ( 1.063)	Loss 3.5228e-02 (5.2986e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.78)
Epoch: [124][30/51]	Time  1.175 ( 2.055)	Data  0.570 ( 1.166)	Loss 1.0473e-01 (4.9018e-02)	Acc@1  96.88 ( 98.54)	Acc@5  98.44 ( 99.80)
Epoch: [124][40/51]	Time  3.041 ( 2.008)	Data  1.908 ( 1.123)	Loss 2.6899e-02 (4.8092e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.77)
Epoch: [124][50/51]	Time  0.895 ( 2.070)	Data  0.234 ( 1.175)	Loss 1.6199e-01 (4.7813e-02)	Acc@1  96.77 ( 98.70)	Acc@5  96.77 ( 99.78)
Test: [0/8]	Time  0.841 ( 0.841)	Loss 1.3855e-01 (1.3855e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.695 ( 0.889)	Loss 1.8440e-01 (1.7050e-01)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.800 Acc@5 99.600
learning rate is: 0.001
Epoch: [125][ 0/51]	Time  1.433 ( 1.433)	Data  0.464 ( 0.464)	Loss 2.6490e-02 (2.6490e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [125][10/51]	Time  2.125 ( 2.024)	Data  1.579 ( 1.156)	Loss 3.1732e-03 (3.8254e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [125][20/51]	Time  1.207 ( 1.970)	Data  0.536 ( 1.145)	Loss 7.9490e-03 (4.1132e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [125][30/51]	Time  1.187 ( 1.741)	Data  0.621 ( 0.985)	Loss 2.1882e-02 (4.4860e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [125][40/51]	Time  1.348 ( 1.588)	Data  0.565 ( 0.866)	Loss 6.8987e-03 (4.4352e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.81)
Epoch: [125][50/51]	Time  1.513 ( 1.662)	Data  1.022 ( 0.930)	Loss 2.6809e-01 (4.8778e-02)	Acc@1  87.10 ( 98.42)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [126][ 0/51]	Time  1.168 ( 1.168)	Data  0.597 ( 0.597)	Loss 8.6187e-02 (8.6187e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [126][10/51]	Time  1.456 ( 1.520)	Data  0.496 ( 0.795)	Loss 7.4198e-02 (3.7541e-02)	Acc@1  98.44 ( 99.01)	Acc@5  98.44 ( 99.86)
Epoch: [126][20/51]	Time  2.695 ( 2.144)	Data  1.767 ( 1.237)	Loss 5.2201e-02 (5.3555e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.63)
Epoch: [126][30/51]	Time  3.095 ( 2.383)	Data  2.010 ( 1.423)	Loss 8.6743e-03 (4.5946e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.75)
Epoch: [126][40/51]	Time  1.012 ( 2.159)	Data  0.432 ( 1.262)	Loss 5.0829e-02 (4.7659e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.73)
Epoch: [126][50/51]	Time  1.018 ( 2.098)	Data  0.293 ( 1.208)	Loss 2.2698e-01 (5.1243e-02)	Acc@1  90.32 ( 98.70)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [127][ 0/51]	Time  1.183 ( 1.183)	Data  0.466 ( 0.466)	Loss 3.2701e-02 (3.2701e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [127][10/51]	Time  1.395 ( 1.477)	Data  0.643 ( 0.683)	Loss 2.9405e-02 (4.1643e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [127][20/51]	Time  3.444 ( 2.012)	Data  2.022 ( 1.089)	Loss 7.7607e-03 (4.8763e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.70)
Epoch: [127][30/51]	Time  3.071 ( 2.136)	Data  1.950 ( 1.224)	Loss 5.4445e-02 (5.7047e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.60)
Epoch: [127][40/51]	Time  3.093 ( 2.171)	Data  1.946 ( 1.264)	Loss 3.5847e-02 (5.0847e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.70)
Epoch: [127][50/51]	Time  2.492 ( 2.186)	Data  1.304 ( 1.265)	Loss 4.2342e-02 (5.6736e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [128][ 0/51]	Time  3.190 ( 3.190)	Data  2.007 ( 2.007)	Loss 1.5955e-02 (1.5955e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [128][10/51]	Time  1.278 ( 1.568)	Data  0.558 ( 0.770)	Loss 2.3439e-02 (7.2085e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.43)
Epoch: [128][20/51]	Time  1.272 ( 1.769)	Data  0.544 ( 0.940)	Loss 3.6778e-02 (6.3265e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.55)
Epoch: [128][30/51]	Time  2.341 ( 1.675)	Data  1.556 ( 0.850)	Loss 1.4221e-02 (5.5247e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.65)
Epoch: [128][40/51]	Time  3.461 ( 1.740)	Data  2.138 ( 0.879)	Loss 6.0070e-02 (5.5232e-02)	Acc@1  96.88 ( 98.55)	Acc@5 100.00 ( 99.66)
Epoch: [128][50/51]	Time  1.608 ( 1.929)	Data  0.738 ( 0.997)	Loss 6.0880e-02 (5.5159e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.66)
learning rate is: 0.001
Epoch: [129][ 0/51]	Time  1.354 ( 1.354)	Data  0.586 ( 0.586)	Loss 1.0321e-01 (1.0321e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [129][10/51]	Time  1.143 ( 1.776)	Data  0.478 ( 0.981)	Loss 1.0095e-01 (4.9798e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.72)
Epoch: [129][20/51]	Time  3.504 ( 2.115)	Data  2.177 ( 1.214)	Loss 3.9477e-02 (5.7104e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.78)
Epoch: [129][30/51]	Time  1.621 ( 1.974)	Data  0.574 ( 1.106)	Loss 1.5730e-02 (5.1081e-02)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.85)
Epoch: [129][40/51]	Time  1.726 ( 1.828)	Data  0.963 ( 0.990)	Loss 4.3379e-02 (4.5338e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.89)
Epoch: [129][50/51]	Time  1.930 ( 1.766)	Data  0.920 ( 0.941)	Loss 1.4050e-02 (4.7830e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.91)
Test: [0/8]	Time  3.111 ( 3.111)	Loss 1.3336e-01 (1.3336e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.966 ( 2.332)	Loss 1.8312e-01 (1.6789e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.001
Epoch: [130][ 0/51]	Time  3.449 ( 3.449)	Data  2.307 ( 2.307)	Loss 1.3067e-01 (1.3067e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [130][10/51]	Time  1.447 ( 2.426)	Data  0.803 ( 1.501)	Loss 2.5408e-02 (6.1394e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.72)
Epoch: [130][20/51]	Time  1.425 ( 2.598)	Data  0.434 ( 1.638)	Loss 1.2543e-01 (5.9863e-02)	Acc@1  96.88 ( 98.36)	Acc@5  98.44 ( 99.63)
Epoch: [130][30/51]	Time  2.946 ( 2.614)	Data  2.016 ( 1.601)	Loss 1.3368e-02 (5.4588e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [130][40/51]	Time  2.713 ( 2.491)	Data  1.572 ( 1.483)	Loss 2.3535e-02 (5.1649e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.77)
Epoch: [130][50/51]	Time  0.791 ( 2.483)	Data  0.252 ( 1.485)	Loss 3.6831e-01 (5.4035e-02)	Acc@1  93.55 ( 98.58)	Acc@5  96.77 ( 99.75)
learning rate is: 0.001
Epoch: [131][ 0/51]	Time  1.555 ( 1.555)	Data  0.432 ( 0.432)	Loss 5.5814e-02 (5.5814e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [131][10/51]	Time  3.369 ( 2.891)	Data  2.215 ( 1.801)	Loss 5.1167e-02 (4.9319e-02)	Acc@1  96.88 ( 98.15)	Acc@5 100.00 (100.00)
Epoch: [131][20/51]	Time  1.401 ( 2.805)	Data  0.640 ( 1.703)	Loss 5.5174e-03 (5.2068e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.85)
Epoch: [131][30/51]	Time  3.207 ( 2.577)	Data  2.008 ( 1.546)	Loss 8.5682e-03 (5.4486e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [131][40/51]	Time  1.328 ( 2.531)	Data  0.757 ( 1.525)	Loss 2.3034e-02 (5.1111e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.73)
Epoch: [131][50/51]	Time  0.824 ( 2.316)	Data  0.336 ( 1.377)	Loss 2.6587e-01 (5.6094e-02)	Acc@1  93.55 ( 98.51)	Acc@5  96.77 ( 99.69)
learning rate is: 0.001
Epoch: [132][ 0/51]	Time  1.803 ( 1.803)	Data  0.875 ( 0.875)	Loss 5.5458e-02 (5.5458e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [132][10/51]	Time  1.439 ( 2.024)	Data  0.850 ( 1.206)	Loss 7.3725e-02 (6.4150e-02)	Acc@1  96.88 ( 97.30)	Acc@5 100.00 ( 99.86)
Epoch: [132][20/51]	Time  1.323 ( 1.682)	Data  0.393 ( 0.923)	Loss 9.9556e-02 (6.1515e-02)	Acc@1  96.88 ( 97.92)	Acc@5 100.00 ( 99.85)
Epoch: [132][30/51]	Time  1.776 ( 1.796)	Data  0.754 ( 0.981)	Loss 5.6661e-02 (6.0070e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.85)
Epoch: [132][40/51]	Time  1.383 ( 1.723)	Data  0.602 ( 0.898)	Loss 1.8257e-02 (5.7287e-02)	Acc@1 100.00 ( 98.32)	Acc@5 100.00 ( 99.85)
Epoch: [132][50/51]	Time  2.080 ( 1.784)	Data  0.959 ( 0.932)	Loss 9.5953e-02 (5.2805e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.85)
learning rate is: 0.001
Epoch: [133][ 0/51]	Time  3.171 ( 3.171)	Data  1.842 ( 1.842)	Loss 3.5390e-03 (3.5390e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [133][10/51]	Time  1.090 ( 2.411)	Data  0.489 ( 1.450)	Loss 6.4265e-02 (7.1133e-02)	Acc@1  96.88 ( 98.01)	Acc@5 100.00 ( 99.15)
Epoch: [133][20/51]	Time  2.936 ( 2.244)	Data  1.867 ( 1.368)	Loss 6.0124e-02 (5.8935e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.48)
Epoch: [133][30/51]	Time  3.991 ( 2.387)	Data  2.787 ( 1.435)	Loss 3.2617e-02 (4.7275e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 ( 99.65)
Epoch: [133][40/51]	Time  2.986 ( 2.368)	Data  1.743 ( 1.393)	Loss 3.3031e-02 (4.9737e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.66)
Epoch: [133][50/51]	Time  2.124 ( 2.393)	Data  0.795 ( 1.424)	Loss 2.5072e-01 (4.9160e-02)	Acc@1  93.55 ( 98.82)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [134][ 0/51]	Time  1.366 ( 1.366)	Data  0.613 ( 0.613)	Loss 7.2209e-02 (7.2209e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [134][10/51]	Time  1.134 ( 1.266)	Data  0.563 ( 0.595)	Loss 2.5527e-02 (6.0545e-02)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.57)
Epoch: [134][20/51]	Time  1.083 ( 1.290)	Data  0.506 ( 0.644)	Loss 2.9150e-02 (5.0788e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.70)
Epoch: [134][30/51]	Time  1.133 ( 1.320)	Data  0.594 ( 0.676)	Loss 3.7226e-02 (4.4698e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.75)
Epoch: [134][40/51]	Time  1.529 ( 1.434)	Data  0.753 ( 0.755)	Loss 7.8426e-03 (4.1431e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.77)
Epoch: [134][50/51]	Time  0.685 ( 1.390)	Data  0.222 ( 0.718)	Loss 1.7545e-01 (5.0844e-02)	Acc@1  93.55 ( 98.64)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  1.164 ( 1.164)	Loss 1.3419e-01 (1.3419e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.808 ( 1.801)	Loss 1.9969e-01 (1.7295e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.001
Epoch: [135][ 0/51]	Time  1.445 ( 1.445)	Data  0.917 ( 0.917)	Loss 5.1796e-02 (5.1796e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [135][10/51]	Time  1.030 ( 1.739)	Data  0.426 ( 0.932)	Loss 1.0919e-02 (4.5837e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [135][20/51]	Time  2.619 ( 1.660)	Data  1.699 ( 0.892)	Loss 2.4316e-02 (4.8476e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.93)
Epoch: [135][30/51]	Time  3.666 ( 2.165)	Data  2.463 ( 1.285)	Loss 3.3364e-02 (5.7060e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.75)
Epoch: [135][40/51]	Time  1.552 ( 2.213)	Data  0.878 ( 1.311)	Loss 7.8321e-02 (5.0699e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.77)
Epoch: [135][50/51]	Time  1.066 ( 2.053)	Data  0.295 ( 1.178)	Loss 8.2019e-02 (5.1689e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [136][ 0/51]	Time  1.848 ( 1.848)	Data  0.892 ( 0.892)	Loss 5.5686e-02 (5.5686e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [136][10/51]	Time  2.209 ( 1.960)	Data  1.424 ( 1.008)	Loss 4.0723e-02 (4.1352e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [136][20/51]	Time  1.153 ( 1.979)	Data  0.401 ( 1.012)	Loss 8.2140e-02 (4.6200e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [136][30/51]	Time  1.484 ( 1.929)	Data  0.675 ( 0.972)	Loss 9.1713e-03 (4.0113e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.80)
Epoch: [136][40/51]	Time  1.207 ( 1.882)	Data  0.460 ( 0.944)	Loss 5.3511e-03 (4.1747e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.77)
Epoch: [136][50/51]	Time  1.131 ( 1.872)	Data  0.389 ( 0.955)	Loss 9.7654e-03 (4.3737e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [137][ 0/51]	Time  1.283 ( 1.283)	Data  0.502 ( 0.502)	Loss 1.1480e-02 (1.1480e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [137][10/51]	Time  1.239 ( 1.379)	Data  0.454 ( 0.568)	Loss 5.4461e-03 (4.8862e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [137][20/51]	Time  1.009 ( 1.352)	Data  0.481 ( 0.568)	Loss 1.4791e-01 (5.9199e-02)	Acc@1  96.88 ( 98.36)	Acc@5  98.44 ( 99.78)
Epoch: [137][30/51]	Time  2.894 ( 1.659)	Data  1.790 ( 0.787)	Loss 3.1376e-02 (5.7613e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.75)
Epoch: [137][40/51]	Time  2.154 ( 1.918)	Data  0.967 ( 0.980)	Loss 1.1973e-02 (5.5359e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.77)
Epoch: [137][50/51]	Time  1.323 ( 1.958)	Data  0.500 ( 1.007)	Loss 9.4839e-02 (5.7966e-02)	Acc@1  96.77 ( 98.42)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [138][ 0/51]	Time  1.458 ( 1.458)	Data  0.438 ( 0.438)	Loss 9.3267e-03 (9.3267e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [138][10/51]	Time  2.177 ( 1.904)	Data  1.163 ( 0.995)	Loss 7.5196e-02 (3.7307e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [138][20/51]	Time  2.855 ( 1.984)	Data  1.697 ( 1.046)	Loss 1.1105e-02 (4.7003e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [138][30/51]	Time  3.319 ( 2.164)	Data  2.014 ( 1.181)	Loss 2.2280e-01 (5.4854e-02)	Acc@1  95.31 ( 98.54)	Acc@5  98.44 ( 99.80)
Epoch: [138][40/51]	Time  3.142 ( 2.364)	Data  2.308 ( 1.340)	Loss 8.4637e-02 (5.0175e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 ( 99.85)
Epoch: [138][50/51]	Time  2.003 ( 2.187)	Data  0.973 ( 1.214)	Loss 1.2167e-01 (5.6873e-02)	Acc@1  93.55 ( 98.45)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [139][ 0/51]	Time  1.331 ( 1.331)	Data  0.465 ( 0.465)	Loss 7.6581e-02 (7.6581e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [139][10/51]	Time  1.295 ( 1.394)	Data  0.672 ( 0.601)	Loss 1.0055e-02 (5.0180e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [139][20/51]	Time  2.819 ( 1.335)	Data  1.907 ( 0.623)	Loss 4.6969e-02 (4.9540e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [139][30/51]	Time  0.990 ( 1.378)	Data  0.385 ( 0.669)	Loss 1.4829e-01 (5.5217e-02)	Acc@1  95.31 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [139][40/51]	Time  3.062 ( 1.762)	Data  1.909 ( 0.964)	Loss 3.8196e-02 (5.3307e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.77)
Epoch: [139][50/51]	Time  0.850 ( 1.881)	Data  0.331 ( 1.065)	Loss 2.0250e-02 (5.0794e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  1.011 ( 1.011)	Loss 1.3579e-01 (1.3579e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.505 ( 2.242)	Loss 1.7596e-01 (1.6659e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.001
Epoch: [140][ 0/51]	Time  3.078 ( 3.078)	Data  1.915 ( 1.915)	Loss 2.0801e-01 (2.0801e-01)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [140][10/51]	Time  2.647 ( 2.033)	Data  1.556 ( 1.178)	Loss 9.8259e-02 (6.6115e-02)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.43)
Epoch: [140][20/51]	Time  1.842 ( 2.205)	Data  0.855 ( 1.270)	Loss 1.3138e-01 (5.5748e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [140][30/51]	Time  3.064 ( 1.981)	Data  1.865 ( 1.094)	Loss 8.9682e-03 (6.1714e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.75)
Epoch: [140][40/51]	Time  3.023 ( 2.029)	Data  1.780 ( 1.128)	Loss 3.8858e-02 (5.9366e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.77)
Epoch: [140][50/51]	Time  1.160 ( 2.154)	Data  0.248 ( 1.214)	Loss 7.7751e-02 (6.1696e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [141][ 0/51]	Time  1.230 ( 1.230)	Data  0.466 ( 0.466)	Loss 2.0023e-02 (2.0023e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [141][10/51]	Time  3.313 ( 2.243)	Data  1.882 ( 1.253)	Loss 1.2273e-01 (6.6108e-02)	Acc@1  96.88 ( 98.58)	Acc@5  98.44 ( 99.57)
Epoch: [141][20/51]	Time  1.020 ( 2.153)	Data  0.474 ( 1.225)	Loss 2.9439e-02 (6.9635e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.63)
Epoch: [141][30/51]	Time  1.434 ( 2.118)	Data  0.756 ( 1.193)	Loss 1.0593e-01 (6.1941e-02)	Acc@1  95.31 ( 98.29)	Acc@5 100.00 ( 99.75)
Epoch: [141][40/51]	Time  1.098 ( 1.900)	Data  0.525 ( 1.039)	Loss 3.1368e-02 (5.8319e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.73)
Epoch: [141][50/51]	Time  1.884 ( 1.784)	Data  0.944 ( 0.969)	Loss 2.4944e-02 (5.5115e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [142][ 0/51]	Time  2.995 ( 2.995)	Data  2.009 ( 2.009)	Loss 9.0980e-02 (9.0980e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [142][10/51]	Time  3.189 ( 2.985)	Data  1.842 ( 1.767)	Loss 1.7185e-01 (4.7649e-02)	Acc@1  95.31 ( 98.58)	Acc@5  98.44 ( 99.57)
Epoch: [142][20/51]	Time  1.264 ( 2.557)	Data  0.482 ( 1.488)	Loss 1.5470e-01 (4.6113e-02)	Acc@1  96.88 ( 98.81)	Acc@5  98.44 ( 99.63)
Epoch: [142][30/51]	Time  1.264 ( 2.249)	Data  0.643 ( 1.276)	Loss 4.0068e-02 (4.3034e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.70)
Epoch: [142][40/51]	Time  2.962 ( 2.316)	Data  1.765 ( 1.311)	Loss 3.6269e-02 (5.0896e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.70)
Epoch: [142][50/51]	Time  0.964 ( 2.396)	Data  0.273 ( 1.378)	Loss 2.0112e-01 (5.1486e-02)	Acc@1  93.55 ( 98.61)	Acc@5  96.77 ( 99.69)
learning rate is: 0.001
Epoch: [143][ 0/51]	Time  1.884 ( 1.884)	Data  0.854 ( 0.854)	Loss 7.2510e-02 (7.2510e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [143][10/51]	Time  1.340 ( 2.509)	Data  0.475 ( 1.397)	Loss 5.5424e-02 (3.9396e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [143][20/51]	Time  1.631 ( 2.550)	Data  0.578 ( 1.429)	Loss 4.7400e-02 (3.6954e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.93)
Epoch: [143][30/51]	Time  1.591 ( 2.226)	Data  0.854 ( 1.201)	Loss 8.0764e-03 (4.5439e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.85)
Epoch: [143][40/51]	Time  1.413 ( 2.229)	Data  0.540 ( 1.193)	Loss 5.1756e-02 (5.1436e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.77)
Epoch: [143][50/51]	Time  2.109 ( 2.361)	Data  0.960 ( 1.303)	Loss 5.2117e-02 (4.9474e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.78)
learning rate is: 0.001
Epoch: [144][ 0/51]	Time  2.879 ( 2.879)	Data  1.775 ( 1.775)	Loss 5.7322e-02 (5.7322e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [144][10/51]	Time  1.555 ( 2.502)	Data  0.513 ( 1.516)	Loss 1.5120e-02 (3.5654e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [144][20/51]	Time  1.297 ( 2.236)	Data  0.733 ( 1.332)	Loss 3.0171e-02 (4.5590e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.93)
Epoch: [144][30/51]	Time  1.003 ( 1.923)	Data  0.415 ( 1.097)	Loss 7.9800e-02 (4.3184e-02)	Acc@1  98.44 ( 98.89)	Acc@5  98.44 ( 99.90)
Epoch: [144][40/51]	Time  3.408 ( 2.095)	Data  2.425 ( 1.224)	Loss 7.7140e-03 (4.4195e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 ( 99.81)
Epoch: [144][50/51]	Time  1.875 ( 2.215)	Data  0.814 ( 1.308)	Loss 1.0190e-02 (4.2502e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  3.306 ( 3.306)	Loss 1.4912e-01 (1.4912e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.399 ( 2.158)	Loss 1.7151e-01 (1.7215e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.001
Epoch: [145][ 0/51]	Time  3.096 ( 3.096)	Data  2.027 ( 2.027)	Loss 9.5273e-03 (9.5273e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [145][10/51]	Time  1.262 ( 2.335)	Data  0.628 ( 1.446)	Loss 8.3577e-02 (7.5482e-02)	Acc@1  98.44 ( 98.01)	Acc@5  98.44 ( 99.29)
Epoch: [145][20/51]	Time  0.992 ( 1.888)	Data  0.443 ( 1.081)	Loss 6.1498e-02 (8.1833e-02)	Acc@1  98.44 ( 97.92)	Acc@5 100.00 ( 99.18)
Epoch: [145][30/51]	Time  1.391 ( 1.704)	Data  0.841 ( 0.953)	Loss 9.8603e-02 (7.1208e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.34)
Epoch: [145][40/51]	Time  3.446 ( 1.773)	Data  2.400 ( 1.000)	Loss 4.6395e-02 (6.3690e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.50)
Epoch: [145][50/51]	Time  2.183 ( 1.708)	Data  1.214 ( 0.958)	Loss 3.6500e-02 (6.1257e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.57)
learning rate is: 0.001
Epoch: [146][ 0/51]	Time  2.911 ( 2.911)	Data  2.000 ( 2.000)	Loss 2.9400e-02 (2.9400e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [146][10/51]	Time  3.160 ( 3.004)	Data  1.959 ( 1.912)	Loss 6.0771e-03 (4.1054e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.43)
Epoch: [146][20/51]	Time  3.603 ( 2.518)	Data  2.409 ( 1.554)	Loss 2.0967e-02 (4.3171e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.63)
Epoch: [146][30/51]	Time  3.169 ( 2.694)	Data  2.037 ( 1.698)	Loss 1.4449e-02 (4.5115e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.65)
Epoch: [146][40/51]	Time  1.502 ( 2.664)	Data  0.566 ( 1.671)	Loss 8.8191e-03 (4.4630e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.70)
Epoch: [146][50/51]	Time  0.944 ( 2.459)	Data  0.275 ( 1.516)	Loss 1.2926e-01 (4.5020e-02)	Acc@1  96.77 ( 98.82)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [147][ 0/51]	Time  2.753 ( 2.753)	Data  1.833 ( 1.833)	Loss 1.1760e-02 (1.1760e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [147][10/51]	Time  0.977 ( 1.623)	Data  0.423 ( 0.906)	Loss 9.9482e-03 (5.0178e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [147][20/51]	Time  1.714 ( 1.450)	Data  0.960 ( 0.762)	Loss 1.1322e-01 (5.8890e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.93)
Epoch: [147][30/51]	Time  1.316 ( 1.644)	Data  0.561 ( 0.865)	Loss 6.5022e-02 (5.0329e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 ( 99.90)
Epoch: [147][40/51]	Time  1.122 ( 1.569)	Data  0.410 ( 0.785)	Loss 1.2820e-01 (4.7894e-02)	Acc@1  96.88 ( 98.74)	Acc@5  98.44 ( 99.89)
Epoch: [147][50/51]	Time  0.978 ( 1.509)	Data  0.236 ( 0.729)	Loss 3.6108e-01 (5.4918e-02)	Acc@1  90.32 ( 98.55)	Acc@5  96.77 ( 99.78)
learning rate is: 0.001
Epoch: [148][ 0/51]	Time  1.420 ( 1.420)	Data  0.460 ( 0.460)	Loss 8.1534e-02 (8.1534e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [148][10/51]	Time  3.304 ( 1.916)	Data  1.973 ( 0.919)	Loss 4.0269e-03 (5.2660e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.43)
Epoch: [148][20/51]	Time  1.583 ( 2.207)	Data  0.709 ( 1.194)	Loss 5.7295e-02 (4.9033e-02)	Acc@1  98.44 ( 98.66)	Acc@5  98.44 ( 99.48)
Epoch: [148][30/51]	Time  2.677 ( 2.003)	Data  1.934 ( 1.075)	Loss 9.3074e-02 (4.9954e-02)	Acc@1  98.44 ( 98.69)	Acc@5  98.44 ( 99.55)
Epoch: [148][40/51]	Time  1.632 ( 1.861)	Data  0.908 ( 0.986)	Loss 3.2493e-02 (4.9460e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.62)
Epoch: [148][50/51]	Time  1.606 ( 1.760)	Data  0.591 ( 0.912)	Loss 1.6361e-01 (4.3919e-02)	Acc@1  96.77 ( 98.92)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [149][ 0/51]	Time  2.679 ( 2.679)	Data  1.699 ( 1.699)	Loss 2.6899e-02 (2.6899e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [149][10/51]	Time  1.569 ( 2.137)	Data  0.640 ( 1.254)	Loss 1.2466e-01 (7.1211e-02)	Acc@1  96.88 ( 98.01)	Acc@5  98.44 ( 99.29)
Epoch: [149][20/51]	Time  1.598 ( 2.209)	Data  0.533 ( 1.295)	Loss 6.3488e-02 (6.4590e-02)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 ( 99.55)
Epoch: [149][30/51]	Time  2.745 ( 2.157)	Data  2.114 ( 1.257)	Loss 2.7834e-02 (7.3134e-02)	Acc@1  98.44 ( 97.83)	Acc@5 100.00 ( 99.55)
Epoch: [149][40/51]	Time  1.449 ( 2.065)	Data  0.516 ( 1.198)	Loss 5.1056e-02 (6.5535e-02)	Acc@1  98.44 ( 98.02)	Acc@5 100.00 ( 99.66)
Epoch: [149][50/51]	Time  0.733 ( 1.935)	Data  0.276 ( 1.113)	Loss 8.2273e-02 (6.2740e-02)	Acc@1  96.77 ( 98.14)	Acc@5 100.00 ( 99.66)
Test: [0/8]	Time  1.792 ( 1.792)	Loss 1.4095e-01 (1.4095e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.817 ( 1.052)	Loss 1.7737e-01 (1.7122e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.001
Epoch: [150][ 0/51]	Time  3.277 ( 3.277)	Data  2.142 ( 2.142)	Loss 6.3077e-02 (6.3077e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [150][10/51]	Time  1.067 ( 1.872)	Data  0.448 ( 1.044)	Loss 7.8540e-02 (6.1120e-02)	Acc@1  96.88 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [150][20/51]	Time  1.339 ( 1.790)	Data  0.670 ( 0.939)	Loss 9.3377e-03 (5.5593e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.85)
Epoch: [150][30/51]	Time  2.107 ( 1.727)	Data  1.394 ( 0.883)	Loss 5.0317e-02 (5.5547e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.75)
Epoch: [150][40/51]	Time  1.123 ( 1.629)	Data  0.470 ( 0.804)	Loss 7.9617e-02 (5.6122e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.73)
Epoch: [150][50/51]	Time  2.245 ( 1.768)	Data  1.107 ( 0.907)	Loss 1.2461e-01 (5.5111e-02)	Acc@1  93.55 ( 98.39)	Acc@5 100.00 ( 99.69)
learning rate is: 0.001
Epoch: [151][ 0/51]	Time  1.980 ( 1.980)	Data  0.825 ( 0.825)	Loss 5.8536e-02 (5.8536e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [151][10/51]	Time  1.037 ( 2.306)	Data  0.403 ( 1.370)	Loss 1.5833e-02 (3.3207e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [151][20/51]	Time  3.153 ( 1.965)	Data  2.093 ( 1.100)	Loss 7.0121e-02 (4.6017e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [151][30/51]	Time  2.924 ( 2.145)	Data  1.995 ( 1.256)	Loss 5.1791e-02 (4.3165e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 ( 99.85)
Epoch: [151][40/51]	Time  1.071 ( 1.956)	Data  0.530 ( 1.119)	Loss 9.3894e-03 (5.1356e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.73)
Epoch: [151][50/51]	Time  0.928 ( 1.834)	Data  0.183 ( 1.019)	Loss 6.3380e-02 (5.6119e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.75)
learning rate is: 0.001
Epoch: [152][ 0/51]	Time  1.333 ( 1.333)	Data  0.646 ( 0.646)	Loss 2.0077e-02 (2.0077e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [152][10/51]	Time  1.005 ( 1.983)	Data  0.456 ( 1.184)	Loss 3.8806e-02 (6.2503e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.72)
Epoch: [152][20/51]	Time  2.235 ( 2.120)	Data  0.997 ( 1.243)	Loss 1.5205e-02 (4.8211e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [152][30/51]	Time  1.311 ( 1.881)	Data  0.488 ( 1.057)	Loss 4.0438e-03 (5.0575e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [152][40/51]	Time  1.377 ( 1.865)	Data  0.822 ( 1.051)	Loss 5.1583e-02 (4.9593e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.81)
Epoch: [152][50/51]	Time  0.721 ( 1.796)	Data  0.253 ( 1.008)	Loss 4.3486e-02 (4.8711e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [153][ 0/51]	Time  1.266 ( 1.266)	Data  0.736 ( 0.736)	Loss 5.6124e-02 (5.6124e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [153][10/51]	Time  1.227 ( 1.262)	Data  0.441 ( 0.691)	Loss 5.2391e-02 (6.2888e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [153][20/51]	Time  2.914 ( 1.994)	Data  1.752 ( 1.177)	Loss 2.9439e-02 (5.4634e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [153][30/51]	Time  1.265 ( 1.804)	Data  0.687 ( 1.010)	Loss 1.2556e-01 (4.8525e-02)	Acc@1  96.88 ( 98.94)	Acc@5  98.44 ( 99.75)
Epoch: [153][40/51]	Time  1.085 ( 1.710)	Data  0.557 ( 0.944)	Loss 6.9824e-03 (5.0861e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.70)
Epoch: [153][50/51]	Time  0.862 ( 1.771)	Data  0.381 ( 0.987)	Loss 4.2560e-02 (6.0720e-02)	Acc@1 100.00 ( 98.45)	Acc@5 100.00 ( 99.63)
learning rate is: 0.001
Epoch: [154][ 0/51]	Time  1.258 ( 1.258)	Data  0.663 ( 0.663)	Loss 8.5397e-03 (8.5397e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [154][10/51]	Time  2.744 ( 1.484)	Data  1.733 ( 0.795)	Loss 1.4770e-03 (2.8302e-02)	Acc@1 100.00 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [154][20/51]	Time  1.239 ( 1.456)	Data  0.704 ( 0.805)	Loss 2.0870e-02 (2.6987e-02)	Acc@1 100.00 ( 99.40)	Acc@5 100.00 (100.00)
Epoch: [154][30/51]	Time  1.912 ( 1.409)	Data  0.937 ( 0.760)	Loss 5.4826e-02 (2.9820e-02)	Acc@1  98.44 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [154][40/51]	Time  1.161 ( 1.457)	Data  0.604 ( 0.788)	Loss 1.1448e-01 (3.6374e-02)	Acc@1  98.44 ( 99.09)	Acc@5  98.44 ( 99.85)
Epoch: [154][50/51]	Time  1.923 ( 1.654)	Data  0.647 ( 0.901)	Loss 3.9856e-01 (4.5626e-02)	Acc@1  90.32 ( 98.76)	Acc@5  93.55 ( 99.75)
Test: [0/8]	Time  3.074 ( 3.074)	Loss 1.3772e-01 (1.3772e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.929 ( 1.304)	Loss 1.7504e-01 (1.7278e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.001
Epoch: [155][ 0/51]	Time  2.186 ( 2.186)	Data  0.943 ( 0.943)	Loss 7.4086e-03 (7.4086e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [155][10/51]	Time  1.084 ( 1.491)	Data  0.463 ( 0.744)	Loss 6.9639e-02 (3.6571e-02)	Acc@1  96.88 ( 99.01)	Acc@5 100.00 ( 99.72)
Epoch: [155][20/51]	Time  1.380 ( 2.012)	Data  0.598 ( 1.129)	Loss 6.2232e-02 (3.3803e-02)	Acc@1  98.44 ( 99.33)	Acc@5 100.00 ( 99.85)
Epoch: [155][30/51]	Time  1.519 ( 1.947)	Data  0.978 ( 1.108)	Loss 1.6933e-02 (4.5644e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 ( 99.85)
Epoch: [155][40/51]	Time  1.383 ( 1.850)	Data  0.559 ( 1.048)	Loss 1.0219e-02 (4.8513e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.81)
Epoch: [155][50/51]	Time  1.970 ( 1.829)	Data  0.992 ( 1.040)	Loss 1.6709e-01 (4.8607e-02)	Acc@1  93.55 ( 98.92)	Acc@5 100.00 ( 99.81)
learning rate is: 0.001
Epoch: [156][ 0/51]	Time  2.584 ( 2.584)	Data  1.713 ( 1.713)	Loss 3.2981e-02 (3.2981e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [156][10/51]	Time  1.050 ( 1.308)	Data  0.491 ( 0.679)	Loss 7.3506e-02 (5.5982e-02)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [156][20/51]	Time  1.167 ( 1.668)	Data  0.421 ( 0.920)	Loss 6.6587e-02 (5.0146e-02)	Acc@1  95.31 ( 98.29)	Acc@5 100.00 ( 99.85)
Epoch: [156][30/51]	Time  3.209 ( 2.071)	Data  1.830 ( 1.178)	Loss 3.9259e-02 (5.7817e-02)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 ( 99.65)
Epoch: [156][40/51]	Time  3.049 ( 2.345)	Data  1.926 ( 1.388)	Loss 7.1994e-02 (6.3173e-02)	Acc@1  96.88 ( 98.02)	Acc@5 100.00 ( 99.66)
Epoch: [156][50/51]	Time  1.329 ( 2.502)	Data  0.489 ( 1.486)	Loss 4.3321e-02 (6.1834e-02)	Acc@1 100.00 ( 98.05)	Acc@5 100.00 ( 99.60)
learning rate is: 0.001
Epoch: [157][ 0/51]	Time  1.361 ( 1.361)	Data  0.615 ( 0.615)	Loss 4.9055e-02 (4.9055e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [157][10/51]	Time  1.628 ( 1.999)	Data  0.861 ( 1.060)	Loss 3.3075e-02 (3.1267e-02)	Acc@1  98.44 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [157][20/51]	Time  1.332 ( 1.794)	Data  0.558 ( 0.906)	Loss 8.2130e-02 (3.9868e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [157][30/51]	Time  1.144 ( 1.888)	Data  0.387 ( 0.968)	Loss 1.5573e-02 (4.1027e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.80)
Epoch: [157][40/51]	Time  3.133 ( 1.862)	Data  1.927 ( 0.961)	Loss 1.4441e-02 (4.7481e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.70)
Epoch: [157][50/51]	Time  0.888 ( 1.837)	Data  0.432 ( 0.953)	Loss 1.2108e-01 (4.9697e-02)	Acc@1  96.77 ( 98.79)	Acc@5 100.00 ( 99.72)
learning rate is: 0.001
Epoch: [158][ 0/51]	Time  1.347 ( 1.347)	Data  0.757 ( 0.757)	Loss 4.0655e-02 (4.0655e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [158][10/51]	Time  1.192 ( 1.408)	Data  0.660 ( 0.818)	Loss 3.1500e-02 (3.8041e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [158][20/51]	Time  1.013 ( 1.258)	Data  0.487 ( 0.688)	Loss 1.6733e-02 (4.0472e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [158][30/51]	Time  1.141 ( 1.567)	Data  0.583 ( 0.907)	Loss 2.1340e-02 (4.7905e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.90)
Epoch: [158][40/51]	Time  1.220 ( 1.470)	Data  0.685 ( 0.830)	Loss 1.4860e-01 (5.2354e-02)	Acc@1  95.31 ( 98.59)	Acc@5  98.44 ( 99.81)
Epoch: [158][50/51]	Time  1.933 ( 1.567)	Data  0.778 ( 0.866)	Loss 3.4069e-01 (5.4656e-02)	Acc@1  93.55 ( 98.55)	Acc@5  96.77 ( 99.75)
learning rate is: 0.001
Epoch: [159][ 0/51]	Time  2.982 ( 2.982)	Data  1.772 ( 1.772)	Loss 4.5490e-02 (4.5490e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [159][10/51]	Time  2.844 ( 2.634)	Data  1.832 ( 1.534)	Loss 3.3318e-02 (4.4840e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [159][20/51]	Time  1.934 ( 2.151)	Data  0.759 ( 1.205)	Loss 2.9386e-02 (5.2015e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [159][30/51]	Time  3.348 ( 2.221)	Data  2.024 ( 1.253)	Loss 2.8207e-02 (4.9972e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [159][40/51]	Time  1.499 ( 2.183)	Data  0.611 ( 1.226)	Loss 8.6611e-02 (4.9128e-02)	Acc@1  96.88 ( 98.82)	Acc@5 100.00 ( 99.77)
Epoch: [159][50/51]	Time  0.958 ( 2.190)	Data  0.225 ( 1.242)	Loss 6.2809e-02 (4.5594e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  0.950 ( 0.950)	Loss 1.4546e-01 (1.4546e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.854 ( 1.084)	Loss 1.6186e-01 (1.6991e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [160][ 0/51]	Time  1.432 ( 1.432)	Data  0.708 ( 0.708)	Loss 1.5062e-01 (1.5062e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [160][10/51]	Time  1.419 ( 1.357)	Data  0.669 ( 0.705)	Loss 1.1170e-02 (4.7970e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [160][20/51]	Time  1.252 ( 1.417)	Data  0.504 ( 0.716)	Loss 6.5549e-03 (4.4375e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.93)
Epoch: [160][30/51]	Time  3.048 ( 1.468)	Data  1.853 ( 0.762)	Loss 1.0840e-01 (4.2254e-02)	Acc@1  96.88 ( 98.54)	Acc@5 100.00 ( 99.90)
Epoch: [160][40/51]	Time  1.157 ( 1.696)	Data  0.526 ( 0.915)	Loss 1.0176e-01 (4.7065e-02)	Acc@1  96.88 ( 98.32)	Acc@5 100.00 ( 99.89)
Epoch: [160][50/51]	Time  1.964 ( 1.888)	Data  0.878 ( 1.054)	Loss 7.5031e-03 (4.8532e-02)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 ( 99.88)
learning rate is: 0.00010000000000000002
Epoch: [161][ 0/51]	Time  1.327 ( 1.327)	Data  0.538 ( 0.538)	Loss 9.0478e-02 (9.0478e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [161][10/51]	Time  3.064 ( 2.011)	Data  1.932 ( 1.143)	Loss 4.2149e-02 (5.7287e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [161][20/51]	Time  2.726 ( 2.509)	Data  1.674 ( 1.534)	Loss 7.1147e-03 (5.4544e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.78)
Epoch: [161][30/51]	Time  2.651 ( 2.301)	Data  1.574 ( 1.398)	Loss 4.6837e-03 (4.8089e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.75)
Epoch: [161][40/51]	Time  3.431 ( 2.369)	Data  2.081 ( 1.444)	Loss 9.5388e-03 (4.8071e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.73)
Epoch: [161][50/51]	Time  2.609 ( 2.444)	Data  1.589 ( 1.483)	Loss 4.1871e-02 (4.7000e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [162][ 0/51]	Time  1.021 ( 1.021)	Data  0.442 ( 0.442)	Loss 1.0489e-01 (1.0489e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [162][10/51]	Time  1.270 ( 1.460)	Data  0.507 ( 0.632)	Loss 3.0531e-02 (3.7474e-02)	Acc@1  98.44 ( 99.29)	Acc@5 100.00 ( 99.72)
Epoch: [162][20/51]	Time  1.752 ( 1.673)	Data  0.744 ( 0.782)	Loss 1.0690e-01 (3.9126e-02)	Acc@1  95.31 ( 98.88)	Acc@5 100.00 ( 99.85)
Epoch: [162][30/51]	Time  2.964 ( 1.665)	Data  1.879 ( 0.797)	Loss 3.2918e-03 (4.2064e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.85)
Epoch: [162][40/51]	Time  3.737 ( 1.821)	Data  2.239 ( 0.932)	Loss 1.4446e-01 (4.4477e-02)	Acc@1  96.88 ( 98.82)	Acc@5  98.44 ( 99.81)
Epoch: [162][50/51]	Time  2.095 ( 1.935)	Data  0.914 ( 1.014)	Loss 1.7980e-01 (4.9456e-02)	Acc@1  90.32 ( 98.67)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [163][ 0/51]	Time  1.616 ( 1.616)	Data  0.903 ( 0.903)	Loss 1.2539e-03 (1.2539e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [163][10/51]	Time  3.087 ( 2.367)	Data  1.815 ( 1.380)	Loss 1.9093e-02 (5.4830e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [163][20/51]	Time  3.158 ( 2.722)	Data  2.025 ( 1.597)	Loss 5.3606e-02 (5.2970e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.78)
Epoch: [163][30/51]	Time  1.396 ( 2.708)	Data  0.511 ( 1.575)	Loss 2.5416e-02 (5.1869e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [163][40/51]	Time  3.135 ( 2.790)	Data  1.731 ( 1.629)	Loss 1.1914e-01 (5.0498e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 ( 99.77)
Epoch: [163][50/51]	Time  1.134 ( 2.620)	Data  0.282 ( 1.503)	Loss 1.3201e-01 (5.2219e-02)	Acc@1  96.77 ( 98.64)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [164][ 0/51]	Time  1.685 ( 1.685)	Data  0.620 ( 0.620)	Loss 1.7165e-02 (1.7165e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [164][10/51]	Time  1.301 ( 1.636)	Data  0.520 ( 0.831)	Loss 5.3485e-02 (4.1128e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [164][20/51]	Time  3.067 ( 1.703)	Data  2.079 ( 0.882)	Loss 8.2955e-02 (5.6136e-02)	Acc@1  96.88 ( 98.51)	Acc@5  98.44 ( 99.78)
Epoch: [164][30/51]	Time  1.306 ( 1.570)	Data  0.528 ( 0.795)	Loss 4.8879e-02 (4.9221e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [164][40/51]	Time  1.615 ( 1.536)	Data  0.561 ( 0.774)	Loss 7.5581e-03 (4.5886e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [164][50/51]	Time  0.820 ( 1.668)	Data  0.290 ( 0.887)	Loss 6.9160e-02 (4.6848e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  0.887 ( 0.887)	Loss 1.3906e-01 (1.3906e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.751 ( 0.860)	Loss 1.6259e-01 (1.7138e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [165][ 0/51]	Time  1.495 ( 1.495)	Data  0.657 ( 0.657)	Loss 7.5289e-02 (7.5289e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [165][10/51]	Time  1.757 ( 1.558)	Data  1.230 ( 0.819)	Loss 1.8532e-02 (3.4718e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [165][20/51]	Time  2.914 ( 2.029)	Data  2.004 ( 1.176)	Loss 1.6336e-02 (4.1306e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [165][30/51]	Time  2.956 ( 2.302)	Data  1.921 ( 1.398)	Loss 2.0975e-02 (4.2177e-02)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [165][40/51]	Time  1.504 ( 2.378)	Data  0.604 ( 1.436)	Loss 1.6289e-02 (4.4736e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.89)
Epoch: [165][50/51]	Time  0.839 ( 2.186)	Data  0.385 ( 1.288)	Loss 9.7969e-02 (5.2417e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [166][ 0/51]	Time  1.304 ( 1.304)	Data  0.522 ( 0.522)	Loss 2.7733e-02 (2.7733e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [166][10/51]	Time  3.650 ( 2.085)	Data  2.458 ( 1.186)	Loss 9.9970e-02 (3.5680e-02)	Acc@1  96.88 ( 98.86)	Acc@5  98.44 ( 99.86)
Epoch: [166][20/51]	Time  1.269 ( 2.247)	Data  0.504 ( 1.260)	Loss 9.2175e-03 (4.2125e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 ( 99.85)
Epoch: [166][30/51]	Time  1.548 ( 2.059)	Data  0.616 ( 1.121)	Loss 7.5554e-02 (4.1338e-02)	Acc@1  98.44 ( 98.79)	Acc@5  98.44 ( 99.85)
Epoch: [166][40/51]	Time  0.986 ( 2.071)	Data  0.422 ( 1.157)	Loss 1.2490e-01 (4.5494e-02)	Acc@1  95.31 ( 98.63)	Acc@5  98.44 ( 99.77)
Epoch: [166][50/51]	Time  1.079 ( 1.968)	Data  0.479 ( 1.098)	Loss 1.0514e-01 (4.8733e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [167][ 0/51]	Time  2.865 ( 2.865)	Data  1.752 ( 1.752)	Loss 5.8467e-02 (5.8467e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [167][10/51]	Time  1.123 ( 1.987)	Data  0.540 ( 1.131)	Loss 1.0625e-02 (3.5932e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.72)
Epoch: [167][20/51]	Time  1.376 ( 1.612)	Data  0.824 ( 0.874)	Loss 8.4771e-02 (4.2267e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.78)
Epoch: [167][30/51]	Time  2.820 ( 1.641)	Data  1.730 ( 0.870)	Loss 1.2549e-02 (4.4854e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.75)
Epoch: [167][40/51]	Time  1.290 ( 1.748)	Data  0.504 ( 0.931)	Loss 6.0430e-02 (4.5696e-02)	Acc@1  96.88 ( 98.67)	Acc@5 100.00 ( 99.77)
Epoch: [167][50/51]	Time  1.225 ( 1.642)	Data  0.433 ( 0.865)	Loss 1.2368e-02 (4.8046e-02)	Acc@1 100.00 ( 98.61)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [168][ 0/51]	Time  1.402 ( 1.402)	Data  0.663 ( 0.663)	Loss 4.1424e-02 (4.1424e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [168][10/51]	Time  1.481 ( 1.872)	Data  0.607 ( 0.933)	Loss 4.6942e-02 (5.2663e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.57)
Epoch: [168][20/51]	Time  2.954 ( 2.038)	Data  1.714 ( 1.098)	Loss 3.1896e-02 (5.8416e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.55)
Epoch: [168][30/51]	Time  1.294 ( 2.182)	Data  0.473 ( 1.195)	Loss 5.8016e-02 (5.5994e-02)	Acc@1  96.88 ( 98.64)	Acc@5 100.00 ( 99.65)
Epoch: [168][40/51]	Time  3.528 ( 2.255)	Data  2.055 ( 1.246)	Loss 2.1236e-02 (4.7739e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.73)
Epoch: [168][50/51]	Time  0.938 ( 2.253)	Data  0.282 ( 1.258)	Loss 1.8659e-01 (4.7725e-02)	Acc@1  96.77 ( 98.89)	Acc@5  96.77 ( 99.72)
learning rate is: 0.00010000000000000002
Epoch: [169][ 0/51]	Time  3.394 ( 3.394)	Data  2.260 ( 2.260)	Loss 7.2870e-03 (7.2870e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [169][10/51]	Time  1.242 ( 2.077)	Data  0.678 ( 1.236)	Loss 1.0346e-01 (4.7340e-02)	Acc@1  96.88 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [169][20/51]	Time  3.099 ( 2.561)	Data  2.085 ( 1.572)	Loss 5.0090e-02 (3.8749e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.93)
Epoch: [169][30/51]	Time  1.186 ( 2.437)	Data  0.624 ( 1.476)	Loss 3.5795e-02 (4.8447e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.70)
Epoch: [169][40/51]	Time  2.334 ( 2.545)	Data  1.767 ( 1.563)	Loss 1.4989e-02 (4.5569e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.73)
Epoch: [169][50/51]	Time  0.904 ( 2.468)	Data  0.197 ( 1.506)	Loss 1.8446e-01 (5.2941e-02)	Acc@1  93.55 ( 98.82)	Acc@5  96.77 ( 99.63)
Test: [0/8]	Time  1.002 ( 1.002)	Loss 1.3906e-01 (1.3906e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  1.065 ( 1.030)	Loss 1.6737e-01 (1.7130e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [170][ 0/51]	Time  1.154 ( 1.154)	Data  0.456 ( 0.456)	Loss 2.6310e-02 (2.6310e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [170][10/51]	Time  1.526 ( 2.554)	Data  0.660 ( 1.492)	Loss 6.4349e-02 (3.0464e-02)	Acc@1  98.44 ( 99.57)	Acc@5 100.00 (100.00)
Epoch: [170][20/51]	Time  1.010 ( 2.366)	Data  0.465 ( 1.417)	Loss 3.6134e-02 (2.7546e-02)	Acc@1  98.44 ( 99.40)	Acc@5 100.00 (100.00)
Epoch: [170][30/51]	Time  2.756 ( 2.309)	Data  1.733 ( 1.387)	Loss 7.9592e-03 (2.8024e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [170][40/51]	Time  3.032 ( 2.462)	Data  1.807 ( 1.502)	Loss 1.8577e-01 (3.8353e-02)	Acc@1  95.31 ( 98.93)	Acc@5  98.44 ( 99.92)
Epoch: [170][50/51]	Time  2.180 ( 2.492)	Data  0.973 ( 1.495)	Loss 4.2107e-02 (3.5547e-02)	Acc@1 100.00 ( 98.98)	Acc@5 100.00 ( 99.94)
learning rate is: 0.00010000000000000002
Epoch: [171][ 0/51]	Time  3.391 ( 3.391)	Data  2.126 ( 2.126)	Loss 2.9541e-03 (2.9541e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [171][10/51]	Time  1.564 ( 2.320)	Data  0.616 ( 1.274)	Loss 1.1845e-01 (4.1567e-02)	Acc@1  96.88 ( 98.86)	Acc@5  98.44 ( 99.86)
Epoch: [171][20/51]	Time  2.834 ( 2.023)	Data  1.790 ( 1.084)	Loss 1.7978e-01 (5.3192e-02)	Acc@1  96.88 ( 98.88)	Acc@5  98.44 ( 99.63)
Epoch: [171][30/51]	Time  2.014 ( 2.132)	Data  0.924 ( 1.134)	Loss 5.6613e-02 (5.3152e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 ( 99.70)
Epoch: [171][40/51]	Time  3.031 ( 2.297)	Data  1.919 ( 1.264)	Loss 2.8501e-02 (4.7682e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.77)
Epoch: [171][50/51]	Time  1.402 ( 2.288)	Data  0.322 ( 1.261)	Loss 8.2838e-02 (4.8429e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [172][ 0/51]	Time  2.756 ( 2.756)	Data  1.735 ( 1.735)	Loss 6.9241e-03 (6.9241e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [172][10/51]	Time  3.252 ( 3.150)	Data  1.795 ( 1.868)	Loss 1.0790e-01 (4.2348e-02)	Acc@1  96.88 ( 98.86)	Acc@5  98.44 ( 99.86)
Epoch: [172][20/51]	Time  1.230 ( 2.831)	Data  0.462 ( 1.632)	Loss 1.3331e-02 (4.3800e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [172][30/51]	Time  3.294 ( 2.899)	Data  1.945 ( 1.694)	Loss 4.6507e-02 (4.1056e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.85)
Epoch: [172][40/51]	Time  1.343 ( 2.633)	Data  0.517 ( 1.506)	Loss 1.6493e-01 (5.0230e-02)	Acc@1  95.31 ( 98.48)	Acc@5  98.44 ( 99.73)
Epoch: [172][50/51]	Time  2.585 ( 2.463)	Data  1.166 ( 1.371)	Loss 1.0958e-01 (5.1903e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [173][ 0/51]	Time  3.313 ( 3.313)	Data  1.953 ( 1.953)	Loss 2.2280e-02 (2.2280e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [173][10/51]	Time  3.162 ( 2.808)	Data  1.861 ( 1.608)	Loss 4.0215e-02 (5.4943e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [173][20/51]	Time  3.216 ( 2.860)	Data  1.804 ( 1.680)	Loss 2.2804e-03 (4.1092e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.85)
Epoch: [173][30/51]	Time  3.300 ( 2.960)	Data  1.993 ( 1.756)	Loss 3.5813e-02 (4.3872e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.80)
Epoch: [173][40/51]	Time  2.970 ( 2.988)	Data  1.915 ( 1.772)	Loss 1.4811e-02 (4.2446e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.85)
Epoch: [173][50/51]	Time  2.211 ( 2.750)	Data  0.920 ( 1.592)	Loss 3.1912e-02 (4.3430e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [174][ 0/51]	Time  2.736 ( 2.736)	Data  1.706 ( 1.706)	Loss 1.7210e-02 (1.7210e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [174][10/51]	Time  1.394 ( 2.795)	Data  0.786 ( 1.724)	Loss 7.0972e-02 (5.8826e-02)	Acc@1  96.88 ( 97.87)	Acc@5 100.00 ( 99.72)
Epoch: [174][20/51]	Time  1.813 ( 2.314)	Data  0.918 ( 1.324)	Loss 9.5503e-02 (4.6959e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.85)
Epoch: [174][30/51]	Time  2.600 ( 2.132)	Data  1.851 ( 1.198)	Loss 6.8211e-02 (4.8641e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.90)
Epoch: [174][40/51]	Time  1.145 ( 2.165)	Data  0.509 ( 1.218)	Loss 1.0025e-02 (4.9460e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.89)
Epoch: [174][50/51]	Time  0.875 ( 2.095)	Data  0.230 ( 1.162)	Loss 6.5374e-03 (4.9093e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.91)
Test: [0/8]	Time  1.026 ( 1.026)	Loss 1.4935e-01 (1.4935e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.777 ( 2.153)	Loss 1.6996e-01 (1.7505e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [175][ 0/51]	Time  3.320 ( 3.320)	Data  2.251 ( 2.251)	Loss 2.6028e-02 (2.6028e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [175][10/51]	Time  2.989 ( 2.635)	Data  1.731 ( 1.490)	Loss 4.4552e-02 (5.8090e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.57)
Epoch: [175][20/51]	Time  3.204 ( 2.862)	Data  1.827 ( 1.653)	Loss 9.8506e-03 (5.4458e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.63)
Epoch: [175][30/51]	Time  1.450 ( 2.480)	Data  0.665 ( 1.401)	Loss 4.7665e-02 (5.1471e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.70)
Epoch: [175][40/51]	Time  1.509 ( 2.249)	Data  0.751 ( 1.230)	Loss 7.8814e-03 (4.8295e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.73)
Epoch: [175][50/51]	Time  1.115 ( 2.053)	Data  0.221 ( 1.078)	Loss 2.5362e-02 (4.8092e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.72)
learning rate is: 0.00010000000000000002
Epoch: [176][ 0/51]	Time  2.818 ( 2.818)	Data  1.625 ( 1.625)	Loss 2.7709e-02 (2.7709e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [176][10/51]	Time  2.848 ( 1.804)	Data  1.734 ( 0.946)	Loss 1.2859e-02 (4.8339e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.72)
Epoch: [176][20/51]	Time  3.253 ( 1.918)	Data  1.774 ( 0.990)	Loss 6.0169e-02 (5.2044e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 ( 99.78)
Epoch: [176][30/51]	Time  1.542 ( 2.162)	Data  0.515 ( 1.165)	Loss 4.8722e-02 (4.6041e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 ( 99.85)
Epoch: [176][40/51]	Time  3.375 ( 2.442)	Data  1.984 ( 1.372)	Loss 8.5376e-02 (4.5721e-02)	Acc@1  96.88 ( 99.09)	Acc@5 100.00 ( 99.85)
Epoch: [176][50/51]	Time  1.983 ( 2.475)	Data  0.899 ( 1.399)	Loss 1.0744e-01 (4.9593e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.88)
learning rate is: 0.00010000000000000002
Epoch: [177][ 0/51]	Time  2.628 ( 2.628)	Data  1.730 ( 1.730)	Loss 6.2920e-02 (6.2920e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [177][10/51]	Time  3.067 ( 2.154)	Data  2.093 ( 1.320)	Loss 2.5927e-03 (4.0363e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [177][20/51]	Time  2.950 ( 2.552)	Data  1.595 ( 1.587)	Loss 4.6272e-02 (5.1650e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [177][30/51]	Time  1.520 ( 2.342)	Data  0.546 ( 1.393)	Loss 4.7348e-02 (5.4073e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.75)
Epoch: [177][40/51]	Time  1.137 ( 2.117)	Data  0.545 ( 1.235)	Loss 3.0740e-03 (5.8167e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.73)
Epoch: [177][50/51]	Time  0.714 ( 2.043)	Data  0.234 ( 1.174)	Loss 1.7563e-01 (5.6718e-02)	Acc@1  96.77 ( 98.48)	Acc@5  96.77 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [178][ 0/51]	Time  1.656 ( 1.656)	Data  1.076 ( 1.076)	Loss 2.4960e-02 (2.4960e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [178][10/51]	Time  1.155 ( 1.766)	Data  0.409 ( 1.008)	Loss 7.9484e-03 (4.4668e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [178][20/51]	Time  1.464 ( 1.827)	Data  0.646 ( 0.985)	Loss 2.7793e-02 (4.8099e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [178][30/51]	Time  2.927 ( 2.294)	Data  1.796 ( 1.319)	Loss 3.0714e-02 (4.7483e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 ( 99.75)
Epoch: [178][40/51]	Time  2.918 ( 2.444)	Data  1.860 ( 1.410)	Loss 1.0853e-02 (4.7589e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.73)
Epoch: [178][50/51]	Time  1.061 ( 2.401)	Data  0.232 ( 1.362)	Loss 4.1290e-02 (4.7204e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [179][ 0/51]	Time  3.060 ( 3.060)	Data  2.129 ( 2.129)	Loss 2.9423e-02 (2.9423e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [179][10/51]	Time  1.489 ( 1.967)	Data  0.740 ( 1.120)	Loss 2.3178e-02 (2.5739e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [179][20/51]	Time  1.698 ( 2.096)	Data  0.885 ( 1.187)	Loss 1.4548e-02 (4.0527e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.85)
Epoch: [179][30/51]	Time  1.383 ( 1.942)	Data  0.680 ( 1.077)	Loss 2.2903e-03 (5.0202e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.65)
Epoch: [179][40/51]	Time  1.072 ( 1.861)	Data  0.437 ( 1.021)	Loss 3.6758e-02 (4.8009e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.70)
Epoch: [179][50/51]	Time  0.710 ( 1.818)	Data  0.202 ( 0.993)	Loss 8.9309e-02 (4.6984e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 ( 99.72)
Test: [0/8]	Time  0.817 ( 0.817)	Loss 1.4798e-01 (1.4798e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.877 ( 1.455)	Loss 1.6157e-01 (1.6973e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [180][ 0/51]	Time  1.044 ( 1.044)	Data  0.405 ( 0.405)	Loss 9.4524e-02 (9.4524e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [180][10/51]	Time  1.738 ( 1.322)	Data  0.834 ( 0.588)	Loss 8.5025e-02 (5.3220e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [180][20/51]	Time  1.621 ( 1.386)	Data  0.502 ( 0.654)	Loss 1.2926e-02 (6.3886e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [180][30/51]	Time  3.020 ( 1.844)	Data  1.932 ( 0.986)	Loss 1.4809e-01 (6.9185e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [180][40/51]	Time  1.309 ( 1.753)	Data  0.616 ( 0.917)	Loss 1.3219e-02 (6.4624e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.66)
Epoch: [180][50/51]	Time  1.919 ( 1.711)	Data  0.670 ( 0.883)	Loss 1.5908e-01 (6.1874e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [181][ 0/51]	Time  1.255 ( 1.255)	Data  0.489 ( 0.489)	Loss 2.6433e-02 (2.6433e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [181][10/51]	Time  2.748 ( 2.457)	Data  1.621 ( 1.403)	Loss 4.8780e-03 (4.0097e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [181][20/51]	Time  1.745 ( 2.208)	Data  0.705 ( 1.185)	Loss 3.4797e-02 (3.7743e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 ( 99.93)
Epoch: [181][30/51]	Time  1.839 ( 2.091)	Data  1.153 ( 1.121)	Loss 1.5104e-02 (4.2548e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.85)
Epoch: [181][40/51]	Time  2.771 ( 1.983)	Data  1.641 ( 1.049)	Loss 1.2982e-01 (4.6607e-02)	Acc@1  96.88 ( 98.78)	Acc@5 100.00 ( 99.81)
Epoch: [181][50/51]	Time  0.699 ( 2.066)	Data  0.234 ( 1.131)	Loss 1.4155e-01 (5.0674e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [182][ 0/51]	Time  1.401 ( 1.401)	Data  0.727 ( 0.727)	Loss 1.0341e-01 (1.0341e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [182][10/51]	Time  1.857 ( 1.536)	Data  1.017 ( 0.823)	Loss 6.9911e-02 (7.1847e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.72)
Epoch: [182][20/51]	Time  2.947 ( 2.031)	Data  2.068 ( 1.167)	Loss 8.6359e-03 (6.8076e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.63)
Epoch: [182][30/51]	Time  1.105 ( 1.799)	Data  0.550 ( 0.993)	Loss 3.7627e-02 (6.3247e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.70)
Epoch: [182][40/51]	Time  1.136 ( 1.659)	Data  0.607 ( 0.909)	Loss 1.8933e-02 (6.0591e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.70)
Epoch: [182][50/51]	Time  1.029 ( 1.729)	Data  0.231 ( 0.962)	Loss 1.1117e-01 (5.8117e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [183][ 0/51]	Time  2.578 ( 2.578)	Data  1.605 ( 1.605)	Loss 4.6447e-02 (4.6447e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [183][10/51]	Time  1.605 ( 1.401)	Data  0.593 ( 0.732)	Loss 1.9674e-02 (5.8337e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [183][20/51]	Time  1.137 ( 1.604)	Data  0.587 ( 0.884)	Loss 7.3448e-02 (5.1091e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [183][30/51]	Time  1.021 ( 1.473)	Data  0.465 ( 0.785)	Loss 5.7569e-02 (5.7307e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.75)
Epoch: [183][40/51]	Time  1.136 ( 1.401)	Data  0.406 ( 0.712)	Loss 2.5365e-02 (5.2338e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.77)
Epoch: [183][50/51]	Time  0.952 ( 1.504)	Data  0.440 ( 0.785)	Loss 1.6374e-01 (5.4864e-02)	Acc@1  96.77 ( 98.55)	Acc@5  96.77 ( 99.72)
learning rate is: 0.00010000000000000002
Epoch: [184][ 0/51]	Time  1.419 ( 1.419)	Data  0.902 ( 0.902)	Loss 9.4039e-02 (9.4039e-02)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [184][10/51]	Time  3.019 ( 1.740)	Data  1.759 ( 0.950)	Loss 2.1012e-02 (3.7287e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [184][20/51]	Time  2.548 ( 2.316)	Data  1.623 ( 1.406)	Loss 2.1657e-02 (3.9638e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [184][30/51]	Time  1.202 ( 2.299)	Data  0.621 ( 1.398)	Loss 7.2648e-02 (4.4043e-02)	Acc@1  98.44 ( 98.74)	Acc@5  98.44 ( 99.90)
Epoch: [184][40/51]	Time  2.817 ( 2.233)	Data  1.889 ( 1.344)	Loss 4.2567e-03 (4.5800e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.89)
Epoch: [184][50/51]	Time  1.965 ( 2.371)	Data  0.957 ( 1.450)	Loss 3.3332e-01 (4.3899e-02)	Acc@1  90.32 ( 98.79)	Acc@5  96.77 ( 99.88)
Test: [0/8]	Time  2.897 ( 2.897)	Loss 1.4455e-01 (1.4455e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.735 ( 2.102)	Loss 1.6581e-01 (1.7553e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [185][ 0/51]	Time  1.892 ( 1.892)	Data  1.341 ( 1.341)	Loss 3.0451e-03 (3.0451e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [185][10/51]	Time  1.252 ( 1.794)	Data  0.706 ( 1.121)	Loss 6.5113e-02 (3.7761e-02)	Acc@1  98.44 ( 98.72)	Acc@5  98.44 ( 99.72)
Epoch: [185][20/51]	Time  1.172 ( 1.556)	Data  0.426 ( 0.892)	Loss 3.8373e-02 (4.4529e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.78)
Epoch: [185][30/51]	Time  2.706 ( 1.587)	Data  1.742 ( 0.849)	Loss 7.3886e-02 (4.1683e-02)	Acc@1  98.44 ( 98.74)	Acc@5  98.44 ( 99.80)
Epoch: [185][40/51]	Time  2.633 ( 1.647)	Data  1.551 ( 0.903)	Loss 3.2586e-03 (4.2276e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.81)
Epoch: [185][50/51]	Time  1.165 ( 1.680)	Data  0.423 ( 0.940)	Loss 1.1705e-01 (3.9699e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [186][ 0/51]	Time  3.027 ( 3.027)	Data  2.077 ( 2.077)	Loss 2.5784e-02 (2.5784e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [186][10/51]	Time  3.139 ( 2.082)	Data  2.091 ( 1.259)	Loss 1.0025e-01 (5.7051e-02)	Acc@1  95.31 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [186][20/51]	Time  3.034 ( 2.542)	Data  1.782 ( 1.549)	Loss 3.9588e-02 (6.1874e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.78)
Epoch: [186][30/51]	Time  3.353 ( 2.403)	Data  1.962 ( 1.407)	Loss 2.6241e-02 (5.9548e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 ( 99.80)
Epoch: [186][40/51]	Time  1.510 ( 2.429)	Data  0.774 ( 1.421)	Loss 6.9694e-02 (6.1261e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.77)
Epoch: [186][50/51]	Time  1.474 ( 2.265)	Data  0.748 ( 1.294)	Loss 1.3788e-01 (6.2681e-02)	Acc@1  96.77 ( 98.42)	Acc@5 100.00 ( 99.72)
learning rate is: 0.00010000000000000002
Epoch: [187][ 0/51]	Time  2.088 ( 2.088)	Data  1.320 ( 1.320)	Loss 3.8399e-02 (3.8399e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [187][10/51]	Time  1.114 ( 1.519)	Data  0.559 ( 0.820)	Loss 8.1170e-02 (5.5574e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [187][20/51]	Time  3.321 ( 1.841)	Data  2.044 ( 1.057)	Loss 8.0180e-03 (4.2266e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.93)
Epoch: [187][30/51]	Time  1.276 ( 1.741)	Data  0.493 ( 0.947)	Loss 4.2436e-03 (3.7945e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.85)
Epoch: [187][40/51]	Time  1.233 ( 1.978)	Data  0.524 ( 1.124)	Loss 1.0882e-01 (4.4125e-02)	Acc@1  98.44 ( 98.86)	Acc@5  98.44 ( 99.81)
Epoch: [187][50/51]	Time  0.699 ( 1.857)	Data  0.227 ( 1.035)	Loss 1.3683e-01 (4.3971e-02)	Acc@1  96.77 ( 98.79)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [188][ 0/51]	Time  1.028 ( 1.028)	Data  0.497 ( 0.497)	Loss 4.9896e-02 (4.9896e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [188][10/51]	Time  1.444 ( 1.277)	Data  0.887 ( 0.651)	Loss 6.6454e-03 (5.6664e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [188][20/51]	Time  1.118 ( 1.252)	Data  0.604 ( 0.662)	Loss 7.0654e-02 (7.0374e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.55)
Epoch: [188][30/51]	Time  0.954 ( 1.217)	Data  0.389 ( 0.630)	Loss 1.6111e-01 (6.5668e-02)	Acc@1  96.88 ( 98.49)	Acc@5  98.44 ( 99.55)
Epoch: [188][40/51]	Time  0.940 ( 1.349)	Data  0.393 ( 0.720)	Loss 3.0538e-02 (5.8772e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.62)
Epoch: [188][50/51]	Time  0.826 ( 1.419)	Data  0.220 ( 0.781)	Loss 1.1737e-01 (5.9465e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.60)
learning rate is: 0.00010000000000000002
Epoch: [189][ 0/51]	Time  2.828 ( 2.828)	Data  1.753 ( 1.753)	Loss 1.6703e-01 (1.6703e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [189][10/51]	Time  3.110 ( 2.574)	Data  1.954 ( 1.525)	Loss 1.4812e-02 (9.6268e-02)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.15)
Epoch: [189][20/51]	Time  1.182 ( 2.242)	Data  0.508 ( 1.287)	Loss 2.5218e-02 (7.8730e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.48)
Epoch: [189][30/51]	Time  2.918 ( 1.941)	Data  1.916 ( 1.079)	Loss 1.4589e-02 (6.4677e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.65)
Epoch: [189][40/51]	Time  2.809 ( 2.001)	Data  1.775 ( 1.136)	Loss 2.9546e-02 (5.8466e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [189][50/51]	Time  2.152 ( 2.045)	Data  0.902 ( 1.168)	Loss 3.2070e-02 (5.7876e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  3.232 ( 3.232)	Loss 1.4482e-01 (1.4482e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.542 ( 2.817)	Loss 1.6531e-01 (1.7640e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [190][ 0/51]	Time  1.891 ( 1.891)	Data  0.960 ( 0.960)	Loss 1.7364e-01 (1.7364e-01)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 96.88)
Epoch: [190][10/51]	Time  1.651 ( 2.024)	Data  0.610 ( 1.129)	Loss 9.3289e-02 (6.7964e-02)	Acc@1  98.44 ( 98.58)	Acc@5  98.44 ( 99.29)
Epoch: [190][20/51]	Time  2.795 ( 2.462)	Data  1.662 ( 1.411)	Loss 3.3715e-02 (6.4756e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.40)
Epoch: [190][30/51]	Time  1.812 ( 2.321)	Data  0.757 ( 1.291)	Loss 4.0188e-02 (5.6900e-02)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.60)
Epoch: [190][40/51]	Time  2.512 ( 2.351)	Data  1.228 ( 1.302)	Loss 6.3985e-03 (4.9260e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.70)
Epoch: [190][50/51]	Time  2.172 ( 2.508)	Data  1.067 ( 1.405)	Loss 2.0592e-02 (5.2287e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [191][ 0/51]	Time  2.936 ( 2.936)	Data  1.603 ( 1.603)	Loss 3.4576e-02 (3.4576e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [191][10/51]	Time  1.793 ( 2.816)	Data  1.103 ( 1.703)	Loss 1.9825e-02 (4.7472e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [191][20/51]	Time  2.446 ( 2.885)	Data  1.904 ( 1.789)	Loss 1.1418e-01 (4.8108e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [191][30/51]	Time  1.412 ( 2.621)	Data  0.743 ( 1.603)	Loss 2.7477e-02 (4.4871e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 ( 99.90)
Epoch: [191][40/51]	Time  3.400 ( 2.522)	Data  2.180 ( 1.521)	Loss 1.1132e-02 (4.3868e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.81)
Epoch: [191][50/51]	Time  2.086 ( 2.503)	Data  0.994 ( 1.489)	Loss 7.0548e-02 (4.3244e-02)	Acc@1  96.77 ( 98.82)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [192][ 0/51]	Time  3.139 ( 3.139)	Data  1.999 ( 1.999)	Loss 2.2807e-02 (2.2807e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [192][10/51]	Time  1.289 ( 2.710)	Data  0.516 ( 1.639)	Loss 1.5523e-01 (6.8484e-02)	Acc@1  96.88 ( 98.30)	Acc@5  98.44 ( 99.72)
Epoch: [192][20/51]	Time  2.963 ( 2.365)	Data  1.842 ( 1.352)	Loss 6.6521e-02 (7.1823e-02)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 ( 99.78)
Epoch: [192][30/51]	Time  3.542 ( 2.518)	Data  2.012 ( 1.442)	Loss 2.4535e-02 (6.9405e-02)	Acc@1  98.44 ( 97.98)	Acc@5 100.00 ( 99.65)
Epoch: [192][40/51]	Time  3.124 ( 2.676)	Data  1.920 ( 1.553)	Loss 1.5031e-02 (6.8224e-02)	Acc@1 100.00 ( 98.02)	Acc@5 100.00 ( 99.66)
Epoch: [192][50/51]	Time  1.101 ( 2.559)	Data  0.240 ( 1.482)	Loss 3.7998e-01 (6.4271e-02)	Acc@1  90.32 ( 98.17)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [193][ 0/51]	Time  1.324 ( 1.324)	Data  0.570 ( 0.570)	Loss 9.5989e-03 (9.5989e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [193][10/51]	Time  1.679 ( 1.581)	Data  0.673 ( 0.766)	Loss 3.5294e-02 (3.3398e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [193][20/51]	Time  1.191 ( 1.506)	Data  0.661 ( 0.766)	Loss 2.4859e-02 (4.3138e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [193][30/51]	Time  1.158 ( 1.420)	Data  0.429 ( 0.716)	Loss 9.5403e-02 (5.0277e-02)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 ( 99.75)
Epoch: [193][40/51]	Time  1.011 ( 1.356)	Data  0.456 ( 0.677)	Loss 1.8737e-02 (4.3806e-02)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 ( 99.77)
Epoch: [193][50/51]	Time  0.800 ( 1.377)	Data  0.341 ( 0.696)	Loss 9.9031e-03 (3.9937e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [194][ 0/51]	Time  1.321 ( 1.321)	Data  0.501 ( 0.501)	Loss 2.6940e-02 (2.6940e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [194][10/51]	Time  1.349 ( 1.544)	Data  0.488 ( 0.812)	Loss 4.5385e-02 (7.1046e-02)	Acc@1  98.44 ( 97.59)	Acc@5 100.00 ( 99.72)
Epoch: [194][20/51]	Time  1.955 ( 1.855)	Data  0.946 ( 1.029)	Loss 1.3301e-02 (6.0417e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.63)
Epoch: [194][30/51]	Time  0.941 ( 1.623)	Data  0.379 ( 0.864)	Loss 3.3575e-03 (5.4053e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 ( 99.75)
Epoch: [194][40/51]	Time  1.399 ( 1.528)	Data  0.468 ( 0.777)	Loss 2.1391e-02 (5.2550e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.73)
Epoch: [194][50/51]	Time  1.726 ( 1.669)	Data  0.840 ( 0.878)	Loss 1.5851e-01 (5.2157e-02)	Acc@1  96.77 ( 98.55)	Acc@5  96.77 ( 99.72)
Test: [0/8]	Time  1.020 ( 1.020)	Loss 1.4869e-01 (1.4869e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.288 ( 1.167)	Loss 1.6060e-01 (1.6952e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [195][ 0/51]	Time  1.124 ( 1.124)	Data  0.457 ( 0.457)	Loss 7.2608e-02 (7.2608e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [195][10/51]	Time  1.382 ( 2.411)	Data  0.763 ( 1.493)	Loss 7.9806e-02 (6.2088e-02)	Acc@1  95.31 ( 98.30)	Acc@5 100.00 ( 99.43)
Epoch: [195][20/51]	Time  2.800 ( 2.093)	Data  1.783 ( 1.244)	Loss 3.0567e-02 (5.0971e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.70)
Epoch: [195][30/51]	Time  1.089 ( 1.929)	Data  0.540 ( 1.125)	Loss 9.4572e-02 (6.4765e-02)	Acc@1  96.88 ( 98.29)	Acc@5  98.44 ( 99.55)
Epoch: [195][40/51]	Time  1.062 ( 1.784)	Data  0.492 ( 1.025)	Loss 1.7388e-02 (5.5765e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.62)
Epoch: [195][50/51]	Time  0.959 ( 1.777)	Data  0.220 ( 1.015)	Loss 2.6068e-02 (5.6265e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.63)
learning rate is: 0.00010000000000000002
Epoch: [196][ 0/51]	Time  2.522 ( 2.522)	Data  1.448 ( 1.448)	Loss 1.6860e-02 (1.6860e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [196][10/51]	Time  2.448 ( 3.022)	Data  1.522 ( 1.924)	Loss 5.3740e-02 (4.4998e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 ( 99.72)
Epoch: [196][20/51]	Time  3.083 ( 2.946)	Data  2.074 ( 1.870)	Loss 9.3816e-02 (5.4326e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [196][30/51]	Time  1.851 ( 2.551)	Data  0.874 ( 1.561)	Loss 8.8301e-03 (5.5960e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.80)
Epoch: [196][40/51]	Time  1.695 ( 2.352)	Data  0.685 ( 1.391)	Loss 9.3069e-03 (5.2728e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.77)
Epoch: [196][50/51]	Time  0.643 ( 2.147)	Data  0.192 ( 1.248)	Loss 1.2114e-01 (5.0787e-02)	Acc@1  93.55 ( 98.67)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [197][ 0/51]	Time  1.213 ( 1.213)	Data  0.669 ( 0.669)	Loss 1.8866e-01 (1.8866e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [197][10/51]	Time  1.267 ( 1.216)	Data  0.475 ( 0.620)	Loss 1.6363e-02 (5.1393e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [197][20/51]	Time  2.765 ( 1.646)	Data  1.812 ( 0.869)	Loss 1.1863e-01 (4.9167e-02)	Acc@1  95.31 ( 98.59)	Acc@5 100.00 ( 99.78)
Epoch: [197][30/51]	Time  3.180 ( 1.931)	Data  2.069 ( 1.093)	Loss 2.0260e-02 (4.6581e-02)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.80)
Epoch: [197][40/51]	Time  2.754 ( 2.041)	Data  1.748 ( 1.188)	Loss 3.7647e-02 (4.6744e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.81)
Epoch: [197][50/51]	Time  2.103 ( 2.208)	Data  1.067 ( 1.315)	Loss 2.1946e-02 (4.3513e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [198][ 0/51]	Time  3.149 ( 3.149)	Data  2.129 ( 2.129)	Loss 2.1686e-02 (2.1686e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [198][10/51]	Time  3.727 ( 2.170)	Data  2.442 ( 1.287)	Loss 1.6279e-01 (5.7613e-02)	Acc@1  95.31 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [198][20/51]	Time  3.022 ( 2.292)	Data  2.087 ( 1.391)	Loss 7.8583e-02 (6.7994e-02)	Acc@1  98.44 ( 98.29)	Acc@5  98.44 ( 99.55)
Epoch: [198][30/51]	Time  2.895 ( 2.226)	Data  1.780 ( 1.359)	Loss 1.1333e-01 (6.7318e-02)	Acc@1  96.88 ( 98.19)	Acc@5  96.88 ( 99.55)
Epoch: [198][40/51]	Time  2.716 ( 2.097)	Data  1.668 ( 1.274)	Loss 8.1067e-03 (6.0216e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.62)
Epoch: [198][50/51]	Time  0.886 ( 2.008)	Data  0.386 ( 1.216)	Loss 2.9498e-02 (5.5947e-02)	Acc@1 100.00 ( 98.45)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [199][ 0/51]	Time  1.590 ( 1.590)	Data  1.048 ( 1.048)	Loss 1.0133e-01 (1.0133e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [199][10/51]	Time  1.142 ( 1.348)	Data  0.523 ( 0.707)	Loss 5.7105e-02 (5.3114e-02)	Acc@1  96.88 ( 98.01)	Acc@5 100.00 (100.00)
Epoch: [199][20/51]	Time  1.312 ( 1.304)	Data  0.756 ( 0.682)	Loss 2.8083e-02 (4.3567e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 (100.00)
Epoch: [199][30/51]	Time  1.254 ( 1.397)	Data  0.523 ( 0.756)	Loss 8.5263e-03 (3.9987e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.95)
Epoch: [199][40/51]	Time  1.106 ( 1.445)	Data  0.533 ( 0.781)	Loss 7.5815e-03 (4.7410e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.85)
Epoch: [199][50/51]	Time  0.879 ( 1.622)	Data  0.386 ( 0.903)	Loss 6.9727e-02 (4.9496e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  0.818 ( 0.818)	Loss 1.4822e-01 (1.4822e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.810 ( 0.833)	Loss 1.7290e-01 (1.7427e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [200][ 0/51]	Time  1.122 ( 1.122)	Data  0.570 ( 0.570)	Loss 1.2456e-02 (1.2456e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [200][10/51]	Time  2.697 ( 1.315)	Data  1.693 ( 0.627)	Loss 1.3549e-01 (4.6382e-02)	Acc@1  95.31 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [200][20/51]	Time  1.160 ( 1.910)	Data  0.548 ( 1.096)	Loss 1.7830e-02 (4.5802e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.93)
Epoch: [200][30/51]	Time  1.270 ( 1.684)	Data  0.631 ( 0.922)	Loss 5.1131e-03 (5.2992e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.80)
Epoch: [200][40/51]	Time  3.103 ( 1.776)	Data  1.835 ( 0.987)	Loss 1.6604e-02 (4.9788e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.85)
Epoch: [200][50/51]	Time  0.749 ( 1.935)	Data  0.264 ( 1.123)	Loss 1.8163e-01 (4.9264e-02)	Acc@1  93.55 ( 98.64)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [201][ 0/51]	Time  1.123 ( 1.123)	Data  0.564 ( 0.564)	Loss 1.5285e-02 (1.5285e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [201][10/51]	Time  2.980 ( 1.744)	Data  1.832 ( 0.958)	Loss 1.1774e-02 (6.3063e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [201][20/51]	Time  0.998 ( 1.896)	Data  0.441 ( 1.057)	Loss 1.5419e-01 (7.7106e-02)	Acc@1  95.31 ( 98.07)	Acc@5  98.44 ( 99.33)
Epoch: [201][30/51]	Time  1.259 ( 1.877)	Data  0.505 ( 1.036)	Loss 6.8170e-02 (6.4570e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 ( 99.55)
Epoch: [201][40/51]	Time  2.074 ( 1.827)	Data  1.517 ( 1.019)	Loss 5.3006e-02 (6.0308e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.62)
Epoch: [201][50/51]	Time  1.808 ( 1.986)	Data  0.953 ( 1.148)	Loss 1.5989e-01 (5.9019e-02)	Acc@1  93.55 ( 98.64)	Acc@5 100.00 ( 99.63)
learning rate is: 0.00010000000000000002
Epoch: [202][ 0/51]	Time  1.166 ( 1.166)	Data  0.617 ( 0.617)	Loss 1.2280e-02 (1.2280e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [202][10/51]	Time  0.983 ( 2.153)	Data  0.432 ( 1.279)	Loss 5.0078e-02 (5.1311e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.43)
Epoch: [202][20/51]	Time  1.059 ( 2.180)	Data  0.514 ( 1.317)	Loss 2.4459e-02 (5.3129e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.63)
Epoch: [202][30/51]	Time  0.999 ( 2.183)	Data  0.456 ( 1.316)	Loss 1.8454e-02 (5.0507e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.65)
Epoch: [202][40/51]	Time  2.745 ( 2.323)	Data  1.822 ( 1.415)	Loss 2.1020e-02 (4.4926e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.73)
Epoch: [202][50/51]	Time  0.744 ( 2.242)	Data  0.265 ( 1.365)	Loss 1.5178e-01 (5.0482e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [203][ 0/51]	Time  1.015 ( 1.015)	Data  0.477 ( 0.477)	Loss 6.8057e-02 (6.8057e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [203][10/51]	Time  2.714 ( 1.749)	Data  1.633 ( 0.998)	Loss 8.0669e-03 (3.2920e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [203][20/51]	Time  2.851 ( 1.870)	Data  1.828 ( 1.086)	Loss 9.1881e-02 (4.5613e-02)	Acc@1  98.44 ( 98.59)	Acc@5  98.44 ( 99.78)
Epoch: [203][30/51]	Time  1.048 ( 2.002)	Data  0.512 ( 1.207)	Loss 1.1671e-01 (4.7740e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.85)
Epoch: [203][40/51]	Time  1.128 ( 1.809)	Data  0.514 ( 1.064)	Loss 4.1971e-02 (5.0110e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.85)
Epoch: [203][50/51]	Time  1.221 ( 1.759)	Data  0.292 ( 1.020)	Loss 4.7051e-01 (5.6365e-02)	Acc@1  87.10 ( 98.30)	Acc@5  93.55 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [204][ 0/51]	Time  1.670 ( 1.670)	Data  1.057 ( 1.057)	Loss 1.3261e-01 (1.3261e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [204][10/51]	Time  2.701 ( 1.914)	Data  1.660 ( 1.143)	Loss 5.4551e-02 (6.2725e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.72)
Epoch: [204][20/51]	Time  1.227 ( 1.971)	Data  0.543 ( 1.167)	Loss 6.2120e-03 (5.6883e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.70)
Epoch: [204][30/51]	Time  2.886 ( 1.902)	Data  1.743 ( 1.085)	Loss 3.7243e-03 (5.2347e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [204][40/51]	Time  2.826 ( 2.040)	Data  1.792 ( 1.186)	Loss 6.2207e-02 (5.4006e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.77)
Epoch: [204][50/51]	Time  2.036 ( 2.154)	Data  0.931 ( 1.280)	Loss 3.5645e-02 (5.2657e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  2.830 ( 2.830)	Loss 1.5184e-01 (1.5184e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.348 ( 2.725)	Loss 1.7318e-01 (1.7163e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [205][ 0/51]	Time  2.213 ( 2.213)	Data  1.301 ( 1.301)	Loss 3.6020e-03 (3.6020e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [205][10/51]	Time  3.510 ( 2.113)	Data  2.430 ( 1.262)	Loss 2.6452e-03 (2.3579e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [205][20/51]	Time  2.983 ( 2.582)	Data  1.949 ( 1.568)	Loss 1.8179e-02 (3.1392e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 ( 99.93)
Epoch: [205][30/51]	Time  1.611 ( 2.661)	Data  0.662 ( 1.626)	Loss 1.3376e-01 (4.3148e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [205][40/51]	Time  1.304 ( 2.446)	Data  0.517 ( 1.468)	Loss 1.7080e-01 (4.9236e-02)	Acc@1  96.88 ( 98.55)	Acc@5  96.88 ( 99.77)
Epoch: [205][50/51]	Time  1.042 ( 2.215)	Data  0.561 ( 1.299)	Loss 4.2521e-02 (4.7710e-02)	Acc@1 100.00 ( 98.61)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [206][ 0/51]	Time  1.091 ( 1.091)	Data  0.456 ( 0.456)	Loss 3.0617e-03 (3.0617e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [206][10/51]	Time  1.525 ( 2.123)	Data  0.606 ( 1.265)	Loss 9.1710e-02 (4.3905e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [206][20/51]	Time  3.390 ( 2.139)	Data  2.216 ( 1.277)	Loss 4.1180e-02 (5.3398e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.78)
Epoch: [206][30/51]	Time  3.443 ( 2.133)	Data  2.294 ( 1.278)	Loss 5.4534e-02 (4.8068e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.85)
Epoch: [206][40/51]	Time  2.651 ( 2.240)	Data  1.708 ( 1.360)	Loss 1.4837e-02 (5.2680e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.77)
Epoch: [206][50/51]	Time  1.142 ( 2.156)	Data  0.620 ( 1.292)	Loss 1.6328e-01 (5.2849e-02)	Acc@1  96.77 ( 98.45)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [207][ 0/51]	Time  1.224 ( 1.224)	Data  0.699 ( 0.699)	Loss 5.0567e-02 (5.0567e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [207][10/51]	Time  2.836 ( 2.701)	Data  1.914 ( 1.803)	Loss 8.0689e-02 (5.0719e-02)	Acc@1  96.88 ( 98.58)	Acc@5 100.00 ( 99.57)
Epoch: [207][20/51]	Time  2.831 ( 2.690)	Data  1.819 ( 1.782)	Loss 6.5210e-02 (4.9160e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [207][30/51]	Time  1.045 ( 2.303)	Data  0.453 ( 1.471)	Loss 1.3771e-01 (5.4696e-02)	Acc@1  95.31 ( 98.54)	Acc@5  98.44 ( 99.65)
Epoch: [207][40/51]	Time  1.107 ( 2.212)	Data  0.568 ( 1.395)	Loss 3.1862e-02 (5.5267e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.66)
Epoch: [207][50/51]	Time  1.518 ( 2.107)	Data  0.321 ( 1.297)	Loss 2.2434e-01 (5.6113e-02)	Acc@1  96.77 ( 98.58)	Acc@5  96.77 ( 99.63)
learning rate is: 0.00010000000000000002
Epoch: [208][ 0/51]	Time  3.152 ( 3.152)	Data  1.872 ( 1.872)	Loss 4.0371e-02 (4.0371e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [208][10/51]	Time  2.938 ( 3.082)	Data  1.672 ( 1.828)	Loss 1.5808e-01 (6.3782e-02)	Acc@1  96.88 ( 98.15)	Acc@5 100.00 ( 99.72)
Epoch: [208][20/51]	Time  3.391 ( 3.095)	Data  2.064 ( 1.854)	Loss 7.5718e-02 (5.2998e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 99.78)
Epoch: [208][30/51]	Time  3.082 ( 2.846)	Data  1.924 ( 1.688)	Loss 4.0732e-02 (4.4397e-02)	Acc@1  98.44 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [208][40/51]	Time  2.164 ( 2.808)	Data  1.369 ( 1.681)	Loss 6.6043e-02 (4.3492e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.85)
Epoch: [208][50/51]	Time  1.090 ( 2.547)	Data  0.435 ( 1.485)	Loss 1.9976e-02 (3.9724e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.88)
learning rate is: 0.00010000000000000002
Epoch: [209][ 0/51]	Time  1.247 ( 1.247)	Data  0.593 ( 0.593)	Loss 1.0176e-02 (1.0176e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [209][10/51]	Time  2.901 ( 2.021)	Data  1.982 ( 1.162)	Loss 6.1555e-02 (2.2562e-02)	Acc@1  98.44 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [209][20/51]	Time  2.969 ( 1.946)	Data  1.672 ( 1.098)	Loss 7.2916e-02 (2.7373e-02)	Acc@1  98.44 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [209][30/51]	Time  1.261 ( 2.097)	Data  0.708 ( 1.261)	Loss 6.9641e-02 (3.2115e-02)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 ( 99.90)
Epoch: [209][40/51]	Time  1.170 ( 1.864)	Data  0.440 ( 1.090)	Loss 7.5295e-02 (3.7021e-02)	Acc@1  96.88 ( 98.97)	Acc@5 100.00 ( 99.89)
Epoch: [209][50/51]	Time  0.759 ( 1.776)	Data  0.308 ( 1.025)	Loss 2.1432e-01 (4.0015e-02)	Acc@1  93.55 ( 98.92)	Acc@5  96.77 ( 99.85)
Test: [0/8]	Time  0.981 ( 0.981)	Loss 1.4434e-01 (1.4434e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.716 ( 0.954)	Loss 1.6898e-01 (1.7299e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [210][ 0/51]	Time  3.335 ( 3.335)	Data  2.393 ( 2.393)	Loss 9.8871e-02 (9.8871e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [210][10/51]	Time  1.076 ( 2.485)	Data  0.444 ( 1.544)	Loss 9.1980e-02 (4.1964e-02)	Acc@1  96.88 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [210][20/51]	Time  1.270 ( 1.928)	Data  0.542 ( 1.147)	Loss 1.4907e-01 (5.0011e-02)	Acc@1  96.88 ( 98.88)	Acc@5  98.44 ( 99.63)
Epoch: [210][30/51]	Time  3.103 ( 1.763)	Data  2.061 ( 1.020)	Loss 1.4484e-01 (5.1974e-02)	Acc@1  96.88 ( 98.79)	Acc@5  98.44 ( 99.70)
Epoch: [210][40/51]	Time  1.546 ( 1.661)	Data  0.951 ( 0.958)	Loss 3.1009e-03 (5.0294e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.73)
Epoch: [210][50/51]	Time  0.652 ( 1.616)	Data  0.198 ( 0.921)	Loss 1.0118e-01 (5.0396e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [211][ 0/51]	Time  0.993 ( 0.993)	Data  0.466 ( 0.466)	Loss 7.0759e-02 (7.0759e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [211][10/51]	Time  1.184 ( 2.299)	Data  0.437 ( 1.405)	Loss 6.0175e-02 (6.0879e-02)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.86)
Epoch: [211][20/51]	Time  3.286 ( 2.643)	Data  2.028 ( 1.608)	Loss 5.6713e-02 (5.5660e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.85)
Epoch: [211][30/51]	Time  3.448 ( 2.437)	Data  2.079 ( 1.447)	Loss 1.1717e-02 (4.8115e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.90)
Epoch: [211][40/51]	Time  2.478 ( 2.528)	Data  1.632 ( 1.500)	Loss 3.6545e-02 (5.1907e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.92)
Epoch: [211][50/51]	Time  0.846 ( 2.275)	Data  0.207 ( 1.312)	Loss 2.9754e-02 (4.7613e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.94)
learning rate is: 0.00010000000000000002
Epoch: [212][ 0/51]	Time  2.322 ( 2.322)	Data  1.587 ( 1.587)	Loss 1.1703e-02 (1.1703e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [212][10/51]	Time  2.292 ( 1.861)	Data  1.626 ( 0.996)	Loss 1.1400e-02 (3.2952e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [212][20/51]	Time  1.074 ( 1.528)	Data  0.525 ( 0.790)	Loss 3.0740e-02 (3.0531e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.93)
Epoch: [212][30/51]	Time  1.014 ( 1.401)	Data  0.406 ( 0.695)	Loss 1.2731e-02 (3.3322e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 ( 99.90)
Epoch: [212][40/51]	Time  1.678 ( 1.445)	Data  0.828 ( 0.719)	Loss 3.5082e-02 (3.5403e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 ( 99.92)
Epoch: [212][50/51]	Time  2.182 ( 1.685)	Data  1.243 ( 0.907)	Loss 5.4090e-02 (3.7181e-02)	Acc@1 100.00 ( 98.98)	Acc@5 100.00 ( 99.94)
learning rate is: 0.00010000000000000002
Epoch: [213][ 0/51]	Time  2.910 ( 2.910)	Data  1.879 ( 1.879)	Loss 8.5984e-02 (8.5984e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [213][10/51]	Time  1.277 ( 1.658)	Data  0.577 ( 0.885)	Loss 3.7809e-02 (5.4312e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [213][20/51]	Time  1.754 ( 1.979)	Data  0.560 ( 1.085)	Loss 8.0402e-03 (6.6386e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.70)
Epoch: [213][30/51]	Time  3.161 ( 2.222)	Data  1.906 ( 1.279)	Loss 1.2818e-01 (6.6788e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.70)
Epoch: [213][40/51]	Time  1.921 ( 2.214)	Data  1.054 ( 1.295)	Loss 5.6233e-03 (7.0202e-02)	Acc@1 100.00 ( 98.06)	Acc@5 100.00 ( 99.58)
Epoch: [213][50/51]	Time  1.173 ( 2.201)	Data  0.613 ( 1.297)	Loss 1.3144e-01 (6.3168e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.66)
learning rate is: 0.00010000000000000002
Epoch: [214][ 0/51]	Time  2.869 ( 2.869)	Data  1.843 ( 1.843)	Loss 5.5146e-02 (5.5146e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [214][10/51]	Time  3.037 ( 3.004)	Data  1.949 ( 1.853)	Loss 5.3866e-02 (3.9028e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [214][20/51]	Time  2.790 ( 2.626)	Data  2.067 ( 1.563)	Loss 1.0299e-02 (3.3865e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.93)
Epoch: [214][30/51]	Time  3.160 ( 2.431)	Data  1.920 ( 1.410)	Loss 9.3537e-02 (4.7657e-02)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.90)
Epoch: [214][40/51]	Time  3.795 ( 2.482)	Data  2.588 ( 1.447)	Loss 3.4088e-02 (4.4758e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.89)
Epoch: [214][50/51]	Time  1.232 ( 2.323)	Data  0.608 ( 1.340)	Loss 9.3163e-02 (4.4048e-02)	Acc@1  96.77 ( 98.82)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  1.084 ( 1.084)	Loss 1.4774e-01 (1.4774e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.449 ( 2.380)	Loss 1.5990e-01 (1.6954e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [215][ 0/51]	Time  1.235 ( 1.235)	Data  0.619 ( 0.619)	Loss 6.2478e-02 (6.2478e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [215][10/51]	Time  2.651 ( 2.720)	Data  1.743 ( 1.700)	Loss 6.8732e-02 (3.2907e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [215][20/51]	Time  2.418 ( 2.897)	Data  1.698 ( 1.827)	Loss 1.1534e-01 (4.4127e-02)	Acc@1  96.88 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [215][30/51]	Time  2.769 ( 2.470)	Data  1.467 ( 1.486)	Loss 5.9303e-03 (4.7612e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [215][40/51]	Time  2.895 ( 2.330)	Data  1.895 ( 1.383)	Loss 9.2933e-02 (4.5410e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.81)
Epoch: [215][50/51]	Time  1.009 ( 2.221)	Data  0.367 ( 1.298)	Loss 4.4922e-02 (4.8790e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [216][ 0/51]	Time  1.290 ( 1.290)	Data  0.532 ( 0.532)	Loss 4.9167e-02 (4.9167e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [216][10/51]	Time  1.395 ( 1.325)	Data  0.794 ( 0.667)	Loss 8.9553e-02 (5.8627e-02)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [216][20/51]	Time  2.784 ( 2.080)	Data  1.643 ( 1.198)	Loss 3.8120e-02 (6.3235e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.70)
Epoch: [216][30/51]	Time  1.091 ( 2.033)	Data  0.525 ( 1.170)	Loss 4.0751e-02 (5.4290e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.70)
Epoch: [216][40/51]	Time  1.458 ( 1.957)	Data  0.790 ( 1.124)	Loss 4.5867e-02 (5.3867e-02)	Acc@1  96.88 ( 98.67)	Acc@5 100.00 ( 99.73)
Epoch: [216][50/51]	Time  0.959 ( 1.841)	Data  0.439 ( 1.051)	Loss 4.7579e-02 (5.1059e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [217][ 0/51]	Time  2.682 ( 2.682)	Data  1.798 ( 1.798)	Loss 3.5791e-02 (3.5791e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [217][10/51]	Time  1.463 ( 2.343)	Data  0.712 ( 1.371)	Loss 8.0333e-02 (5.8770e-02)	Acc@1  96.88 ( 97.87)	Acc@5 100.00 ( 99.86)
Epoch: [217][20/51]	Time  1.248 ( 2.084)	Data  0.504 ( 1.194)	Loss 8.0219e-03 (4.2250e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.93)
Epoch: [217][30/51]	Time  1.314 ( 1.952)	Data  0.674 ( 1.136)	Loss 6.6146e-03 (3.8401e-02)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [217][40/51]	Time  1.393 ( 1.857)	Data  0.862 ( 1.052)	Loss 1.3714e-02 (4.3873e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.77)
Epoch: [217][50/51]	Time  0.666 ( 1.730)	Data  0.201 ( 0.971)	Loss 3.9694e-02 (4.2419e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [218][ 0/51]	Time  1.104 ( 1.104)	Data  0.532 ( 0.532)	Loss 4.3872e-02 (4.3872e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [218][10/51]	Time  1.317 ( 1.187)	Data  0.768 ( 0.632)	Loss 8.5638e-02 (5.9278e-02)	Acc@1  95.31 ( 98.01)	Acc@5 100.00 ( 99.43)
Epoch: [218][20/51]	Time  0.975 ( 1.456)	Data  0.439 ( 0.807)	Loss 1.9240e-01 (6.2878e-02)	Acc@1  98.44 ( 98.14)	Acc@5  98.44 ( 99.55)
Epoch: [218][30/51]	Time  1.436 ( 1.472)	Data  0.486 ( 0.803)	Loss 1.0845e-01 (6.3826e-02)	Acc@1  95.31 ( 98.14)	Acc@5  98.44 ( 99.55)
Epoch: [218][40/51]	Time  1.320 ( 1.423)	Data  0.501 ( 0.748)	Loss 2.9117e-02 (5.8146e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 ( 99.62)
Epoch: [218][50/51]	Time  0.647 ( 1.364)	Data  0.194 ( 0.704)	Loss 3.3388e-01 (5.6863e-02)	Acc@1  90.32 ( 98.36)	Acc@5 100.00 ( 99.66)
learning rate is: 0.00010000000000000002
Epoch: [219][ 0/51]	Time  1.380 ( 1.380)	Data  0.491 ( 0.491)	Loss 1.6651e-02 (1.6651e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [219][10/51]	Time  1.009 ( 2.381)	Data  0.459 ( 1.498)	Loss 7.5023e-02 (4.9812e-02)	Acc@1  96.88 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [219][20/51]	Time  1.903 ( 2.026)	Data  1.168 ( 1.191)	Loss 1.8520e-02 (4.4324e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [219][30/51]	Time  1.399 ( 1.962)	Data  0.417 ( 1.122)	Loss 7.7148e-02 (4.6748e-02)	Acc@1  95.31 ( 98.44)	Acc@5 100.00 ( 99.90)
Epoch: [219][40/51]	Time  1.320 ( 1.932)	Data  0.545 ( 1.074)	Loss 1.5239e-02 (4.3725e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.89)
Epoch: [219][50/51]	Time  0.884 ( 1.854)	Data  0.396 ( 1.017)	Loss 6.7698e-02 (4.6482e-02)	Acc@1 100.00 ( 98.61)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  0.917 ( 0.917)	Loss 1.4291e-01 (1.4291e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.546 ( 1.120)	Loss 1.7585e-01 (1.7054e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [220][ 0/51]	Time  2.618 ( 2.618)	Data  1.694 ( 1.694)	Loss 1.1462e-01 (1.1462e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [220][10/51]	Time  2.832 ( 2.085)	Data  1.740 ( 1.161)	Loss 5.1858e-03 (5.9539e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [220][20/51]	Time  1.305 ( 2.352)	Data  0.519 ( 1.393)	Loss 1.6635e-01 (6.6183e-02)	Acc@1  95.31 ( 98.36)	Acc@5  98.44 ( 99.78)
Epoch: [220][30/51]	Time  1.379 ( 2.275)	Data  0.493 ( 1.349)	Loss 2.1900e-02 (5.8665e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.85)
Epoch: [220][40/51]	Time  3.183 ( 2.234)	Data  2.136 ( 1.319)	Loss 1.6390e-01 (5.4680e-02)	Acc@1  95.31 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [220][50/51]	Time  1.896 ( 2.085)	Data  1.066 ( 1.212)	Loss 4.9103e-02 (5.9576e-02)	Acc@1  96.77 ( 98.45)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [221][ 0/51]	Time  2.816 ( 2.816)	Data  1.847 ( 1.847)	Loss 4.5202e-02 (4.5202e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [221][10/51]	Time  2.900 ( 2.516)	Data  1.955 ( 1.620)	Loss 6.2604e-02 (3.1508e-02)	Acc@1 100.00 ( 99.57)	Acc@5 100.00 (100.00)
Epoch: [221][20/51]	Time  2.883 ( 2.292)	Data  1.985 ( 1.428)	Loss 8.1923e-02 (4.2326e-02)	Acc@1  96.88 ( 99.11)	Acc@5 100.00 ( 99.85)
Epoch: [221][30/51]	Time  1.392 ( 2.142)	Data  0.540 ( 1.315)	Loss 9.4885e-03 (4.8352e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.75)
Epoch: [221][40/51]	Time  1.529 ( 1.984)	Data  0.672 ( 1.202)	Loss 4.0176e-02 (4.4222e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 ( 99.81)
Epoch: [221][50/51]	Time  1.178 ( 2.201)	Data  0.450 ( 1.346)	Loss 1.6528e-01 (5.2875e-02)	Acc@1  96.77 ( 98.76)	Acc@5  96.77 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [222][ 0/51]	Time  1.323 ( 1.323)	Data  0.443 ( 0.443)	Loss 7.9911e-03 (7.9911e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [222][10/51]	Time  1.679 ( 1.784)	Data  0.922 ( 0.992)	Loss 1.7559e-02 (4.1556e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.72)
Epoch: [222][20/51]	Time  1.235 ( 1.691)	Data  0.665 ( 0.940)	Loss 4.3667e-03 (3.8041e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.85)
Epoch: [222][30/51]	Time  1.762 ( 1.537)	Data  0.966 ( 0.828)	Loss 8.3737e-02 (4.1071e-02)	Acc@1  96.88 ( 98.99)	Acc@5 100.00 ( 99.90)
Epoch: [222][40/51]	Time  3.172 ( 1.668)	Data  1.993 ( 0.916)	Loss 1.8761e-02 (4.1508e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.85)
Epoch: [222][50/51]	Time  2.657 ( 1.884)	Data  1.354 ( 1.077)	Loss 7.7046e-02 (4.4030e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [223][ 0/51]	Time  3.139 ( 3.139)	Data  1.794 ( 1.794)	Loss 7.9350e-02 (7.9350e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [223][10/51]	Time  1.534 ( 2.126)	Data  0.999 ( 1.222)	Loss 6.7497e-02 (5.6568e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.72)
Epoch: [223][20/51]	Time  1.421 ( 2.149)	Data  0.778 ( 1.280)	Loss 5.8983e-03 (5.6720e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.70)
Epoch: [223][30/51]	Time  3.163 ( 2.031)	Data  1.853 ( 1.146)	Loss 2.9409e-02 (5.1914e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.70)
Epoch: [223][40/51]	Time  1.486 ( 2.255)	Data  0.461 ( 1.296)	Loss 2.5434e-03 (4.6204e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.77)
Epoch: [223][50/51]	Time  2.275 ( 2.291)	Data  0.987 ( 1.293)	Loss 8.8057e-02 (4.3164e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [224][ 0/51]	Time  3.305 ( 3.305)	Data  1.948 ( 1.948)	Loss 9.4052e-02 (9.4052e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [224][10/51]	Time  3.293 ( 2.406)	Data  1.951 ( 1.344)	Loss 3.3924e-03 (4.3075e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [224][20/51]	Time  1.269 ( 2.009)	Data  0.718 ( 1.066)	Loss 1.0090e-02 (4.2592e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.78)
Epoch: [224][30/51]	Time  2.408 ( 1.901)	Data  1.552 ( 1.020)	Loss 8.8236e-02 (4.2278e-02)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [224][40/51]	Time  3.314 ( 1.869)	Data  1.878 ( 1.002)	Loss 9.0102e-03 (3.8193e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.89)
Epoch: [224][50/51]	Time  1.844 ( 1.959)	Data  0.884 ( 1.064)	Loss 1.8966e-01 (3.9572e-02)	Acc@1  93.55 ( 98.92)	Acc@5 100.00 ( 99.91)
Test: [0/8]	Time  2.675 ( 2.675)	Loss 1.4025e-01 (1.4025e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.964 ( 1.483)	Loss 1.7530e-01 (1.7197e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [225][ 0/51]	Time  1.426 ( 1.426)	Data  0.458 ( 0.458)	Loss 6.8710e-02 (6.8710e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [225][10/51]	Time  1.264 ( 1.471)	Data  0.555 ( 0.715)	Loss 3.7337e-02 (4.3703e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [225][20/51]	Time  1.152 ( 1.495)	Data  0.624 ( 0.790)	Loss 3.1036e-02 (4.0555e-02)	Acc@1  96.88 ( 99.18)	Acc@5 100.00 ( 99.93)
Epoch: [225][30/51]	Time  1.209 ( 1.437)	Data  0.663 ( 0.770)	Loss 5.4370e-02 (4.1789e-02)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 ( 99.85)
Epoch: [225][40/51]	Time  1.349 ( 1.522)	Data  0.435 ( 0.840)	Loss 1.8257e-02 (4.3285e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 ( 99.85)
Epoch: [225][50/51]	Time  1.989 ( 1.729)	Data  0.863 ( 0.983)	Loss 8.9774e-03 (4.5285e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [226][ 0/51]	Time  3.655 ( 3.655)	Data  2.381 ( 2.381)	Loss 1.1593e-02 (1.1593e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [226][10/51]	Time  1.378 ( 2.703)	Data  0.729 ( 1.568)	Loss 2.0545e-02 (3.5798e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [226][20/51]	Time  1.482 ( 2.110)	Data  0.821 ( 1.169)	Loss 8.5368e-02 (4.2018e-02)	Acc@1  96.88 ( 98.81)	Acc@5 100.00 ( 99.70)
Epoch: [226][30/51]	Time  1.291 ( 1.869)	Data  0.565 ( 0.986)	Loss 1.2275e-01 (5.0704e-02)	Acc@1  96.88 ( 98.64)	Acc@5  98.44 ( 99.65)
Epoch: [226][40/51]	Time  3.024 ( 1.833)	Data  1.824 ( 0.966)	Loss 1.0647e-01 (5.1655e-02)	Acc@1  96.88 ( 98.55)	Acc@5 100.00 ( 99.73)
Epoch: [226][50/51]	Time  0.976 ( 1.755)	Data  0.360 ( 0.928)	Loss 5.3812e-01 (5.1860e-02)	Acc@1  87.10 ( 98.51)	Acc@5  93.55 ( 99.72)
learning rate is: 0.00010000000000000002
Epoch: [227][ 0/51]	Time  1.359 ( 1.359)	Data  0.810 ( 0.810)	Loss 8.5535e-02 (8.5535e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [227][10/51]	Time  1.703 ( 1.323)	Data  0.883 ( 0.725)	Loss 1.5063e-01 (5.4522e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.86)
Epoch: [227][20/51]	Time  1.321 ( 1.256)	Data  0.761 ( 0.660)	Loss 2.4596e-02 (5.0416e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [227][30/51]	Time  2.953 ( 1.396)	Data  1.899 ( 0.758)	Loss 5.3099e-02 (4.9823e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [227][40/51]	Time  1.346 ( 1.409)	Data  0.616 ( 0.761)	Loss 7.5043e-02 (4.9258e-02)	Acc@1  98.44 ( 98.55)	Acc@5  98.44 ( 99.81)
Epoch: [227][50/51]	Time  0.690 ( 1.360)	Data  0.212 ( 0.729)	Loss 1.8276e-01 (5.7117e-02)	Acc@1  90.32 ( 98.30)	Acc@5 100.00 ( 99.69)
learning rate is: 0.00010000000000000002
Epoch: [228][ 0/51]	Time  1.470 ( 1.470)	Data  0.807 ( 0.807)	Loss 6.5919e-02 (6.5919e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [228][10/51]	Time  1.007 ( 1.856)	Data  0.457 ( 1.063)	Loss 2.8941e-02 (4.7949e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [228][20/51]	Time  2.853 ( 1.620)	Data  1.788 ( 0.900)	Loss 1.5773e-02 (5.0653e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [228][30/51]	Time  1.397 ( 1.589)	Data  0.784 ( 0.864)	Loss 5.1657e-02 (5.3059e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 ( 99.70)
Epoch: [228][40/51]	Time  1.337 ( 1.566)	Data  0.575 ( 0.853)	Loss 7.0263e-02 (5.2410e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.77)
Epoch: [228][50/51]	Time  1.104 ( 1.604)	Data  0.368 ( 0.877)	Loss 9.9346e-02 (4.7308e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.78)
learning rate is: 0.00010000000000000002
Epoch: [229][ 0/51]	Time  1.699 ( 1.699)	Data  0.972 ( 0.972)	Loss 8.8761e-03 (8.8761e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [229][10/51]	Time  1.340 ( 1.346)	Data  0.773 ( 0.649)	Loss 1.0244e-02 (4.7118e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [229][20/51]	Time  1.044 ( 1.409)	Data  0.515 ( 0.727)	Loss 2.5864e-02 (4.2082e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [229][30/51]	Time  1.092 ( 1.343)	Data  0.481 ( 0.676)	Loss 1.1994e-01 (3.8848e-02)	Acc@1  96.88 ( 98.84)	Acc@5 100.00 ( 99.90)
Epoch: [229][40/51]	Time  1.071 ( 1.377)	Data  0.542 ( 0.708)	Loss 3.1643e-02 (3.6000e-02)	Acc@1  98.44 ( 98.97)	Acc@5 100.00 ( 99.92)
Epoch: [229][50/51]	Time  0.709 ( 1.349)	Data  0.216 ( 0.682)	Loss 1.2244e-01 (3.5737e-02)	Acc@1  96.77 ( 99.04)	Acc@5 100.00 ( 99.94)
Test: [0/8]	Time  0.917 ( 0.917)	Loss 1.4478e-01 (1.4478e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.687 ( 1.987)	Loss 1.4881e-01 (1.6734e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [230][ 0/51]	Time  2.981 ( 2.981)	Data  2.078 ( 2.078)	Loss 1.0267e-01 (1.0267e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [230][10/51]	Time  1.427 ( 2.474)	Data  0.657 ( 1.481)	Loss 5.1745e-02 (1.0906e-01)	Acc@1  98.44 ( 97.02)	Acc@5 100.00 ( 99.29)
Epoch: [230][20/51]	Time  3.532 ( 2.308)	Data  2.196 ( 1.304)	Loss 1.3334e-02 (7.0447e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.55)
Epoch: [230][30/51]	Time  3.149 ( 2.173)	Data  1.900 ( 1.201)	Loss 1.2530e-01 (6.1835e-02)	Acc@1  96.88 ( 98.49)	Acc@5  98.44 ( 99.60)
Epoch: [230][40/51]	Time  3.026 ( 2.239)	Data  1.909 ( 1.248)	Loss 6.1450e-02 (5.9687e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.62)
Epoch: [230][50/51]	Time  1.030 ( 2.169)	Data  0.224 ( 1.196)	Loss 1.1393e-01 (6.0729e-02)	Acc@1  93.55 ( 98.55)	Acc@5 100.00 ( 99.60)
learning rate is: 0.00010000000000000002
Epoch: [231][ 0/51]	Time  1.480 ( 1.480)	Data  0.739 ( 0.739)	Loss 2.6747e-02 (2.6747e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [231][10/51]	Time  1.152 ( 1.403)	Data  0.540 ( 0.672)	Loss 8.9686e-02 (4.9529e-02)	Acc@1  96.88 ( 98.58)	Acc@5  98.44 ( 99.57)
Epoch: [231][20/51]	Time  1.301 ( 1.344)	Data  0.705 ( 0.666)	Loss 1.7312e-02 (4.2104e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.78)
Epoch: [231][30/51]	Time  3.172 ( 1.532)	Data  2.114 ( 0.814)	Loss 1.2647e-02 (3.8451e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.80)
Epoch: [231][40/51]	Time  2.609 ( 1.624)	Data  1.796 ( 0.894)	Loss 7.1749e-02 (4.2101e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.77)
Epoch: [231][50/51]	Time  0.847 ( 1.610)	Data  0.364 ( 0.881)	Loss 1.0783e-01 (5.0254e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.66)
learning rate is: 0.00010000000000000002
Epoch: [232][ 0/51]	Time  1.031 ( 1.031)	Data  0.495 ( 0.495)	Loss 5.1635e-02 (5.1635e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [232][10/51]	Time  1.235 ( 1.128)	Data  0.671 ( 0.552)	Loss 6.2085e-03 (4.3765e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [232][20/51]	Time  1.403 ( 1.292)	Data  0.576 ( 0.681)	Loss 1.3088e-01 (5.2888e-02)	Acc@1  98.44 ( 98.51)	Acc@5  98.44 ( 99.55)
Epoch: [232][30/51]	Time  1.107 ( 1.547)	Data  0.566 ( 0.845)	Loss 1.0691e-02 (4.2987e-02)	Acc@1 100.00 ( 98.84)	Acc@5 100.00 ( 99.70)
Epoch: [232][40/51]	Time  2.686 ( 1.644)	Data  1.737 ( 0.933)	Loss 7.5643e-02 (4.4115e-02)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 ( 99.77)
Epoch: [232][50/51]	Time  0.724 ( 1.607)	Data  0.239 ( 0.911)	Loss 1.0421e-01 (4.1075e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.81)
learning rate is: 0.00010000000000000002
Epoch: [233][ 0/51]	Time  1.214 ( 1.214)	Data  0.654 ( 0.654)	Loss 1.6377e-02 (1.6377e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [233][10/51]	Time  1.283 ( 1.378)	Data  0.682 ( 0.720)	Loss 8.9119e-02 (5.5641e-02)	Acc@1  98.44 ( 98.58)	Acc@5  98.44 ( 99.72)
Epoch: [233][20/51]	Time  1.051 ( 1.327)	Data  0.512 ( 0.687)	Loss 1.3839e-01 (5.4893e-02)	Acc@1  95.31 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [233][30/51]	Time  1.394 ( 1.299)	Data  0.605 ( 0.662)	Loss 1.9508e-02 (4.9505e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [233][40/51]	Time  2.633 ( 1.610)	Data  1.634 ( 0.888)	Loss 4.3379e-02 (4.6688e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.89)
Epoch: [233][50/51]	Time  1.905 ( 1.682)	Data  0.848 ( 0.942)	Loss 1.4678e-01 (4.2960e-02)	Acc@1  96.77 ( 98.95)	Acc@5 100.00 ( 99.91)
learning rate is: 0.00010000000000000002
Epoch: [234][ 0/51]	Time  3.019 ( 3.019)	Data  1.927 ( 1.927)	Loss 1.7605e-01 (1.7605e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [234][10/51]	Time  2.758 ( 2.700)	Data  1.721 ( 1.688)	Loss 1.2722e-02 (6.0917e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [234][20/51]	Time  1.158 ( 2.705)	Data  0.584 ( 1.710)	Loss 6.7191e-02 (5.1609e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.78)
Epoch: [234][30/51]	Time  3.328 ( 2.791)	Data  2.009 ( 1.761)	Loss 9.1235e-02 (5.4698e-02)	Acc@1  96.88 ( 98.64)	Acc@5 100.00 ( 99.65)
Epoch: [234][40/51]	Time  2.937 ( 2.788)	Data  1.643 ( 1.724)	Loss 1.0097e-01 (5.4051e-02)	Acc@1  96.88 ( 98.63)	Acc@5  98.44 ( 99.66)
Epoch: [234][50/51]	Time  2.933 ( 2.784)	Data  1.578 ( 1.713)	Loss 2.5091e-01 (5.1875e-02)	Acc@1  93.55 ( 98.70)	Acc@5  96.77 ( 99.66)
Test: [0/8]	Time  2.405 ( 2.405)	Loss 1.3265e-01 (1.3265e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.374 ( 2.362)	Loss 1.6859e-01 (1.6865e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 0.00010000000000000002
Epoch: [235][ 0/51]	Time  1.431 ( 1.431)	Data  0.627 ( 0.627)	Loss 6.7399e-02 (6.7399e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [235][10/51]	Time  1.513 ( 1.760)	Data  0.720 ( 0.827)	Loss 5.2337e-02 (4.6583e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [235][20/51]	Time  1.307 ( 1.720)	Data  0.494 ( 0.813)	Loss 2.0692e-01 (5.8498e-02)	Acc@1  93.75 ( 98.36)	Acc@5  98.44 ( 99.63)
Epoch: [235][30/51]	Time  3.205 ( 1.778)	Data  2.044 ( 0.867)	Loss 6.6538e-03 (5.1673e-02)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.75)
Epoch: [235][40/51]	Time  1.317 ( 1.975)	Data  0.528 ( 1.022)	Loss 9.4945e-02 (5.2541e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.73)
Epoch: [235][50/51]	Time  1.097 ( 1.856)	Data  0.314 ( 0.937)	Loss 1.9124e-02 (5.3953e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.75)
learning rate is: 0.00010000000000000002
Epoch: [236][ 0/51]	Time  1.445 ( 1.445)	Data  0.492 ( 0.492)	Loss 4.2494e-03 (4.2494e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [236][10/51]	Time  1.760 ( 1.918)	Data  0.942 ( 0.934)	Loss 5.8346e-02 (4.0801e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.72)
Epoch: [236][20/51]	Time  1.961 ( 1.833)	Data  0.999 ( 0.937)	Loss 3.6294e-02 (5.4405e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.70)
Epoch: [236][30/51]	Time  2.798 ( 1.878)	Data  1.723 ( 0.993)	Loss 2.6344e-02 (5.5786e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.65)
Epoch: [236][40/51]	Time  4.108 ( 2.221)	Data  2.901 ( 1.248)	Loss 1.6011e-02 (5.8133e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.54)
Epoch: [236][50/51]	Time  1.333 ( 2.118)	Data  0.374 ( 1.181)	Loss 3.4452e-01 (5.6596e-02)	Acc@1  90.32 ( 98.58)	Acc@5  96.77 ( 99.60)
learning rate is: 0.00010000000000000002
Epoch: [237][ 0/51]	Time  2.273 ( 2.273)	Data  1.429 ( 1.429)	Loss 1.8913e-01 (1.8913e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [237][10/51]	Time  1.300 ( 2.155)	Data  0.513 ( 1.178)	Loss 8.2098e-03 (4.7779e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [237][20/51]	Time  2.015 ( 2.144)	Data  1.212 ( 1.164)	Loss 7.6682e-02 (5.0374e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.78)
Epoch: [237][30/51]	Time  1.511 ( 2.034)	Data  0.752 ( 1.058)	Loss 4.0520e-02 (5.0986e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.80)
Epoch: [237][40/51]	Time  1.524 ( 1.884)	Data  0.603 ( 0.959)	Loss 1.2319e-02 (4.8934e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.81)
Epoch: [237][50/51]	Time  0.728 ( 1.783)	Data  0.247 ( 0.897)	Loss 4.4281e-02 (4.4883e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.85)
learning rate is: 0.00010000000000000002
Epoch: [238][ 0/51]	Time  1.656 ( 1.656)	Data  0.928 ( 0.928)	Loss 1.0753e-01 (1.0753e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [238][10/51]	Time  1.120 ( 1.319)	Data  0.424 ( 0.646)	Loss 6.0091e-02 (5.0974e-02)	Acc@1  95.31 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [238][20/51]	Time  1.323 ( 1.435)	Data  0.454 ( 0.720)	Loss 1.0361e-02 (3.7578e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.93)
Epoch: [238][30/51]	Time  0.999 ( 1.383)	Data  0.472 ( 0.684)	Loss 1.4613e-01 (3.7209e-02)	Acc@1  95.31 ( 98.94)	Acc@5  98.44 ( 99.90)
Epoch: [238][40/51]	Time  3.216 ( 1.652)	Data  2.020 ( 0.870)	Loss 8.9055e-02 (4.6139e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 ( 99.89)
Epoch: [238][50/51]	Time  1.707 ( 1.606)	Data  0.841 ( 0.829)	Loss 7.1465e-02 (4.5880e-02)	Acc@1  96.77 ( 98.73)	Acc@5 100.00 ( 99.91)
learning rate is: 0.00010000000000000002
Epoch: [239][ 0/51]	Time  3.351 ( 3.351)	Data  2.313 ( 2.313)	Loss 1.9280e-02 (1.9280e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [239][10/51]	Time  1.272 ( 2.114)	Data  0.691 ( 1.297)	Loss 3.3129e-02 (4.1243e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [239][20/51]	Time  2.956 ( 1.864)	Data  1.717 ( 1.032)	Loss 8.1079e-03 (3.8116e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.93)
Epoch: [239][30/51]	Time  2.609 ( 1.751)	Data  1.525 ( 0.975)	Loss 1.6372e-02 (5.6568e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.60)
Epoch: [239][40/51]	Time  1.363 ( 1.738)	Data  0.823 ( 0.976)	Loss 8.5071e-02 (6.3433e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 ( 99.62)
Epoch: [239][50/51]	Time  1.534 ( 1.754)	Data  0.911 ( 0.999)	Loss 1.6346e-01 (6.3154e-02)	Acc@1  93.55 ( 98.42)	Acc@5 100.00 ( 99.63)
Test: [0/8]	Time  0.891 ( 0.891)	Loss 1.3825e-01 (1.3825e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.819 ( 0.983)	Loss 1.6702e-01 (1.7350e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [240][ 0/51]	Time  1.216 ( 1.216)	Data  0.513 ( 0.513)	Loss 1.1649e-01 (1.1649e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [240][10/51]	Time  1.604 ( 1.474)	Data  1.083 ( 0.889)	Loss 2.2301e-02 (3.8259e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.72)
Epoch: [240][20/51]	Time  2.599 ( 1.825)	Data  1.592 ( 1.104)	Loss 4.4797e-02 (3.5057e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 ( 99.78)
Epoch: [240][30/51]	Time  1.138 ( 1.803)	Data  0.612 ( 1.081)	Loss 4.3194e-02 (3.5351e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 ( 99.80)
Epoch: [240][40/51]	Time  1.224 ( 1.725)	Data  0.707 ( 1.012)	Loss 2.3215e-02 (3.5147e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.77)
Epoch: [240][50/51]	Time  0.822 ( 1.770)	Data  0.365 ( 1.043)	Loss 9.8900e-02 (4.0534e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [241][ 0/51]	Time  1.438 ( 1.438)	Data  0.850 ( 0.850)	Loss 2.4328e-03 (2.4328e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [241][10/51]	Time  1.030 ( 1.149)	Data  0.492 ( 0.558)	Loss 2.2924e-02 (4.7842e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [241][20/51]	Time  1.183 ( 1.276)	Data  0.496 ( 0.666)	Loss 2.9804e-02 (4.5971e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.78)
Epoch: [241][30/51]	Time  1.167 ( 1.361)	Data  0.645 ( 0.716)	Loss 1.3875e-01 (5.6054e-02)	Acc@1  96.88 ( 98.69)	Acc@5  98.44 ( 99.55)
Epoch: [241][40/51]	Time  1.312 ( 1.590)	Data  0.762 ( 0.878)	Loss 4.9683e-02 (5.6182e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.58)
Epoch: [241][50/51]	Time  0.791 ( 1.552)	Data  0.308 ( 0.867)	Loss 2.4466e-02 (5.5629e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.57)
learning rate is: 1.0000000000000003e-05
Epoch: [242][ 0/51]	Time  1.229 ( 1.229)	Data  0.614 ( 0.614)	Loss 8.2062e-02 (8.2062e-02)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [242][10/51]	Time  1.074 ( 1.435)	Data  0.557 ( 0.802)	Loss 1.6862e-02 (3.7904e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [242][20/51]	Time  1.252 ( 1.337)	Data  0.526 ( 0.698)	Loss 1.5110e-02 (3.3288e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.93)
Epoch: [242][30/51]	Time  2.958 ( 1.550)	Data  1.565 ( 0.801)	Loss 2.0013e-02 (3.6563e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 ( 99.95)
Epoch: [242][40/51]	Time  2.875 ( 1.937)	Data  1.844 ( 1.088)	Loss 9.1054e-03 (3.6812e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 ( 99.96)
Epoch: [242][50/51]	Time  1.280 ( 1.909)	Data  0.621 ( 1.079)	Loss 4.0491e-02 (3.6742e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 ( 99.97)
learning rate is: 1.0000000000000003e-05
Epoch: [243][ 0/51]	Time  1.599 ( 1.599)	Data  0.660 ( 0.660)	Loss 1.0827e-01 (1.0827e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [243][10/51]	Time  0.965 ( 1.454)	Data  0.435 ( 0.769)	Loss 1.2645e-01 (4.6043e-02)	Acc@1  95.31 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [243][20/51]	Time  3.027 ( 1.870)	Data  1.963 ( 1.073)	Loss 8.2435e-02 (4.8615e-02)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [243][30/51]	Time  1.425 ( 1.901)	Data  0.853 ( 1.076)	Loss 3.5575e-02 (5.2409e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [243][40/51]	Time  1.244 ( 1.892)	Data  0.672 ( 1.077)	Loss 2.1590e-02 (4.8173e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 ( 99.77)
Epoch: [243][50/51]	Time  0.931 ( 1.823)	Data  0.209 ( 1.027)	Loss 2.1182e-01 (5.0312e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [244][ 0/51]	Time  1.063 ( 1.063)	Data  0.515 ( 0.515)	Loss 6.4571e-03 (6.4571e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [244][10/51]	Time  1.123 ( 1.177)	Data  0.484 ( 0.612)	Loss 1.2951e-01 (6.4976e-02)	Acc@1  95.31 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [244][20/51]	Time  1.111 ( 1.359)	Data  0.554 ( 0.743)	Loss 1.0872e-01 (5.1927e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 ( 99.93)
Epoch: [244][30/51]	Time  1.834 ( 1.467)	Data  1.279 ( 0.828)	Loss 6.2997e-03 (5.3583e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.95)
Epoch: [244][40/51]	Time  2.584 ( 1.428)	Data  1.757 ( 0.792)	Loss 7.6850e-02 (5.9513e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 ( 99.85)
Epoch: [244][50/51]	Time  1.699 ( 1.470)	Data  0.775 ( 0.816)	Loss 1.5749e-01 (5.7096e-02)	Acc@1  93.55 ( 98.42)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  2.914 ( 2.914)	Loss 1.3331e-01 (1.3331e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.760 ( 2.406)	Loss 1.7395e-01 (1.6865e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [245][ 0/51]	Time  1.622 ( 1.622)	Data  1.083 ( 1.083)	Loss 2.5740e-03 (2.5740e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [245][10/51]	Time  1.056 ( 1.245)	Data  0.528 ( 0.647)	Loss 1.5785e-03 (6.0006e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [245][20/51]	Time  2.745 ( 1.743)	Data  1.702 ( 1.012)	Loss 6.2886e-02 (5.7539e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.70)
Epoch: [245][30/51]	Time  2.643 ( 1.760)	Data  1.632 ( 1.014)	Loss 2.6849e-03 (5.2906e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.75)
Epoch: [245][40/51]	Time  1.572 ( 1.658)	Data  1.056 ( 0.942)	Loss 1.3281e-02 (5.1774e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.73)
Epoch: [245][50/51]	Time  2.138 ( 1.649)	Data  0.910 ( 0.917)	Loss 2.6025e-01 (5.1694e-02)	Acc@1  96.77 ( 98.76)	Acc@5  96.77 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [246][ 0/51]	Time  1.421 ( 1.421)	Data  0.638 ( 0.638)	Loss 1.0755e-02 (1.0755e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [246][10/51]	Time  1.198 ( 1.385)	Data  0.433 ( 0.693)	Loss 3.3711e-02 (4.4360e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.57)
Epoch: [246][20/51]	Time  3.050 ( 1.466)	Data  2.089 ( 0.780)	Loss 1.6989e-02 (3.8961e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.63)
Epoch: [246][30/51]	Time  3.438 ( 1.873)	Data  2.410 ( 1.097)	Loss 4.3460e-03 (3.4418e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.75)
Epoch: [246][40/51]	Time  1.281 ( 1.859)	Data  0.742 ( 1.084)	Loss 1.3935e-01 (3.6040e-02)	Acc@1  96.88 ( 98.97)	Acc@5  96.88 ( 99.70)
Epoch: [246][50/51]	Time  1.487 ( 1.760)	Data  0.493 ( 0.992)	Loss 1.7437e-02 (4.2066e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.69)
learning rate is: 1.0000000000000003e-05
Epoch: [247][ 0/51]	Time  3.316 ( 3.316)	Data  2.199 ( 2.199)	Loss 1.0194e-02 (1.0194e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [247][10/51]	Time  1.380 ( 2.305)	Data  0.622 ( 1.393)	Loss 1.7303e-02 (3.7853e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [247][20/51]	Time  2.700 ( 1.886)	Data  1.798 ( 1.102)	Loss 7.0810e-02 (4.3087e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.93)
Epoch: [247][30/51]	Time  1.045 ( 1.720)	Data  0.496 ( 0.977)	Loss 1.5650e-01 (5.1994e-02)	Acc@1  98.44 ( 98.64)	Acc@5  98.44 ( 99.85)
Epoch: [247][40/51]	Time  1.516 ( 1.603)	Data  0.734 ( 0.893)	Loss 1.0327e-01 (4.9529e-02)	Acc@1  96.88 ( 98.70)	Acc@5  98.44 ( 99.81)
Epoch: [247][50/51]	Time  0.939 ( 1.527)	Data  0.187 ( 0.827)	Loss 3.7897e-02 (4.9568e-02)	Acc@1 100.00 ( 98.61)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [248][ 0/51]	Time  1.298 ( 1.298)	Data  0.450 ( 0.450)	Loss 1.4428e-01 (1.4428e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [248][10/51]	Time  2.956 ( 2.282)	Data  1.827 ( 1.350)	Loss 7.1262e-02 (5.9000e-02)	Acc@1  98.44 ( 98.01)	Acc@5  98.44 ( 99.86)
Epoch: [248][20/51]	Time  3.012 ( 2.160)	Data  2.116 ( 1.255)	Loss 9.6009e-02 (6.0392e-02)	Acc@1  98.44 ( 98.07)	Acc@5 100.00 ( 99.85)
Epoch: [248][30/51]	Time  1.295 ( 2.191)	Data  0.498 ( 1.295)	Loss 3.2277e-02 (5.7083e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.75)
Epoch: [248][40/51]	Time  3.098 ( 2.082)	Data  2.046 ( 1.227)	Loss 2.6895e-02 (5.2710e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.77)
Epoch: [248][50/51]	Time  0.740 ( 1.897)	Data  0.277 ( 1.100)	Loss 2.0143e-01 (5.4962e-02)	Acc@1  93.55 ( 98.39)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [249][ 0/51]	Time  1.027 ( 1.027)	Data  0.461 ( 0.461)	Loss 3.6553e-03 (3.6553e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [249][10/51]	Time  1.098 ( 1.111)	Data  0.549 ( 0.567)	Loss 7.9394e-03 (4.1399e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.72)
Epoch: [249][20/51]	Time  1.234 ( 1.222)	Data  0.694 ( 0.645)	Loss 6.9749e-02 (5.1533e-02)	Acc@1  98.44 ( 98.66)	Acc@5  98.44 ( 99.70)
Epoch: [249][30/51]	Time  1.015 ( 1.182)	Data  0.466 ( 0.609)	Loss 2.2717e-02 (4.4572e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [249][40/51]	Time  1.302 ( 1.185)	Data  0.485 ( 0.597)	Loss 9.3107e-03 (5.0163e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.77)
Epoch: [249][50/51]	Time  0.845 ( 1.353)	Data  0.227 ( 0.712)	Loss 1.0126e-01 (5.0088e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  1.434 ( 1.434)	Loss 1.4171e-01 (1.4171e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.480 ( 1.847)	Loss 1.6141e-01 (1.6667e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [250][ 0/51]	Time  1.264 ( 1.264)	Data  0.593 ( 0.593)	Loss 6.5881e-03 (6.5881e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [250][10/51]	Time  1.316 ( 1.686)	Data  0.762 ( 0.944)	Loss 2.5104e-02 (4.8786e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.72)
Epoch: [250][20/51]	Time  1.101 ( 1.535)	Data  0.581 ( 0.871)	Loss 6.7018e-02 (5.1493e-02)	Acc@1  98.44 ( 98.81)	Acc@5  98.44 ( 99.63)
Epoch: [250][30/51]	Time  0.980 ( 1.430)	Data  0.433 ( 0.787)	Loss 4.6674e-02 (5.1861e-02)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 ( 99.60)
Epoch: [250][40/51]	Time  1.097 ( 1.360)	Data  0.568 ( 0.740)	Loss 8.3365e-02 (4.8566e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [250][50/51]	Time  1.699 ( 1.376)	Data  0.978 ( 0.730)	Loss 3.3953e-02 (4.9892e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [251][ 0/51]	Time  1.316 ( 1.316)	Data  0.590 ( 0.590)	Loss 1.1423e-01 (1.1423e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [251][10/51]	Time  1.001 ( 1.846)	Data  0.460 ( 1.078)	Loss 3.1281e-02 (6.8894e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.29)
Epoch: [251][20/51]	Time  1.230 ( 2.015)	Data  0.658 ( 1.211)	Loss 5.6493e-03 (6.4858e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.40)
Epoch: [251][30/51]	Time  1.963 ( 1.928)	Data  1.366 ( 1.149)	Loss 3.1006e-02 (5.6214e-02)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.55)
Epoch: [251][40/51]	Time  1.177 ( 1.739)	Data  0.560 ( 1.014)	Loss 5.1911e-02 (5.4720e-02)	Acc@1  98.44 ( 98.59)	Acc@5  98.44 ( 99.54)
Epoch: [251][50/51]	Time  0.660 ( 1.646)	Data  0.191 ( 0.947)	Loss 2.1669e-01 (4.8805e-02)	Acc@1  96.77 ( 98.79)	Acc@5 100.00 ( 99.63)
learning rate is: 1.0000000000000003e-05
Epoch: [252][ 0/51]	Time  1.016 ( 1.016)	Data  0.468 ( 0.468)	Loss 5.4408e-02 (5.4408e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [252][10/51]	Time  2.668 ( 2.249)	Data  1.828 ( 1.347)	Loss 3.7810e-02 (4.7216e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [252][20/51]	Time  1.203 ( 2.151)	Data  0.494 ( 1.252)	Loss 9.3865e-02 (5.5300e-02)	Acc@1  96.88 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [252][30/51]	Time  1.312 ( 2.227)	Data  0.737 ( 1.301)	Loss 1.2241e-01 (6.2394e-02)	Acc@1  95.31 ( 98.44)	Acc@5 100.00 ( 99.75)
Epoch: [252][40/51]	Time  2.056 ( 2.119)	Data  1.256 ( 1.216)	Loss 4.2660e-02 (5.8621e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.81)
Epoch: [252][50/51]	Time  1.159 ( 1.973)	Data  0.478 ( 1.105)	Loss 1.1491e-02 (5.7982e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [253][ 0/51]	Time  1.474 ( 1.474)	Data  0.918 ( 0.918)	Loss 2.5373e-02 (2.5373e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [253][10/51]	Time  1.565 ( 1.355)	Data  0.558 ( 0.673)	Loss 2.4472e-03 (4.0193e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [253][20/51]	Time  1.161 ( 1.875)	Data  0.551 ( 1.084)	Loss 4.4972e-02 (3.7408e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.93)
Epoch: [253][30/51]	Time  2.773 ( 1.918)	Data  1.926 ( 1.102)	Loss 5.7630e-02 (3.6321e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 ( 99.85)
Epoch: [253][40/51]	Time  3.143 ( 2.120)	Data  1.989 ( 1.260)	Loss 2.3273e-01 (4.6450e-02)	Acc@1  95.31 ( 98.82)	Acc@5  98.44 ( 99.81)
Epoch: [253][50/51]	Time  1.842 ( 2.164)	Data  0.896 ( 1.304)	Loss 4.5347e-02 (4.7970e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [254][ 0/51]	Time  1.324 ( 1.324)	Data  0.598 ( 0.598)	Loss 8.1232e-02 (8.1232e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [254][10/51]	Time  2.833 ( 1.576)	Data  1.813 ( 0.867)	Loss 7.6511e-03 (4.3821e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [254][20/51]	Time  1.161 ( 1.691)	Data  0.625 ( 0.984)	Loss 1.2339e-02 (4.3151e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.93)
Epoch: [254][30/51]	Time  0.981 ( 1.509)	Data  0.447 ( 0.842)	Loss 7.7766e-02 (5.4888e-02)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.90)
Epoch: [254][40/51]	Time  3.263 ( 1.610)	Data  1.958 ( 0.910)	Loss 3.6303e-02 (6.1277e-02)	Acc@1  98.44 ( 98.40)	Acc@5 100.00 ( 99.81)
Epoch: [254][50/51]	Time  1.139 ( 1.712)	Data  0.278 ( 0.969)	Loss 4.8960e-02 (5.9844e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.69)
Test: [0/8]	Time  2.653 ( 2.653)	Loss 1.4474e-01 (1.4474e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.533 ( 2.644)	Loss 1.6895e-01 (1.7347e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [255][ 0/51]	Time  1.252 ( 1.252)	Data  0.472 ( 0.472)	Loss 6.8900e-02 (6.8900e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [255][10/51]	Time  1.249 ( 1.369)	Data  0.484 ( 0.659)	Loss 1.1177e-01 (5.2389e-02)	Acc@1  98.44 ( 98.30)	Acc@5  98.44 ( 99.57)
Epoch: [255][20/51]	Time  1.067 ( 1.403)	Data  0.504 ( 0.654)	Loss 5.7537e-03 (5.7885e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.48)
Epoch: [255][30/51]	Time  1.261 ( 1.372)	Data  0.653 ( 0.658)	Loss 8.2764e-02 (5.8688e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.60)
Epoch: [255][40/51]	Time  1.044 ( 1.327)	Data  0.514 ( 0.629)	Loss 5.4056e-02 (5.5877e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 ( 99.70)
Epoch: [255][50/51]	Time  1.813 ( 1.627)	Data  0.872 ( 0.854)	Loss 1.7102e-01 (5.8615e-02)	Acc@1  93.55 ( 98.39)	Acc@5 100.00 ( 99.63)
learning rate is: 1.0000000000000003e-05
Epoch: [256][ 0/51]	Time  1.748 ( 1.748)	Data  1.188 ( 1.188)	Loss 5.2055e-02 (5.2055e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [256][10/51]	Time  3.226 ( 2.905)	Data  2.017 ( 1.790)	Loss 5.8521e-02 (5.4239e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [256][20/51]	Time  3.319 ( 2.475)	Data  2.217 ( 1.414)	Loss 8.5691e-03 (5.7472e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.70)
Epoch: [256][30/51]	Time  3.054 ( 2.669)	Data  1.694 ( 1.574)	Loss 2.3660e-02 (5.1243e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 ( 99.80)
Epoch: [256][40/51]	Time  2.830 ( 2.741)	Data  1.698 ( 1.625)	Loss 4.3252e-03 (4.8680e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.85)
Epoch: [256][50/51]	Time  0.971 ( 2.718)	Data  0.478 ( 1.629)	Loss 1.2729e-01 (5.1793e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [257][ 0/51]	Time  1.291 ( 1.291)	Data  0.525 ( 0.525)	Loss 1.5392e-01 (1.5392e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [257][10/51]	Time  1.335 ( 1.761)	Data  0.679 ( 0.928)	Loss 6.5058e-02 (6.3594e-02)	Acc@1  95.31 ( 97.44)	Acc@5 100.00 ( 99.72)
Epoch: [257][20/51]	Time  2.912 ( 1.841)	Data  1.773 ( 0.996)	Loss 5.0565e-03 (5.4853e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.85)
Epoch: [257][30/51]	Time  2.785 ( 2.212)	Data  1.724 ( 1.261)	Loss 3.4325e-03 (5.5265e-02)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.80)
Epoch: [257][40/51]	Time  1.878 ( 2.064)	Data  1.073 ( 1.139)	Loss 2.9114e-02 (4.8216e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.85)
Epoch: [257][50/51]	Time  2.209 ( 1.976)	Data  1.119 ( 1.067)	Loss 6.3835e-02 (4.5153e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000003e-05
Epoch: [258][ 0/51]	Time  3.363 ( 3.363)	Data  2.197 ( 2.197)	Loss 7.5573e-02 (7.5573e-02)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [258][10/51]	Time  1.481 ( 1.646)	Data  0.780 ( 0.838)	Loss 5.9857e-02 (3.2479e-02)	Acc@1  98.44 ( 99.43)	Acc@5 100.00 ( 99.86)
Epoch: [258][20/51]	Time  1.243 ( 1.523)	Data  0.487 ( 0.738)	Loss 2.7525e-02 (4.1369e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.93)
Epoch: [258][30/51]	Time  1.381 ( 1.474)	Data  0.739 ( 0.715)	Loss 3.0000e-02 (4.1820e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 ( 99.85)
Epoch: [258][40/51]	Time  1.306 ( 1.464)	Data  0.565 ( 0.714)	Loss 5.3037e-02 (4.4494e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.89)
Epoch: [258][50/51]	Time  0.814 ( 1.419)	Data  0.340 ( 0.699)	Loss 2.8516e-01 (5.2262e-02)	Acc@1  87.10 ( 98.55)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000003e-05
Epoch: [259][ 0/51]	Time  1.479 ( 1.479)	Data  0.816 ( 0.816)	Loss 1.8041e-02 (1.8041e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [259][10/51]	Time  2.184 ( 2.809)	Data  1.337 ( 1.786)	Loss 1.7567e-01 (4.5213e-02)	Acc@1  96.88 ( 99.15)	Acc@5  98.44 ( 99.72)
Epoch: [259][20/51]	Time  1.127 ( 2.293)	Data  0.485 ( 1.422)	Loss 4.5726e-03 (3.8695e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.85)
Epoch: [259][30/51]	Time  1.279 ( 2.014)	Data  0.540 ( 1.198)	Loss 2.2918e-02 (3.9078e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 ( 99.85)
Epoch: [259][40/51]	Time  2.665 ( 2.042)	Data  1.712 ( 1.220)	Loss 9.0655e-03 (4.4699e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.81)
Epoch: [259][50/51]	Time  1.865 ( 2.205)	Data  0.833 ( 1.334)	Loss 5.3378e-02 (4.9087e-02)	Acc@1  96.77 ( 98.73)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  2.858 ( 2.858)	Loss 1.4279e-01 (1.4279e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.778 ( 1.709)	Loss 1.6091e-01 (1.6975e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [260][ 0/51]	Time  1.003 ( 1.003)	Data  0.409 ( 0.409)	Loss 5.7261e-02 (5.7261e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [260][10/51]	Time  1.037 ( 1.431)	Data  0.463 ( 0.822)	Loss 1.8494e-02 (3.7597e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [260][20/51]	Time  1.248 ( 1.558)	Data  0.715 ( 0.893)	Loss 2.9036e-02 (4.5558e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.93)
Epoch: [260][30/51]	Time  1.114 ( 1.425)	Data  0.473 ( 0.791)	Loss 1.0473e-01 (5.1926e-02)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.85)
Epoch: [260][40/51]	Time  1.140 ( 1.386)	Data  0.597 ( 0.742)	Loss 2.2584e-02 (4.6583e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [260][50/51]	Time  0.725 ( 1.389)	Data  0.242 ( 0.741)	Loss 1.7592e-01 (4.9904e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [261][ 0/51]	Time  1.550 ( 1.550)	Data  0.533 ( 0.533)	Loss 7.5856e-02 (7.5856e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [261][10/51]	Time  1.358 ( 2.664)	Data  0.721 ( 1.621)	Loss 4.6016e-02 (6.5566e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.86)
Epoch: [261][20/51]	Time  3.226 ( 2.056)	Data  2.282 ( 1.183)	Loss 1.8283e-03 (6.3107e-02)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.78)
Epoch: [261][30/51]	Time  1.100 ( 2.274)	Data  0.522 ( 1.358)	Loss 1.0907e-01 (6.0700e-02)	Acc@1  96.88 ( 98.14)	Acc@5 100.00 ( 99.80)
Epoch: [261][40/51]	Time  1.495 ( 2.138)	Data  0.955 ( 1.276)	Loss 3.0514e-03 (5.1803e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.85)
Epoch: [261][50/51]	Time  1.867 ( 2.201)	Data  0.911 ( 1.324)	Loss 3.2930e-01 (5.2380e-02)	Acc@1  90.32 ( 98.39)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000003e-05
Epoch: [262][ 0/51]	Time  1.375 ( 1.375)	Data  0.862 ( 0.862)	Loss 6.1027e-02 (6.1027e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [262][10/51]	Time  2.845 ( 2.446)	Data  1.802 ( 1.550)	Loss 8.4564e-02 (7.4217e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.43)
Epoch: [262][20/51]	Time  1.407 ( 2.527)	Data  0.488 ( 1.601)	Loss 1.3642e-02 (5.1907e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.55)
Epoch: [262][30/51]	Time  3.049 ( 2.470)	Data  2.148 ( 1.566)	Loss 1.1964e-02 (5.1588e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.60)
Epoch: [262][40/51]	Time  1.018 ( 2.278)	Data  0.469 ( 1.414)	Loss 1.0170e-01 (5.2204e-02)	Acc@1  98.44 ( 98.82)	Acc@5  98.44 ( 99.62)
Epoch: [262][50/51]	Time  2.409 ( 2.164)	Data  1.164 ( 1.316)	Loss 1.9055e-01 (5.0047e-02)	Acc@1  96.77 ( 98.85)	Acc@5 100.00 ( 99.66)
learning rate is: 1.0000000000000003e-05
Epoch: [263][ 0/51]	Time  2.685 ( 2.685)	Data  1.547 ( 1.547)	Loss 7.9850e-03 (7.9850e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [263][10/51]	Time  1.392 ( 2.423)	Data  0.512 ( 1.338)	Loss 4.6471e-02 (5.2208e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.57)
Epoch: [263][20/51]	Time  1.771 ( 1.927)	Data  0.883 ( 1.030)	Loss 1.9270e-02 (4.8605e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.78)
Epoch: [263][30/51]	Time  2.696 ( 1.762)	Data  1.780 ( 0.940)	Loss 5.3554e-02 (4.8632e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.80)
Epoch: [263][40/51]	Time  2.599 ( 1.761)	Data  1.795 ( 0.968)	Loss 1.2844e-02 (4.6460e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.81)
Epoch: [263][50/51]	Time  1.993 ( 1.865)	Data  0.795 ( 1.041)	Loss 1.4133e-01 (5.4264e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [264][ 0/51]	Time  3.019 ( 3.019)	Data  2.081 ( 2.081)	Loss 1.0986e-02 (1.0986e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [264][10/51]	Time  2.992 ( 2.839)	Data  1.926 ( 1.810)	Loss 4.3205e-02 (3.7149e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [264][20/51]	Time  1.325 ( 2.868)	Data  0.578 ( 1.805)	Loss 6.1588e-03 (4.1147e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [264][30/51]	Time  2.875 ( 2.420)	Data  1.716 ( 1.431)	Loss 8.4065e-02 (5.3615e-02)	Acc@1  95.31 ( 98.39)	Acc@5 100.00 ( 99.85)
Epoch: [264][40/51]	Time  0.999 ( 2.206)	Data  0.459 ( 1.259)	Loss 5.4898e-02 (5.4046e-02)	Acc@1  96.88 ( 98.48)	Acc@5 100.00 ( 99.81)
Epoch: [264][50/51]	Time  2.239 ( 2.353)	Data  1.015 ( 1.363)	Loss 5.9885e-02 (4.9992e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  3.169 ( 3.169)	Loss 1.3710e-01 (1.3710e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.027 ( 1.412)	Loss 1.6130e-01 (1.7177e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [265][ 0/51]	Time  1.430 ( 1.430)	Data  0.662 ( 0.662)	Loss 1.1992e-01 (1.1992e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [265][10/51]	Time  3.088 ( 1.729)	Data  1.976 ( 0.860)	Loss 1.8519e-02 (4.8109e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [265][20/51]	Time  2.484 ( 2.010)	Data  1.745 ( 1.117)	Loss 3.5595e-02 (5.5619e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.63)
Epoch: [265][30/51]	Time  1.025 ( 2.054)	Data  0.489 ( 1.179)	Loss 9.9599e-03 (4.9966e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.75)
Epoch: [265][40/51]	Time  2.924 ( 2.102)	Data  2.021 ( 1.228)	Loss 3.0733e-02 (4.9706e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.73)
Epoch: [265][50/51]	Time  0.747 ( 1.978)	Data  0.265 ( 1.154)	Loss 2.1648e-01 (5.0686e-02)	Acc@1  96.77 ( 98.67)	Acc@5  96.77 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [266][ 0/51]	Time  0.993 ( 0.993)	Data  0.461 ( 0.461)	Loss 1.2316e-01 (1.2316e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [266][10/51]	Time  1.382 ( 1.515)	Data  0.490 ( 0.846)	Loss 6.3389e-02 (6.1447e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.43)
Epoch: [266][20/51]	Time  1.073 ( 1.539)	Data  0.514 ( 0.863)	Loss 8.7289e-03 (4.3781e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 ( 99.63)
Epoch: [266][30/51]	Time  1.245 ( 1.447)	Data  0.680 ( 0.814)	Loss 2.4199e-02 (4.5348e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.65)
Epoch: [266][40/51]	Time  1.147 ( 1.353)	Data  0.430 ( 0.738)	Loss 4.2730e-02 (4.3823e-02)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 ( 99.70)
Epoch: [266][50/51]	Time  1.828 ( 1.426)	Data  0.829 ( 0.783)	Loss 1.3108e-01 (4.7608e-02)	Acc@1  96.77 ( 98.79)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [267][ 0/51]	Time  2.983 ( 2.983)	Data  2.002 ( 2.002)	Loss 2.1452e-02 (2.1452e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [267][10/51]	Time  3.000 ( 2.193)	Data  1.903 ( 1.322)	Loss 2.4994e-03 (4.3223e-02)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [267][20/51]	Time  1.940 ( 2.294)	Data  1.037 ( 1.377)	Loss 2.5615e-02 (4.1289e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [267][30/51]	Time  1.616 ( 2.480)	Data  0.999 ( 1.504)	Loss 4.5195e-03 (4.2490e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.80)
Epoch: [267][40/51]	Time  1.220 ( 2.378)	Data  0.593 ( 1.418)	Loss 5.2111e-02 (3.9662e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.85)
Epoch: [267][50/51]	Time  2.220 ( 2.329)	Data  0.953 ( 1.362)	Loss 4.1773e-02 (4.0879e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [268][ 0/51]	Time  3.389 ( 3.389)	Data  2.080 ( 2.080)	Loss 9.7075e-02 (9.7075e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [268][10/51]	Time  1.531 ( 2.891)	Data  0.748 ( 1.690)	Loss 5.5892e-03 (3.5013e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [268][20/51]	Time  1.424 ( 2.282)	Data  0.522 ( 1.212)	Loss 1.6289e-02 (4.7269e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.70)
Epoch: [268][30/51]	Time  2.031 ( 2.079)	Data  1.013 ( 1.062)	Loss 5.6858e-02 (4.8773e-02)	Acc@1  96.88 ( 98.64)	Acc@5 100.00 ( 99.80)
Epoch: [268][40/51]	Time  2.932 ( 1.941)	Data  1.825 ( 0.970)	Loss 4.2620e-02 (5.1593e-02)	Acc@1  98.44 ( 98.63)	Acc@5 100.00 ( 99.85)
Epoch: [268][50/51]	Time  2.307 ( 2.081)	Data  1.066 ( 1.071)	Loss 4.1798e-02 (5.1100e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [269][ 0/51]	Time  2.964 ( 2.964)	Data  1.686 ( 1.686)	Loss 4.0558e-02 (4.0558e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [269][10/51]	Time  1.554 ( 2.952)	Data  0.831 ( 1.786)	Loss 5.3513e-02 (6.0204e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.72)
Epoch: [269][20/51]	Time  1.781 ( 2.315)	Data  0.726 ( 1.278)	Loss 9.6745e-03 (5.6621e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [269][30/51]	Time  1.531 ( 2.303)	Data  0.760 ( 1.279)	Loss 3.2602e-03 (4.9206e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.80)
Epoch: [269][40/51]	Time  1.270 ( 2.064)	Data  0.526 ( 1.119)	Loss 7.1730e-02 (5.0411e-02)	Acc@1  96.88 ( 98.51)	Acc@5 100.00 ( 99.81)
Epoch: [269][50/51]	Time  0.851 ( 2.077)	Data  0.191 ( 1.124)	Loss 9.0305e-02 (4.9665e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  0.853 ( 0.853)	Loss 1.5441e-01 (1.5441e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.390 ( 1.450)	Loss 1.5701e-01 (1.6963e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [270][ 0/51]	Time  2.760 ( 2.760)	Data  1.517 ( 1.517)	Loss 2.8143e-02 (2.8143e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [270][10/51]	Time  1.435 ( 2.895)	Data  0.813 ( 1.693)	Loss 9.1470e-03 (6.1410e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.57)
Epoch: [270][20/51]	Time  3.440 ( 2.726)	Data  1.997 ( 1.581)	Loss 5.1636e-02 (4.7388e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.78)
Epoch: [270][30/51]	Time  2.645 ( 2.782)	Data  1.510 ( 1.625)	Loss 1.0173e-02 (5.0109e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.75)
Epoch: [270][40/51]	Time  1.179 ( 2.808)	Data  0.424 ( 1.652)	Loss 1.6241e-03 (5.2618e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 ( 99.73)
Epoch: [270][50/51]	Time  0.984 ( 2.536)	Data  0.521 ( 1.450)	Loss 2.8891e-01 (5.6987e-02)	Acc@1  93.55 ( 98.33)	Acc@5 100.00 ( 99.69)
learning rate is: 1.0000000000000003e-05
Epoch: [271][ 0/51]	Time  1.096 ( 1.096)	Data  0.536 ( 0.536)	Loss 2.0578e-02 (2.0578e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [271][10/51]	Time  1.153 ( 1.203)	Data  0.547 ( 0.583)	Loss 6.0324e-02 (6.2697e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [271][20/51]	Time  1.323 ( 1.265)	Data  0.631 ( 0.597)	Loss 8.1176e-02 (6.2542e-02)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.70)
Epoch: [271][30/51]	Time  2.914 ( 1.329)	Data  2.004 ( 0.644)	Loss 9.2195e-02 (5.5588e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 99.75)
Epoch: [271][40/51]	Time  2.861 ( 1.603)	Data  1.898 ( 0.857)	Loss 3.7311e-02 (5.1059e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.77)
Epoch: [271][50/51]	Time  1.620 ( 1.557)	Data  0.774 ( 0.820)	Loss 1.0352e-01 (5.3442e-02)	Acc@1  96.77 ( 98.45)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [272][ 0/51]	Time  2.598 ( 2.598)	Data  1.713 ( 1.713)	Loss 9.2864e-03 (9.2864e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [272][10/51]	Time  0.962 ( 2.452)	Data  0.411 ( 1.518)	Loss 1.8177e-02 (2.2616e-02)	Acc@1 100.00 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [272][20/51]	Time  3.026 ( 2.621)	Data  2.040 ( 1.636)	Loss 9.7091e-03 (2.5863e-02)	Acc@1 100.00 ( 99.40)	Acc@5 100.00 (100.00)
Epoch: [272][30/51]	Time  3.482 ( 2.678)	Data  2.360 ( 1.681)	Loss 4.6231e-02 (2.7702e-02)	Acc@1  98.44 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [272][40/51]	Time  1.187 ( 2.421)	Data  0.664 ( 1.493)	Loss 1.4606e-02 (2.6917e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [272][50/51]	Time  1.899 ( 2.251)	Data  1.263 ( 1.375)	Loss 5.9946e-02 (2.7777e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 ( 99.97)
learning rate is: 1.0000000000000003e-05
Epoch: [273][ 0/51]	Time  1.121 ( 1.121)	Data  0.575 ( 0.575)	Loss 3.8557e-02 (3.8557e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [273][10/51]	Time  2.031 ( 1.337)	Data  1.367 ( 0.709)	Loss 2.6578e-02 (7.3803e-02)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.72)
Epoch: [273][20/51]	Time  1.400 ( 1.284)	Data  0.878 ( 0.661)	Loss 3.2834e-02 (5.7339e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.78)
Epoch: [273][30/51]	Time  1.068 ( 1.294)	Data  0.521 ( 0.655)	Loss 1.4490e-01 (5.3146e-02)	Acc@1  93.75 ( 98.34)	Acc@5 100.00 ( 99.80)
Epoch: [273][40/51]	Time  3.583 ( 1.435)	Data  2.402 ( 0.765)	Loss 3.0748e-03 (4.9164e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.81)
Epoch: [273][50/51]	Time  1.891 ( 1.711)	Data  1.012 ( 0.957)	Loss 2.0984e-01 (4.9256e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [274][ 0/51]	Time  3.335 ( 3.335)	Data  2.264 ( 2.264)	Loss 1.4293e-02 (1.4293e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [274][10/51]	Time  1.197 ( 2.182)	Data  0.504 ( 1.255)	Loss 7.3654e-03 (2.6974e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [274][20/51]	Time  1.621 ( 1.807)	Data  0.767 ( 1.018)	Loss 4.1951e-03 (2.8785e-02)	Acc@1 100.00 ( 99.33)	Acc@5 100.00 ( 99.85)
Epoch: [274][30/51]	Time  2.277 ( 1.805)	Data  1.726 ( 1.025)	Loss 1.6831e-02 (3.6817e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.85)
Epoch: [274][40/51]	Time  2.916 ( 1.797)	Data  2.000 ( 1.030)	Loss 8.3448e-03 (3.4842e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 ( 99.85)
Epoch: [274][50/51]	Time  1.887 ( 2.008)	Data  0.823 ( 1.173)	Loss 5.8705e-02 (3.8957e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  3.027 ( 3.027)	Loss 1.4400e-01 (1.4400e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.724 ( 1.534)	Loss 1.7186e-01 (1.7203e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [275][ 0/51]	Time  1.671 ( 1.671)	Data  0.874 ( 0.874)	Loss 3.7093e-02 (3.7093e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [275][10/51]	Time  1.104 ( 2.628)	Data  0.559 ( 1.592)	Loss 1.1646e-01 (4.7674e-02)	Acc@1  96.88 ( 98.86)	Acc@5  98.44 ( 99.72)
Epoch: [275][20/51]	Time  2.993 ( 2.865)	Data  1.916 ( 1.826)	Loss 2.2229e-02 (4.6363e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [275][30/51]	Time  1.041 ( 2.546)	Data  0.452 ( 1.598)	Loss 6.9625e-02 (4.7285e-02)	Acc@1  95.31 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [275][40/51]	Time  1.306 ( 2.220)	Data  0.770 ( 1.370)	Loss 2.9989e-02 (4.4511e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.81)
Epoch: [275][50/51]	Time  1.778 ( 2.061)	Data  0.765 ( 1.245)	Loss 3.5600e-01 (4.5318e-02)	Acc@1  93.55 ( 98.89)	Acc@5  96.77 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [276][ 0/51]	Time  3.034 ( 3.034)	Data  2.153 ( 2.153)	Loss 6.8560e-02 (6.8560e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [276][10/51]	Time  1.341 ( 2.723)	Data  0.601 ( 1.758)	Loss 6.8432e-02 (6.5335e-02)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [276][20/51]	Time  2.933 ( 2.694)	Data  1.677 ( 1.677)	Loss 1.6208e-01 (7.1351e-02)	Acc@1  95.31 ( 97.99)	Acc@5 100.00 ( 99.55)
Epoch: [276][30/51]	Time  1.408 ( 2.430)	Data  0.663 ( 1.476)	Loss 3.3360e-02 (5.8004e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 ( 99.70)
Epoch: [276][40/51]	Time  1.224 ( 2.192)	Data  0.475 ( 1.270)	Loss 3.7029e-02 (5.5179e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.77)
Epoch: [276][50/51]	Time  0.848 ( 2.109)	Data  0.244 ( 1.196)	Loss 2.0086e-01 (5.2342e-02)	Acc@1  93.55 ( 98.42)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [277][ 0/51]	Time  1.404 ( 1.404)	Data  0.693 ( 0.693)	Loss 1.3127e-01 (1.3127e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [277][10/51]	Time  1.286 ( 1.748)	Data  0.571 ( 0.904)	Loss 3.9842e-03 (4.5715e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [277][20/51]	Time  2.965 ( 2.118)	Data  1.780 ( 1.133)	Loss 4.1994e-03 (3.3077e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.93)
Epoch: [277][30/51]	Time  2.833 ( 2.313)	Data  1.612 ( 1.293)	Loss 2.0136e-02 (3.8015e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.85)
Epoch: [277][40/51]	Time  1.413 ( 2.298)	Data  0.806 ( 1.310)	Loss 3.5980e-02 (4.2173e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.73)
Epoch: [277][50/51]	Time  1.906 ( 2.170)	Data  1.093 ( 1.223)	Loss 1.0478e-01 (4.4142e-02)	Acc@1  96.77 ( 98.89)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [278][ 0/51]	Time  1.847 ( 1.847)	Data  1.100 ( 1.100)	Loss 1.8400e-02 (1.8400e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [278][10/51]	Time  2.944 ( 2.050)	Data  1.875 ( 1.250)	Loss 5.8877e-02 (2.8081e-02)	Acc@1  98.44 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [278][20/51]	Time  2.576 ( 2.435)	Data  1.651 ( 1.547)	Loss 3.7666e-02 (4.1623e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [278][30/51]	Time  3.499 ( 2.327)	Data  2.448 ( 1.459)	Loss 9.6425e-03 (4.3080e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.85)
Epoch: [278][40/51]	Time  2.861 ( 2.341)	Data  1.691 ( 1.464)	Loss 4.8469e-02 (4.6202e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.89)
Epoch: [278][50/51]	Time  1.636 ( 2.318)	Data  0.837 ( 1.456)	Loss 6.5387e-02 (4.5458e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.91)
learning rate is: 1.0000000000000003e-05
Epoch: [279][ 0/51]	Time  2.812 ( 2.812)	Data  1.753 ( 1.753)	Loss 8.2641e-03 (8.2641e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [279][10/51]	Time  1.263 ( 1.465)	Data  0.648 ( 0.798)	Loss 9.6849e-02 (4.4892e-02)	Acc@1  95.31 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [279][20/51]	Time  2.685 ( 1.958)	Data  1.768 ( 1.157)	Loss 1.8282e-01 (6.5798e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.70)
Epoch: [279][30/51]	Time  1.328 ( 2.081)	Data  0.445 ( 1.252)	Loss 5.6370e-02 (5.7375e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.80)
Epoch: [279][40/51]	Time  3.221 ( 2.296)	Data  1.872 ( 1.391)	Loss 3.7082e-03 (5.1242e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.81)
Epoch: [279][50/51]	Time  2.235 ( 2.428)	Data  1.138 ( 1.475)	Loss 3.0324e-02 (4.9534e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  3.184 ( 3.184)	Loss 1.4769e-01 (1.4769e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.317 ( 2.517)	Loss 1.6324e-01 (1.7414e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [280][ 0/51]	Time  1.227 ( 1.227)	Data  0.436 ( 0.436)	Loss 3.3392e-02 (3.3392e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [280][10/51]	Time  1.293 ( 1.878)	Data  0.743 ( 0.997)	Loss 2.9653e-02 (5.6138e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [280][20/51]	Time  3.226 ( 2.124)	Data  2.100 ( 1.200)	Loss 2.7271e-02 (6.1683e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.63)
Epoch: [280][30/51]	Time  3.003 ( 2.371)	Data  1.686 ( 1.354)	Loss 5.3524e-03 (5.4359e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [280][40/51]	Time  1.589 ( 2.484)	Data  0.792 ( 1.447)	Loss 2.5941e-02 (5.4971e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [280][50/51]	Time  1.381 ( 2.505)	Data  0.398 ( 1.454)	Loss 2.6065e-01 (5.4278e-02)	Acc@1  93.55 ( 98.48)	Acc@5  93.55 ( 99.69)
learning rate is: 1.0000000000000003e-05
Epoch: [281][ 0/51]	Time  1.536 ( 1.536)	Data  0.505 ( 0.505)	Loss 5.1947e-03 (5.1947e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [281][10/51]	Time  1.546 ( 1.734)	Data  0.662 ( 0.841)	Loss 2.7686e-02 (5.5078e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [281][20/51]	Time  3.007 ( 2.101)	Data  1.896 ( 1.136)	Loss 8.0597e-02 (5.2751e-02)	Acc@1  98.44 ( 98.36)	Acc@5  98.44 ( 99.85)
Epoch: [281][30/51]	Time  1.487 ( 1.930)	Data  0.747 ( 0.999)	Loss 5.8809e-03 (5.2394e-02)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.85)
Epoch: [281][40/51]	Time  1.083 ( 1.772)	Data  0.464 ( 0.912)	Loss 2.3219e-02 (5.3913e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.77)
Epoch: [281][50/51]	Time  1.063 ( 1.662)	Data  0.601 ( 0.857)	Loss 3.6760e-01 (5.5020e-02)	Acc@1  90.32 ( 98.45)	Acc@5  93.55 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [282][ 0/51]	Time  1.370 ( 1.370)	Data  0.823 ( 0.823)	Loss 2.6644e-02 (2.6644e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [282][10/51]	Time  1.172 ( 1.545)	Data  0.649 ( 0.864)	Loss 6.2232e-03 (4.5735e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [282][20/51]	Time  1.054 ( 1.359)	Data  0.526 ( 0.726)	Loss 5.5274e-02 (5.0859e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [282][30/51]	Time  1.149 ( 1.316)	Data  0.580 ( 0.705)	Loss 7.3208e-02 (5.0857e-02)	Acc@1  98.44 ( 98.84)	Acc@5  98.44 ( 99.75)
Epoch: [282][40/51]	Time  3.013 ( 1.307)	Data  1.826 ( 0.685)	Loss 1.2368e-02 (5.0497e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.77)
Epoch: [282][50/51]	Time  1.927 ( 1.605)	Data  0.877 ( 0.898)	Loss 4.0566e-02 (5.4659e-02)	Acc@1 100.00 ( 98.64)	Acc@5 100.00 ( 99.69)
learning rate is: 1.0000000000000003e-05
Epoch: [283][ 0/51]	Time  2.810 ( 2.810)	Data  1.855 ( 1.855)	Loss 3.8352e-02 (3.8352e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [283][10/51]	Time  1.074 ( 1.767)	Data  0.537 ( 0.989)	Loss 4.5340e-02 (5.6441e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.72)
Epoch: [283][20/51]	Time  1.266 ( 1.958)	Data  0.641 ( 1.126)	Loss 2.6929e-02 (5.8261e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [283][30/51]	Time  1.103 ( 1.904)	Data  0.558 ( 1.106)	Loss 1.3609e-02 (5.4848e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.70)
Epoch: [283][40/51]	Time  3.312 ( 2.041)	Data  2.114 ( 1.211)	Loss 8.3149e-02 (5.4862e-02)	Acc@1  95.31 ( 98.51)	Acc@5 100.00 ( 99.73)
Epoch: [283][50/51]	Time  1.886 ( 2.064)	Data  0.881 ( 1.228)	Loss 7.5043e-02 (5.2391e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [284][ 0/51]	Time  2.713 ( 2.713)	Data  1.787 ( 1.787)	Loss 7.0313e-02 (7.0313e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [284][10/51]	Time  1.087 ( 1.449)	Data  0.522 ( 0.792)	Loss 1.6850e-01 (7.3149e-02)	Acc@1  95.31 ( 97.73)	Acc@5  98.44 ( 99.57)
Epoch: [284][20/51]	Time  2.852 ( 1.856)	Data  1.765 ( 1.089)	Loss 2.2916e-02 (5.3045e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.70)
Epoch: [284][30/51]	Time  2.812 ( 2.200)	Data  1.838 ( 1.345)	Loss 3.8477e-03 (5.8469e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.70)
Epoch: [284][40/51]	Time  1.210 ( 2.105)	Data  0.510 ( 1.275)	Loss 4.3409e-02 (5.7579e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.73)
Epoch: [284][50/51]	Time  1.071 ( 2.124)	Data  0.362 ( 1.298)	Loss 1.0494e-01 (5.0646e-02)	Acc@1  96.77 ( 98.67)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  2.977 ( 2.977)	Loss 1.3344e-01 (1.3344e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.277 ( 2.587)	Loss 1.6020e-01 (1.7009e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [285][ 0/51]	Time  1.940 ( 1.940)	Data  0.999 ( 0.999)	Loss 1.2829e-01 (1.2829e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [285][10/51]	Time  2.652 ( 2.846)	Data  1.732 ( 1.840)	Loss 1.6738e-02 (3.8411e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.72)
Epoch: [285][20/51]	Time  1.510 ( 2.730)	Data  0.884 ( 1.742)	Loss 6.8554e-02 (4.2849e-02)	Acc@1  98.44 ( 98.81)	Acc@5  98.44 ( 99.78)
Epoch: [285][30/51]	Time  1.831 ( 2.770)	Data  1.271 ( 1.777)	Loss 1.0414e-01 (4.5559e-02)	Acc@1  95.31 ( 98.54)	Acc@5  98.44 ( 99.75)
Epoch: [285][40/51]	Time  1.334 ( 2.510)	Data  0.574 ( 1.567)	Loss 1.2803e-01 (4.8582e-02)	Acc@1  95.31 ( 98.51)	Acc@5  98.44 ( 99.70)
Epoch: [285][50/51]	Time  1.908 ( 2.305)	Data  0.866 ( 1.409)	Loss 5.9528e-02 (4.4743e-02)	Acc@1  96.77 ( 98.64)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [286][ 0/51]	Time  1.162 ( 1.162)	Data  0.625 ( 0.625)	Loss 1.1561e-01 (1.1561e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [286][10/51]	Time  3.516 ( 2.005)	Data  2.150 ( 1.215)	Loss 4.6274e-02 (5.4813e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.72)
Epoch: [286][20/51]	Time  2.553 ( 2.411)	Data  1.593 ( 1.502)	Loss 6.3249e-02 (6.1769e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.63)
Epoch: [286][30/51]	Time  2.283 ( 2.082)	Data  1.596 ( 1.260)	Loss 8.4515e-02 (6.4387e-02)	Acc@1  98.44 ( 98.39)	Acc@5 100.00 ( 99.70)
Epoch: [286][40/51]	Time  1.645 ( 1.889)	Data  0.582 ( 1.107)	Loss 8.9465e-02 (5.7109e-02)	Acc@1  96.88 ( 98.55)	Acc@5 100.00 ( 99.77)
Epoch: [286][50/51]	Time  0.724 ( 1.842)	Data  0.218 ( 1.083)	Loss 1.4507e-01 (5.4109e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [287][ 0/51]	Time  1.983 ( 1.983)	Data  1.123 ( 1.123)	Loss 1.4375e-01 (1.4375e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [287][10/51]	Time  1.089 ( 1.182)	Data  0.530 ( 0.593)	Loss 6.4058e-02 (6.2330e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.43)
Epoch: [287][20/51]	Time  1.163 ( 1.262)	Data  0.568 ( 0.657)	Loss 9.4372e-02 (5.2925e-02)	Acc@1  95.31 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [287][30/51]	Time  1.514 ( 1.248)	Data  0.717 ( 0.652)	Loss 4.3276e-03 (4.9538e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [287][40/51]	Time  2.625 ( 1.431)	Data  1.601 ( 0.785)	Loss 7.3954e-03 (4.7788e-02)	Acc@1 100.00 ( 98.63)	Acc@5 100.00 ( 99.81)
Epoch: [287][50/51]	Time  0.993 ( 1.547)	Data  0.277 ( 0.867)	Loss 1.8484e-01 (4.9350e-02)	Acc@1  96.77 ( 98.64)	Acc@5  96.77 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [288][ 0/51]	Time  2.824 ( 2.824)	Data  1.750 ( 1.750)	Loss 1.1654e-01 (1.1654e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [288][10/51]	Time  1.402 ( 2.889)	Data  0.601 ( 1.777)	Loss 2.7427e-02 (5.7042e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.72)
Epoch: [288][20/51]	Time  3.101 ( 2.524)	Data  1.831 ( 1.511)	Loss 4.8915e-03 (4.3891e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 ( 99.78)
Epoch: [288][30/51]	Time  2.907 ( 2.491)	Data  1.775 ( 1.499)	Loss 3.3123e-02 (4.2044e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 ( 99.80)
Epoch: [288][40/51]	Time  2.778 ( 2.635)	Data  1.697 ( 1.603)	Loss 1.0493e-01 (4.4193e-02)	Acc@1  96.88 ( 99.01)	Acc@5 100.00 ( 99.81)
Epoch: [288][50/51]	Time  1.221 ( 2.565)	Data  0.216 ( 1.546)	Loss 1.0696e-01 (4.4009e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [289][ 0/51]	Time  1.513 ( 1.513)	Data  0.689 ( 0.689)	Loss 2.7861e-02 (2.7861e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [289][10/51]	Time  1.959 ( 1.750)	Data  0.913 ( 0.871)	Loss 6.2343e-02 (5.4722e-02)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.72)
Epoch: [289][20/51]	Time  3.278 ( 1.612)	Data  2.057 ( 0.820)	Loss 5.8883e-02 (4.3938e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [289][30/51]	Time  1.443 ( 1.794)	Data  0.493 ( 0.938)	Loss 3.4649e-02 (5.0660e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.80)
Epoch: [289][40/51]	Time  1.201 ( 1.695)	Data  0.425 ( 0.851)	Loss 2.8828e-02 (5.3686e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.81)
Epoch: [289][50/51]	Time  0.831 ( 1.589)	Data  0.366 ( 0.790)	Loss 1.1133e-01 (5.3024e-02)	Acc@1  96.77 ( 98.48)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  1.146 ( 1.146)	Loss 1.3862e-01 (1.3862e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.789 ( 0.869)	Loss 1.6559e-01 (1.6635e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [290][ 0/51]	Time  3.126 ( 3.126)	Data  2.054 ( 2.054)	Loss 2.3503e-02 (2.3503e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [290][10/51]	Time  2.870 ( 2.050)	Data  1.749 ( 1.176)	Loss 1.7381e-02 (3.9456e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [290][20/51]	Time  3.060 ( 2.022)	Data  1.966 ( 1.128)	Loss 2.4815e-03 (3.6225e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.93)
Epoch: [290][30/51]	Time  3.115 ( 2.343)	Data  1.779 ( 1.332)	Loss 1.3069e-01 (3.8942e-02)	Acc@1  96.88 ( 99.09)	Acc@5  98.44 ( 99.85)
Epoch: [290][40/51]	Time  1.384 ( 2.358)	Data  0.614 ( 1.345)	Loss 2.6528e-03 (3.9066e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 ( 99.85)
Epoch: [290][50/51]	Time  1.382 ( 2.298)	Data  0.418 ( 1.282)	Loss 2.5983e-01 (4.1850e-02)	Acc@1  93.55 ( 98.95)	Acc@5  96.77 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [291][ 0/51]	Time  3.109 ( 3.109)	Data  1.964 ( 1.964)	Loss 1.1840e-01 (1.1840e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [291][10/51]	Time  1.208 ( 1.627)	Data  0.651 ( 0.943)	Loss 2.6819e-02 (5.0467e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [291][20/51]	Time  2.161 ( 1.649)	Data  1.267 ( 0.950)	Loss 1.9438e-02 (5.1096e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.70)
Epoch: [291][30/51]	Time  3.155 ( 1.753)	Data  1.917 ( 1.003)	Loss 2.3599e-02 (4.9842e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.75)
Epoch: [291][40/51]	Time  3.027 ( 1.885)	Data  1.779 ( 1.051)	Loss 8.8474e-02 (4.9660e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.77)
Epoch: [291][50/51]	Time  2.400 ( 2.023)	Data  1.022 ( 1.140)	Loss 9.9001e-02 (4.6934e-02)	Acc@1  96.77 ( 98.82)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [292][ 0/51]	Time  3.222 ( 3.222)	Data  1.887 ( 1.887)	Loss 6.8816e-03 (6.8816e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [292][10/51]	Time  3.216 ( 3.311)	Data  1.850 ( 2.047)	Loss 9.2358e-03 (4.0996e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [292][20/51]	Time  1.398 ( 2.657)	Data  0.497 ( 1.580)	Loss 1.2620e-02 (5.3824e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.78)
Epoch: [292][30/51]	Time  3.099 ( 2.562)	Data  1.961 ( 1.498)	Loss 8.4561e-02 (5.5543e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.80)
Epoch: [292][40/51]	Time  3.123 ( 2.604)	Data  2.144 ( 1.546)	Loss 7.4581e-02 (5.1699e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.81)
Epoch: [292][50/51]	Time  2.136 ( 2.674)	Data  0.935 ( 1.593)	Loss 1.1237e-01 (4.8856e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [293][ 0/51]	Time  3.222 ( 3.222)	Data  2.214 ( 2.214)	Loss 1.9330e-02 (1.9330e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [293][10/51]	Time  2.839 ( 1.989)	Data  1.825 ( 1.090)	Loss 5.9542e-02 (4.7202e-02)	Acc@1  96.88 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [293][20/51]	Time  2.306 ( 2.482)	Data  1.473 ( 1.419)	Loss 1.2073e-01 (4.0417e-02)	Acc@1  96.88 ( 98.88)	Acc@5 100.00 ( 99.93)
Epoch: [293][30/51]	Time  3.193 ( 2.348)	Data  1.857 ( 1.304)	Loss 1.5525e-01 (4.5664e-02)	Acc@1  96.88 ( 98.79)	Acc@5 100.00 ( 99.95)
Epoch: [293][40/51]	Time  1.465 ( 2.216)	Data  0.707 ( 1.229)	Loss 5.8134e-02 (4.4547e-02)	Acc@1  98.44 ( 98.78)	Acc@5  98.44 ( 99.92)
Epoch: [293][50/51]	Time  1.009 ( 2.058)	Data  0.199 ( 1.107)	Loss 5.2685e-02 (4.3315e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.94)
learning rate is: 1.0000000000000003e-05
Epoch: [294][ 0/51]	Time  1.319 ( 1.319)	Data  0.696 ( 0.696)	Loss 1.7669e-02 (1.7669e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [294][10/51]	Time  2.757 ( 2.116)	Data  1.874 ( 1.229)	Loss 4.9116e-03 (3.8991e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [294][20/51]	Time  2.889 ( 2.534)	Data  1.709 ( 1.529)	Loss 1.1506e-01 (5.4018e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [294][30/51]	Time  2.468 ( 2.675)	Data  1.378 ( 1.659)	Loss 4.1652e-02 (4.5937e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.95)
Epoch: [294][40/51]	Time  3.010 ( 2.664)	Data  1.797 ( 1.653)	Loss 6.4515e-02 (3.9851e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.96)
Epoch: [294][50/51]	Time  1.976 ( 2.644)	Data  0.873 ( 1.640)	Loss 2.0799e-01 (3.9022e-02)	Acc@1  93.55 ( 98.79)	Acc@5 100.00 ( 99.97)
Test: [0/8]	Time  2.904 ( 2.904)	Loss 1.3690e-01 (1.3690e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  1.149 ( 1.727)	Loss 1.6306e-01 (1.7004e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [295][ 0/51]	Time  1.265 ( 1.265)	Data  0.510 ( 0.510)	Loss 7.7287e-02 (7.7287e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [295][10/51]	Time  1.102 ( 2.272)	Data  0.446 ( 1.341)	Loss 2.3367e-02 (4.8876e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [295][20/51]	Time  1.519 ( 2.196)	Data  0.862 ( 1.300)	Loss 3.0318e-02 (4.9866e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.93)
Epoch: [295][30/51]	Time  3.038 ( 2.318)	Data  1.823 ( 1.364)	Loss 1.0485e-01 (5.0474e-02)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.90)
Epoch: [295][40/51]	Time  3.251 ( 2.505)	Data  1.967 ( 1.490)	Loss 4.1230e-02 (5.4795e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.85)
Epoch: [295][50/51]	Time  1.002 ( 2.312)	Data  0.357 ( 1.339)	Loss 1.2297e-01 (5.4953e-02)	Acc@1  96.77 ( 98.58)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [296][ 0/51]	Time  1.071 ( 1.071)	Data  0.463 ( 0.463)	Loss 3.5869e-03 (3.5869e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [296][10/51]	Time  1.580 ( 1.834)	Data  0.832 ( 0.995)	Loss 1.8170e-02 (4.8942e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [296][20/51]	Time  3.201 ( 1.939)	Data  1.903 ( 1.092)	Loss 2.7235e-02 (3.8287e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.93)
Epoch: [296][30/51]	Time  2.934 ( 2.142)	Data  1.909 ( 1.235)	Loss 1.5288e-01 (4.5976e-02)	Acc@1  96.88 ( 98.74)	Acc@5  98.44 ( 99.80)
Epoch: [296][40/51]	Time  1.444 ( 2.028)	Data  0.761 ( 1.150)	Loss 7.2670e-02 (4.3623e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.81)
Epoch: [296][50/51]	Time  1.006 ( 1.879)	Data  0.380 ( 1.053)	Loss 3.5966e-02 (4.5400e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [297][ 0/51]	Time  0.961 ( 0.961)	Data  0.425 ( 0.425)	Loss 1.9780e-01 (1.9780e-01)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [297][10/51]	Time  2.610 ( 2.067)	Data  1.643 ( 1.268)	Loss 2.5330e-02 (6.0343e-02)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [297][20/51]	Time  1.002 ( 2.258)	Data  0.434 ( 1.392)	Loss 1.7470e-02 (4.9909e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.78)
Epoch: [297][30/51]	Time  1.039 ( 1.970)	Data  0.508 ( 1.169)	Loss 3.7583e-02 (5.9364e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.65)
Epoch: [297][40/51]	Time  3.082 ( 1.935)	Data  1.936 ( 1.120)	Loss 2.0802e-03 (5.1844e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.70)
Epoch: [297][50/51]	Time  0.996 ( 1.967)	Data  0.382 ( 1.140)	Loss 3.4720e-02 (4.9538e-02)	Acc@1 100.00 ( 98.61)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [298][ 0/51]	Time  1.242 ( 1.242)	Data  0.562 ( 0.562)	Loss 8.9337e-03 (8.9337e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [298][10/51]	Time  2.921 ( 1.968)	Data  1.935 ( 1.150)	Loss 1.8732e-02 (4.9303e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [298][20/51]	Time  2.972 ( 2.355)	Data  1.873 ( 1.446)	Loss 7.8117e-03 (4.4686e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.93)
Epoch: [298][30/51]	Time  3.149 ( 2.418)	Data  1.929 ( 1.508)	Loss 4.3616e-02 (5.4570e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.85)
Epoch: [298][40/51]	Time  2.776 ( 2.555)	Data  1.680 ( 1.570)	Loss 3.1666e-02 (5.8120e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.81)
Epoch: [298][50/51]	Time  2.331 ( 2.526)	Data  1.165 ( 1.521)	Loss 1.6143e-01 (5.5461e-02)	Acc@1  96.77 ( 98.30)	Acc@5  96.77 ( 99.78)
learning rate is: 1.0000000000000003e-05
Epoch: [299][ 0/51]	Time  3.102 ( 3.102)	Data  1.912 ( 1.912)	Loss 4.7442e-02 (4.7442e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [299][10/51]	Time  3.321 ( 2.161)	Data  2.057 ( 1.226)	Loss 1.3015e-02 (2.5355e-02)	Acc@1 100.00 ( 99.57)	Acc@5 100.00 (100.00)
Epoch: [299][20/51]	Time  1.450 ( 1.868)	Data  0.507 ( 1.013)	Loss 7.6928e-02 (2.8149e-02)	Acc@1  96.88 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [299][30/51]	Time  1.213 ( 1.701)	Data  0.596 ( 0.913)	Loss 7.7069e-03 (4.2296e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.85)
Epoch: [299][40/51]	Time  2.782 ( 1.967)	Data  1.638 ( 1.089)	Loss 6.9150e-02 (4.5497e-02)	Acc@1  98.44 ( 98.93)	Acc@5  98.44 ( 99.81)
Epoch: [299][50/51]	Time  1.317 ( 2.038)	Data  0.391 ( 1.141)	Loss 1.5669e-02 (4.7288e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  1.023 ( 1.023)	Loss 1.5694e-01 (1.5694e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.655 ( 2.396)	Loss 1.7014e-01 (1.7706e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [300][ 0/51]	Time  1.354 ( 1.354)	Data  0.755 ( 0.755)	Loss 4.7065e-03 (4.7065e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [300][10/51]	Time  1.190 ( 1.612)	Data  0.642 ( 0.930)	Loss 4.7139e-02 (3.5575e-02)	Acc@1  98.44 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [300][20/51]	Time  3.350 ( 1.952)	Data  1.927 ( 1.173)	Loss 7.2951e-02 (4.4470e-02)	Acc@1  96.88 ( 98.88)	Acc@5 100.00 ( 99.78)
Epoch: [300][30/51]	Time  1.137 ( 2.171)	Data  0.485 ( 1.322)	Loss 9.7383e-03 (4.3384e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.80)
Epoch: [300][40/51]	Time  1.551 ( 2.017)	Data  0.681 ( 1.205)	Loss 1.6669e-01 (4.6949e-02)	Acc@1  98.44 ( 98.86)	Acc@5  98.44 ( 99.70)
Epoch: [300][50/51]	Time  1.725 ( 2.142)	Data  0.941 ( 1.287)	Loss 1.1004e-01 (4.7925e-02)	Acc@1  96.77 ( 98.73)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [301][ 0/51]	Time  2.636 ( 2.636)	Data  1.750 ( 1.750)	Loss 8.9084e-03 (8.9084e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [301][10/51]	Time  2.685 ( 3.019)	Data  1.577 ( 1.984)	Loss 4.9801e-02 (3.9801e-02)	Acc@1  98.44 ( 99.29)	Acc@5 100.00 ( 99.72)
Epoch: [301][20/51]	Time  1.280 ( 2.853)	Data  0.512 ( 1.822)	Loss 9.8450e-03 (3.8387e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.70)
Epoch: [301][30/51]	Time  3.729 ( 2.805)	Data  2.681 ( 1.801)	Loss 3.9480e-02 (3.6950e-02)	Acc@1 100.00 ( 99.24)	Acc@5 100.00 ( 99.80)
Epoch: [301][40/51]	Time  0.957 ( 2.534)	Data  0.423 ( 1.593)	Loss 1.1187e-01 (4.4794e-02)	Acc@1  96.88 ( 98.86)	Acc@5  98.44 ( 99.77)
Epoch: [301][50/51]	Time  1.974 ( 2.561)	Data  1.110 ( 1.605)	Loss 7.3853e-03 (4.6581e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [302][ 0/51]	Time  2.725 ( 2.725)	Data  1.636 ( 1.636)	Loss 7.1476e-02 (7.1476e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [302][10/51]	Time  1.377 ( 1.653)	Data  0.622 ( 0.874)	Loss 1.8190e-02 (3.6725e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [302][20/51]	Time  0.946 ( 1.704)	Data  0.399 ( 0.922)	Loss 1.2001e-02 (3.8803e-02)	Acc@1 100.00 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [302][30/51]	Time  3.664 ( 1.991)	Data  2.528 ( 1.146)	Loss 4.0438e-02 (3.9688e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.90)
Epoch: [302][40/51]	Time  1.466 ( 1.921)	Data  0.907 ( 1.111)	Loss 1.8465e-01 (4.6992e-02)	Acc@1  93.75 ( 98.44)	Acc@5  98.44 ( 99.89)
Epoch: [302][50/51]	Time  1.854 ( 1.827)	Data  0.959 ( 1.035)	Loss 1.7908e-01 (4.6061e-02)	Acc@1  96.77 ( 98.51)	Acc@5 100.00 ( 99.91)
learning rate is: 1.0000000000000003e-05
Epoch: [303][ 0/51]	Time  3.036 ( 3.036)	Data  1.931 ( 1.931)	Loss 7.2661e-03 (7.2661e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [303][10/51]	Time  2.575 ( 2.921)	Data  1.690 ( 1.891)	Loss 3.1222e-02 (3.9337e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [303][20/51]	Time  1.587 ( 2.382)	Data  0.791 ( 1.489)	Loss 1.6757e-02 (3.5475e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.85)
Epoch: [303][30/51]	Time  3.075 ( 2.481)	Data  1.960 ( 1.548)	Loss 5.9918e-03 (4.3076e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.90)
Epoch: [303][40/51]	Time  1.229 ( 2.439)	Data  0.688 ( 1.524)	Loss 3.5717e-02 (5.1248e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.77)
Epoch: [303][50/51]	Time  1.775 ( 2.303)	Data  0.910 ( 1.427)	Loss 1.3332e-01 (5.0325e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [304][ 0/51]	Time  1.546 ( 1.546)	Data  1.015 ( 1.015)	Loss 7.0606e-02 (7.0606e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [304][10/51]	Time  2.985 ( 2.529)	Data  2.076 ( 1.674)	Loss 5.7593e-04 (5.6162e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.57)
Epoch: [304][20/51]	Time  3.290 ( 2.479)	Data  2.202 ( 1.602)	Loss 1.9624e-02 (4.2637e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 ( 99.78)
Epoch: [304][30/51]	Time  1.171 ( 2.530)	Data  0.616 ( 1.628)	Loss 2.6409e-02 (4.2590e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 ( 99.80)
Epoch: [304][40/51]	Time  1.250 ( 2.390)	Data  0.521 ( 1.506)	Loss 7.4977e-02 (4.4216e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 ( 99.81)
Epoch: [304][50/51]	Time  1.887 ( 2.433)	Data  1.164 ( 1.518)	Loss 1.0599e-02 (4.5944e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  1.121 ( 1.121)	Loss 1.5019e-01 (1.5019e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.996 ( 1.093)	Loss 1.6760e-01 (1.7284e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [305][ 0/51]	Time  2.835 ( 2.835)	Data  1.959 ( 1.959)	Loss 1.0395e-01 (1.0395e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [305][10/51]	Time  2.890 ( 2.904)	Data  1.812 ( 1.901)	Loss 9.8018e-02 (6.4244e-02)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 ( 99.86)
Epoch: [305][20/51]	Time  1.008 ( 2.627)	Data  0.451 ( 1.698)	Loss 7.6783e-02 (6.1697e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.70)
Epoch: [305][30/51]	Time  3.711 ( 2.651)	Data  2.458 ( 1.710)	Loss 8.3702e-02 (6.1907e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.65)
Epoch: [305][40/51]	Time  2.807 ( 2.690)	Data  1.569 ( 1.711)	Loss 1.5484e-02 (5.8342e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.66)
Epoch: [305][50/51]	Time  1.338 ( 2.669)	Data  0.653 ( 1.673)	Loss 2.8451e-02 (5.7462e-02)	Acc@1 100.00 ( 98.45)	Acc@5 100.00 ( 99.69)
learning rate is: 1.0000000000000003e-05
Epoch: [306][ 0/51]	Time  1.294 ( 1.294)	Data  0.511 ( 0.511)	Loss 3.3037e-02 (3.3037e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [306][10/51]	Time  2.788 ( 2.529)	Data  1.615 ( 1.511)	Loss 1.6771e-01 (5.5884e-02)	Acc@1  96.88 ( 98.58)	Acc@5  98.44 ( 99.72)
Epoch: [306][20/51]	Time  2.148 ( 2.364)	Data  1.449 ( 1.386)	Loss 9.6913e-03 (6.5737e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.48)
Epoch: [306][30/51]	Time  2.811 ( 2.296)	Data  1.710 ( 1.350)	Loss 1.0841e-02 (5.9849e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.55)
Epoch: [306][40/51]	Time  1.051 ( 2.155)	Data  0.464 ( 1.258)	Loss 5.8608e-02 (5.9231e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.54)
Epoch: [306][50/51]	Time  0.717 ( 2.096)	Data  0.246 ( 1.235)	Loss 2.0639e-01 (5.4877e-02)	Acc@1  93.55 ( 98.64)	Acc@5 100.00 ( 99.60)
learning rate is: 1.0000000000000003e-05
Epoch: [307][ 0/51]	Time  1.232 ( 1.232)	Data  0.473 ( 0.473)	Loss 4.7110e-02 (4.7110e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [307][10/51]	Time  2.932 ( 1.761)	Data  2.027 ( 0.987)	Loss 2.1222e-02 (5.6128e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.57)
Epoch: [307][20/51]	Time  1.271 ( 1.823)	Data  0.739 ( 1.058)	Loss 4.1898e-02 (4.3090e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.70)
Epoch: [307][30/51]	Time  1.739 ( 1.764)	Data  1.191 ( 1.008)	Loss 1.0106e-02 (4.5549e-02)	Acc@1 100.00 ( 98.84)	Acc@5 100.00 ( 99.70)
Epoch: [307][40/51]	Time  2.443 ( 1.766)	Data  1.554 ( 1.015)	Loss 1.1868e-02 (4.6506e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 ( 99.70)
Epoch: [307][50/51]	Time  2.320 ( 1.997)	Data  1.090 ( 1.177)	Loss 1.5746e-01 (5.4764e-02)	Acc@1  90.32 ( 98.39)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [308][ 0/51]	Time  3.359 ( 3.359)	Data  1.996 ( 1.996)	Loss 1.0657e-01 (1.0657e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [308][10/51]	Time  3.607 ( 3.111)	Data  2.559 ( 1.938)	Loss 1.3124e-01 (6.7027e-02)	Acc@1  98.44 ( 98.01)	Acc@5  98.44 ( 99.43)
Epoch: [308][20/51]	Time  1.356 ( 2.395)	Data  0.590 ( 1.364)	Loss 6.5362e-02 (6.3471e-02)	Acc@1  96.88 ( 98.07)	Acc@5 100.00 ( 99.55)
Epoch: [308][30/51]	Time  2.888 ( 2.170)	Data  1.856 ( 1.216)	Loss 1.8490e-02 (5.5499e-02)	Acc@1 100.00 ( 98.24)	Acc@5 100.00 ( 99.70)
Epoch: [308][40/51]	Time  2.750 ( 2.135)	Data  1.758 ( 1.203)	Loss 3.3427e-02 (5.5388e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 ( 99.73)
Epoch: [308][50/51]	Time  1.747 ( 2.282)	Data  0.820 ( 1.332)	Loss 1.9948e-01 (5.4620e-02)	Acc@1  90.32 ( 98.36)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [309][ 0/51]	Time  2.718 ( 2.718)	Data  1.720 ( 1.720)	Loss 1.8711e-02 (1.8711e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [309][10/51]	Time  2.595 ( 2.226)	Data  1.567 ( 1.370)	Loss 4.0206e-02 (3.8764e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [309][20/51]	Time  1.026 ( 2.028)	Data  0.482 ( 1.230)	Loss 1.3086e-02 (3.4966e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.93)
Epoch: [309][30/51]	Time  1.443 ( 1.884)	Data  0.533 ( 1.096)	Loss 7.0733e-02 (3.8689e-02)	Acc@1  98.44 ( 98.84)	Acc@5  98.44 ( 99.90)
Epoch: [309][40/51]	Time  1.936 ( 1.918)	Data  1.121 ( 1.126)	Loss 4.6219e-02 (4.1364e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.85)
Epoch: [309][50/51]	Time  0.731 ( 1.857)	Data  0.269 ( 1.087)	Loss 1.6824e-01 (3.9435e-02)	Acc@1  96.77 ( 98.85)	Acc@5  96.77 ( 99.85)
Test: [0/8]	Time  0.875 ( 0.875)	Loss 1.4308e-01 (1.4308e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.829 ( 0.868)	Loss 1.6577e-01 (1.7092e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [310][ 0/51]	Time  1.062 ( 1.062)	Data  0.387 ( 0.387)	Loss 1.5661e-03 (1.5661e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [310][10/51]	Time  1.262 ( 1.528)	Data  0.739 ( 0.879)	Loss 2.2916e-02 (2.5534e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 ( 99.86)
Epoch: [310][20/51]	Time  2.843 ( 1.527)	Data  1.895 ( 0.861)	Loss 4.0764e-02 (3.2270e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.85)
Epoch: [310][30/51]	Time  1.504 ( 1.539)	Data  0.883 ( 0.849)	Loss 7.9629e-02 (3.6897e-02)	Acc@1  96.88 ( 98.89)	Acc@5 100.00 ( 99.85)
Epoch: [310][40/51]	Time  3.142 ( 1.610)	Data  2.080 ( 0.897)	Loss 9.4922e-02 (3.9618e-02)	Acc@1  96.88 ( 98.86)	Acc@5 100.00 ( 99.85)
Epoch: [310][50/51]	Time  0.827 ( 1.552)	Data  0.335 ( 0.856)	Loss 1.7747e-02 (4.1848e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [311][ 0/51]	Time  2.444 ( 2.444)	Data  1.227 ( 1.227)	Loss 5.8367e-03 (5.8367e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [311][10/51]	Time  3.157 ( 2.647)	Data  2.082 ( 1.524)	Loss 3.8021e-02 (6.1146e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.57)
Epoch: [311][20/51]	Time  1.412 ( 2.192)	Data  0.675 ( 1.208)	Loss 1.4649e-02 (5.6297e-02)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.63)
Epoch: [311][30/51]	Time  2.036 ( 2.181)	Data  1.117 ( 1.198)	Loss 2.7601e-02 (5.6947e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 ( 99.65)
Epoch: [311][40/51]	Time  3.317 ( 2.383)	Data  1.904 ( 1.348)	Loss 3.8723e-02 (5.2024e-02)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 ( 99.73)
Epoch: [311][50/51]	Time  1.288 ( 2.449)	Data  0.289 ( 1.395)	Loss 2.7526e-02 (4.8977e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000003e-05
Epoch: [312][ 0/51]	Time  3.247 ( 3.247)	Data  1.948 ( 1.948)	Loss 1.8452e-01 (1.8452e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [312][10/51]	Time  2.335 ( 2.449)	Data  1.265 ( 1.447)	Loss 1.6620e-01 (7.5653e-02)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.57)
Epoch: [312][20/51]	Time  3.135 ( 2.593)	Data  2.090 ( 1.561)	Loss 1.9862e-02 (6.3869e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.63)
Epoch: [312][30/51]	Time  1.287 ( 2.212)	Data  0.521 ( 1.304)	Loss 3.5485e-02 (5.5296e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.75)
Epoch: [312][40/51]	Time  1.174 ( 2.167)	Data  0.616 ( 1.276)	Loss 1.0524e-02 (5.5951e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.70)
Epoch: [312][50/51]	Time  0.825 ( 1.971)	Data  0.369 ( 1.133)	Loss 5.7349e-02 (5.7941e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [313][ 0/51]	Time  1.077 ( 1.077)	Data  0.528 ( 0.528)	Loss 2.6260e-02 (2.6260e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [313][10/51]	Time  1.727 ( 1.394)	Data  0.921 ( 0.773)	Loss 2.9807e-02 (2.3795e-02)	Acc@1 100.00 ( 99.86)	Acc@5 100.00 (100.00)
Epoch: [313][20/51]	Time  1.365 ( 1.471)	Data  0.786 ( 0.832)	Loss 1.3763e-01 (3.7986e-02)	Acc@1  93.75 ( 99.18)	Acc@5  98.44 ( 99.85)
Epoch: [313][30/51]	Time  1.235 ( 1.622)	Data  0.433 ( 0.910)	Loss 6.8281e-03 (4.2057e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.75)
Epoch: [313][40/51]	Time  2.935 ( 1.696)	Data  1.699 ( 0.930)	Loss 8.6184e-02 (4.7503e-02)	Acc@1  96.88 ( 98.78)	Acc@5 100.00 ( 99.77)
Epoch: [313][50/51]	Time  2.215 ( 1.928)	Data  0.888 ( 1.073)	Loss 7.4537e-02 (4.6469e-02)	Acc@1  96.77 ( 98.79)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000003e-05
Epoch: [314][ 0/51]	Time  2.899 ( 2.899)	Data  1.759 ( 1.759)	Loss 3.4240e-02 (3.4240e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [314][10/51]	Time  3.144 ( 3.164)	Data  1.930 ( 1.920)	Loss 1.5317e-01 (4.7485e-02)	Acc@1  93.75 ( 98.72)	Acc@5  98.44 ( 99.86)
Epoch: [314][20/51]	Time  3.317 ( 2.804)	Data  2.205 ( 1.666)	Loss 1.2874e-02 (5.9827e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.63)
Epoch: [314][30/51]	Time  1.229 ( 2.829)	Data  0.465 ( 1.713)	Loss 3.9886e-02 (5.2072e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.70)
Epoch: [314][40/51]	Time  3.242 ( 2.720)	Data  1.861 ( 1.619)	Loss 1.2056e-02 (5.0710e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.77)
Epoch: [314][50/51]	Time  2.627 ( 2.797)	Data  1.265 ( 1.671)	Loss 4.5234e-02 (4.8361e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  3.480 ( 3.480)	Loss 1.4147e-01 (1.4147e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.566 ( 2.833)	Loss 1.6199e-01 (1.6834e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000003e-05
Epoch: [315][ 0/51]	Time  2.823 ( 2.823)	Data  1.966 ( 1.966)	Loss 8.4753e-02 (8.4753e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [315][10/51]	Time  1.563 ( 2.791)	Data  0.719 ( 1.641)	Loss 1.7815e-02 (3.1473e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [315][20/51]	Time  1.621 ( 2.719)	Data  0.501 ( 1.582)	Loss 5.8229e-02 (4.1256e-02)	Acc@1  96.88 ( 99.03)	Acc@5 100.00 ( 99.93)
Epoch: [315][30/51]	Time  1.670 ( 2.594)	Data  0.864 ( 1.500)	Loss 1.5292e-01 (4.4331e-02)	Acc@1  96.88 ( 98.99)	Acc@5 100.00 ( 99.90)
Epoch: [315][40/51]	Time  3.460 ( 2.702)	Data  2.028 ( 1.569)	Loss 1.2508e-02 (4.2546e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 ( 99.89)
Epoch: [315][50/51]	Time  2.095 ( 2.806)	Data  1.046 ( 1.654)	Loss 2.6568e-02 (3.9089e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 ( 99.91)
learning rate is: 1.0000000000000003e-05
Epoch: [316][ 0/51]	Time  3.248 ( 3.248)	Data  2.191 ( 2.191)	Loss 6.4435e-02 (6.4435e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [316][10/51]	Time  3.221 ( 3.216)	Data  1.929 ( 1.964)	Loss 6.0784e-02 (3.9611e-02)	Acc@1  96.88 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [316][20/51]	Time  3.282 ( 3.045)	Data  2.161 ( 1.858)	Loss 7.7931e-02 (4.3988e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [316][30/51]	Time  3.875 ( 3.125)	Data  2.565 ( 1.907)	Loss 1.3124e-01 (4.9834e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.90)
Epoch: [316][40/51]	Time  1.687 ( 3.075)	Data  0.555 ( 1.850)	Loss 1.1287e-01 (5.3750e-02)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.81)
Epoch: [316][50/51]	Time  2.223 ( 2.890)	Data  0.833 ( 1.704)	Loss 2.3386e-01 (4.9931e-02)	Acc@1  93.55 ( 98.61)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000003e-05
Epoch: [317][ 0/51]	Time  3.178 ( 3.178)	Data  1.913 ( 1.913)	Loss 4.2333e-02 (4.2333e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [317][10/51]	Time  3.116 ( 3.061)	Data  1.881 ( 1.869)	Loss 4.3260e-02 (5.2389e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.57)
Epoch: [317][20/51]	Time  3.251 ( 3.004)	Data  1.999 ( 1.778)	Loss 7.3627e-02 (4.9715e-02)	Acc@1  96.88 ( 98.81)	Acc@5 100.00 ( 99.70)
Epoch: [317][30/51]	Time  1.394 ( 2.583)	Data  0.663 ( 1.451)	Loss 4.8860e-03 (4.0379e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.80)
Epoch: [317][40/51]	Time  3.293 ( 2.455)	Data  2.195 ( 1.365)	Loss 6.5640e-03 (3.7609e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 ( 99.85)
Epoch: [317][50/51]	Time  0.969 ( 2.314)	Data  0.310 ( 1.280)	Loss 7.5359e-02 (3.8693e-02)	Acc@1  96.77 ( 98.98)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000003e-05
Epoch: [318][ 0/51]	Time  2.776 ( 2.776)	Data  1.589 ( 1.589)	Loss 6.6727e-03 (6.6727e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [318][10/51]	Time  1.251 ( 2.017)	Data  0.578 ( 1.103)	Loss 2.1357e-02 (2.8743e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [318][20/51]	Time  1.273 ( 1.660)	Data  0.605 ( 0.853)	Loss 9.6746e-02 (3.4853e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 ( 99.93)
Epoch: [318][30/51]	Time  1.052 ( 1.717)	Data  0.396 ( 0.898)	Loss 9.4891e-02 (4.8620e-02)	Acc@1  98.44 ( 98.74)	Acc@5  98.44 ( 99.75)
Epoch: [318][40/51]	Time  3.303 ( 1.926)	Data  1.955 ( 1.055)	Loss 1.4996e-02 (4.7701e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.73)
Epoch: [318][50/51]	Time  2.101 ( 2.120)	Data  0.736 ( 1.172)	Loss 2.1470e-01 (5.3175e-02)	Acc@1  96.77 ( 98.61)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000003e-05
Epoch: [319][ 0/51]	Time  3.380 ( 3.380)	Data  2.122 ( 2.122)	Loss 1.4745e-01 (1.4745e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [319][10/51]	Time  3.027 ( 2.778)	Data  1.694 ( 1.616)	Loss 1.8107e-01 (6.6571e-02)	Acc@1  95.31 ( 98.44)	Acc@5  98.44 ( 99.57)
Epoch: [319][20/51]	Time  1.568 ( 2.553)	Data  0.521 ( 1.455)	Loss 1.1667e-01 (7.0740e-02)	Acc@1  96.88 ( 98.21)	Acc@5 100.00 ( 99.63)
Epoch: [319][30/51]	Time  1.346 ( 2.417)	Data  0.592 ( 1.336)	Loss 4.3046e-02 (6.7726e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.70)
Epoch: [319][40/51]	Time  2.916 ( 2.528)	Data  1.661 ( 1.401)	Loss 9.2195e-02 (5.9810e-02)	Acc@1  98.44 ( 98.36)	Acc@5  98.44 ( 99.73)
Epoch: [319][50/51]	Time  2.189 ( 2.652)	Data  0.924 ( 1.496)	Loss 9.5685e-02 (5.5778e-02)	Acc@1  96.77 ( 98.39)	Acc@5 100.00 ( 99.78)
Test: [0/8]	Time  2.947 ( 2.947)	Loss 1.4494e-01 (1.4494e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.827 ( 2.024)	Loss 1.6365e-01 (1.7290e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000002e-06
Epoch: [320][ 0/51]	Time  2.872 ( 2.872)	Data  1.703 ( 1.703)	Loss 4.3144e-03 (4.3144e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [320][10/51]	Time  3.196 ( 2.978)	Data  1.985 ( 1.810)	Loss 1.3487e-02 (3.4874e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [320][20/51]	Time  2.921 ( 3.071)	Data  1.721 ( 1.852)	Loss 9.3929e-02 (4.5859e-02)	Acc@1  96.88 ( 98.81)	Acc@5 100.00 ( 99.93)
Epoch: [320][30/51]	Time  3.913 ( 3.079)	Data  2.679 ( 1.867)	Loss 2.1146e-02 (4.0527e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.95)
Epoch: [320][40/51]	Time  2.892 ( 3.108)	Data  1.570 ( 1.875)	Loss 3.9434e-02 (3.9133e-02)	Acc@1  98.44 ( 98.97)	Acc@5 100.00 ( 99.92)
Epoch: [320][50/51]	Time  2.284 ( 3.081)	Data  0.925 ( 1.839)	Loss 1.1137e-01 (4.0139e-02)	Acc@1  96.77 ( 98.92)	Acc@5 100.00 ( 99.91)
learning rate is: 1.0000000000000002e-06
Epoch: [321][ 0/51]	Time  3.250 ( 3.250)	Data  1.980 ( 1.980)	Loss 3.8860e-03 (3.8860e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [321][10/51]	Time  2.849 ( 3.079)	Data  1.652 ( 1.852)	Loss 1.3531e-01 (4.3524e-02)	Acc@1  96.88 ( 98.58)	Acc@5  98.44 ( 99.72)
Epoch: [321][20/51]	Time  2.938 ( 3.097)	Data  1.611 ( 1.868)	Loss 4.4901e-02 (4.4325e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.78)
Epoch: [321][30/51]	Time  2.633 ( 3.143)	Data  1.863 ( 1.940)	Loss 1.3907e-01 (4.5080e-02)	Acc@1  98.44 ( 98.74)	Acc@5  98.44 ( 99.75)
Epoch: [321][40/51]	Time  3.164 ( 3.114)	Data  1.845 ( 1.896)	Loss 3.4675e-02 (4.4695e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.81)
Epoch: [321][50/51]	Time  1.932 ( 3.094)	Data  0.744 ( 1.873)	Loss 3.7573e-02 (4.4859e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000002e-06
Epoch: [322][ 0/51]	Time  2.692 ( 2.692)	Data  1.599 ( 1.599)	Loss 3.4680e-02 (3.4680e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [322][10/51]	Time  2.909 ( 2.921)	Data  1.607 ( 1.674)	Loss 4.0651e-02 (6.9294e-02)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 99.57)
Epoch: [322][20/51]	Time  2.787 ( 2.958)	Data  1.528 ( 1.695)	Loss 2.2599e-03 (6.7378e-02)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.63)
Epoch: [322][30/51]	Time  3.435 ( 3.046)	Data  2.088 ( 1.768)	Loss 4.7678e-02 (5.7729e-02)	Acc@1  96.88 ( 98.39)	Acc@5 100.00 ( 99.65)
Epoch: [322][40/51]	Time  2.902 ( 3.032)	Data  1.582 ( 1.757)	Loss 2.2453e-02 (5.8319e-02)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.70)
Epoch: [322][50/51]	Time  1.904 ( 3.032)	Data  0.681 ( 1.749)	Loss 5.1840e-02 (5.5206e-02)	Acc@1  96.77 ( 98.55)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000002e-06
Epoch: [323][ 0/51]	Time  2.957 ( 2.957)	Data  1.716 ( 1.716)	Loss 5.2702e-02 (5.2702e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [323][10/51]	Time  3.048 ( 3.039)	Data  1.773 ( 1.768)	Loss 4.9872e-02 (4.0924e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [323][20/51]	Time  2.958 ( 3.043)	Data  1.670 ( 1.775)	Loss 2.9086e-02 (3.8341e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.78)
Epoch: [323][30/51]	Time  3.222 ( 3.059)	Data  1.928 ( 1.783)	Loss 2.7085e-02 (3.8397e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.80)
Epoch: [323][40/51]	Time  1.220 ( 2.960)	Data  0.435 ( 1.716)	Loss 5.3033e-02 (3.8320e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.81)
Epoch: [323][50/51]	Time  2.174 ( 2.967)	Data  0.879 ( 1.718)	Loss 4.4355e-02 (3.7705e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000002e-06
Epoch: [324][ 0/51]	Time  2.736 ( 2.736)	Data  1.612 ( 1.612)	Loss 1.4180e-01 (1.4180e-01)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [324][10/51]	Time  2.881 ( 3.055)	Data  1.542 ( 1.796)	Loss 6.3506e-02 (7.8762e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.43)
Epoch: [324][20/51]	Time  3.124 ( 3.093)	Data  1.861 ( 1.804)	Loss 3.5149e-02 (6.3576e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.63)
Epoch: [324][30/51]	Time  3.213 ( 2.965)	Data  1.837 ( 1.706)	Loss 1.0793e-01 (6.2045e-02)	Acc@1  95.31 ( 98.29)	Acc@5 100.00 ( 99.75)
Epoch: [324][40/51]	Time  3.167 ( 2.979)	Data  2.007 ( 1.729)	Loss 1.9436e-02 (5.4747e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.81)
Epoch: [324][50/51]	Time  1.949 ( 2.881)	Data  0.820 ( 1.649)	Loss 2.9556e-02 (5.4321e-02)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.75)
Test: [0/8]	Time  2.908 ( 2.908)	Loss 1.5454e-01 (1.5454e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.378 ( 2.615)	Loss 1.7216e-01 (1.7183e-01)	Acc@1  95.31 ( 95.57)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.600 Acc@5 99.600
learning rate is: 1.0000000000000002e-06
Epoch: [325][ 0/51]	Time  3.235 ( 3.235)	Data  1.914 ( 1.914)	Loss 8.3038e-03 (8.3038e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [325][10/51]	Time  3.310 ( 2.946)	Data  2.026 ( 1.731)	Loss 2.4975e-02 (5.1222e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.86)
Epoch: [325][20/51]	Time  3.285 ( 2.967)	Data  1.881 ( 1.738)	Loss 7.5109e-03 (5.1390e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.78)
Epoch: [325][30/51]	Time  3.529 ( 3.017)	Data  2.201 ( 1.769)	Loss 3.0636e-02 (4.9681e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.85)
Epoch: [325][40/51]	Time  3.091 ( 3.008)	Data  1.995 ( 1.761)	Loss 5.0369e-02 (4.7500e-02)	Acc@1  96.88 ( 98.55)	Acc@5 100.00 ( 99.89)
Epoch: [325][50/51]	Time  2.157 ( 2.996)	Data  0.941 ( 1.751)	Loss 4.1426e-02 (4.5757e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.91)
learning rate is: 1.0000000000000002e-06
Epoch: [326][ 0/51]	Time  3.238 ( 3.238)	Data  2.073 ( 2.073)	Loss 3.7217e-03 (3.7217e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [326][10/51]	Time  2.972 ( 3.085)	Data  1.829 ( 1.811)	Loss 3.4133e-02 (3.8163e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.86)
Epoch: [326][20/51]	Time  2.263 ( 2.894)	Data  1.165 ( 1.676)	Loss 3.8763e-03 (3.9038e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.85)
Epoch: [326][30/51]	Time  3.199 ( 2.946)	Data  1.915 ( 1.693)	Loss 2.4879e-02 (3.6767e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.90)
Epoch: [326][40/51]	Time  1.645 ( 2.737)	Data  0.868 ( 1.542)	Loss 5.9543e-02 (3.8773e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 ( 99.85)
Epoch: [326][50/51]	Time  2.181 ( 2.770)	Data  0.846 ( 1.561)	Loss 4.8883e-02 (3.7880e-02)	Acc@1 100.00 ( 98.98)	Acc@5 100.00 ( 99.81)
learning rate is: 1.0000000000000002e-06
Epoch: [327][ 0/51]	Time  3.109 ( 3.109)	Data  1.782 ( 1.782)	Loss 1.7715e-02 (1.7715e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [327][10/51]	Time  2.798 ( 3.083)	Data  1.671 ( 1.830)	Loss 1.9021e-02 (3.2778e-02)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [327][20/51]	Time  2.989 ( 3.080)	Data  1.725 ( 1.800)	Loss 1.6964e-02 (3.8491e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 ( 99.93)
Epoch: [327][30/51]	Time  3.087 ( 3.043)	Data  1.781 ( 1.771)	Loss 2.8987e-02 (4.1006e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 ( 99.85)
Epoch: [327][40/51]	Time  3.052 ( 3.062)	Data  1.700 ( 1.793)	Loss 3.8906e-02 (3.5603e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 ( 99.89)
Epoch: [327][50/51]	Time  2.090 ( 2.976)	Data  0.847 ( 1.719)	Loss 1.9493e-02 (3.5423e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000002e-06
Epoch: [328][ 0/51]	Time  3.005 ( 3.005)	Data  1.745 ( 1.745)	Loss 3.2837e-02 (3.2837e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [328][10/51]	Time  3.111 ( 2.796)	Data  1.856 ( 1.593)	Loss 4.6805e-02 (6.6261e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.15)
Epoch: [328][20/51]	Time  3.449 ( 2.737)	Data  2.040 ( 1.554)	Loss 2.0832e-02 (6.3858e-02)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.40)
Epoch: [328][30/51]	Time  1.725 ( 2.618)	Data  0.820 ( 1.474)	Loss 2.2498e-01 (6.7300e-02)	Acc@1  93.75 ( 98.19)	Acc@5  96.88 ( 99.40)
Epoch: [328][40/51]	Time  3.247 ( 2.755)	Data  1.908 ( 1.574)	Loss 1.1751e-01 (6.6463e-02)	Acc@1  96.88 ( 98.21)	Acc@5 100.00 ( 99.50)
Epoch: [328][50/51]	Time  1.900 ( 2.826)	Data  0.722 ( 1.626)	Loss 3.2166e-01 (6.3196e-02)	Acc@1  90.32 ( 98.24)	Acc@5 100.00 ( 99.60)
learning rate is: 1.0000000000000002e-06
Epoch: [329][ 0/51]	Time  2.923 ( 2.923)	Data  1.628 ( 1.628)	Loss 4.5910e-02 (4.5910e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [329][10/51]	Time  2.951 ( 2.906)	Data  1.695 ( 1.674)	Loss 5.3200e-03 (3.6165e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [329][20/51]	Time  3.097 ( 2.976)	Data  1.960 ( 1.692)	Loss 2.3583e-03 (3.6801e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.85)
Epoch: [329][30/51]	Time  1.489 ( 2.774)	Data  0.687 ( 1.546)	Loss 8.0099e-03 (3.2269e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 ( 99.90)
Epoch: [329][40/51]	Time  3.031 ( 2.849)	Data  1.777 ( 1.603)	Loss 5.1769e-03 (3.8559e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 ( 99.85)
Epoch: [329][50/51]	Time  2.353 ( 2.876)	Data  1.030 ( 1.626)	Loss 7.6198e-03 (4.0898e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.85)
Test: [0/8]	Time  3.085 ( 3.085)	Loss 1.4861e-01 (1.4861e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  2.471 ( 2.736)	Loss 1.5957e-01 (1.6758e-01)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.200 Acc@5 99.600
learning rate is: 1.0000000000000002e-06
Epoch: [330][ 0/51]	Time  2.979 ( 2.979)	Data  1.796 ( 1.796)	Loss 5.2976e-02 (5.2976e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [330][10/51]	Time  3.154 ( 3.117)	Data  2.048 ( 1.853)	Loss 2.9857e-02 (5.2287e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [330][20/51]	Time  2.865 ( 3.043)	Data  1.590 ( 1.819)	Loss 9.7267e-02 (4.4872e-02)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.85)
Epoch: [330][30/51]	Time  2.750 ( 3.011)	Data  1.462 ( 1.769)	Loss 6.3052e-02 (4.2627e-02)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.90)
Epoch: [330][40/51]	Time  2.903 ( 3.020)	Data  1.698 ( 1.771)	Loss 2.5533e-02 (4.4782e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.89)
Epoch: [330][50/51]	Time  2.055 ( 2.960)	Data  0.934 ( 1.725)	Loss 7.7383e-02 (4.6480e-02)	Acc@1  96.77 ( 98.64)	Acc@5 100.00 ( 99.85)
learning rate is: 1.0000000000000002e-06
Epoch: [331][ 0/51]	Time  2.894 ( 2.894)	Data  1.581 ( 1.581)	Loss 1.6726e-01 (1.6726e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [331][10/51]	Time  2.757 ( 2.995)	Data  1.650 ( 1.742)	Loss 8.9265e-03 (7.3793e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.57)
Epoch: [331][20/51]	Time  3.364 ( 3.033)	Data  2.155 ( 1.783)	Loss 2.1235e-02 (6.5048e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.78)
Epoch: [331][30/51]	Time  2.924 ( 3.036)	Data  1.657 ( 1.774)	Loss 5.5880e-03 (5.8353e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 ( 99.80)
Epoch: [331][40/51]	Time  3.002 ( 3.050)	Data  1.741 ( 1.773)	Loss 3.6128e-02 (5.6491e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 ( 99.77)
Epoch: [331][50/51]	Time  2.111 ( 3.023)	Data  0.798 ( 1.749)	Loss 2.8345e-02 (5.3161e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 ( 99.75)
learning rate is: 1.0000000000000002e-06
Epoch: [332][ 0/51]	Time  3.096 ( 3.096)	Data  1.915 ( 1.915)	Loss 2.6469e-02 (2.6469e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [332][10/51]	Time  3.247 ( 2.137)	Data  1.945 ( 1.139)	Loss 1.0162e-02 (4.0055e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.57)
Epoch: [332][20/51]	Time  2.956 ( 2.421)	Data  1.631 ( 1.314)	Loss 5.4159e-02 (3.8962e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 ( 99.78)
Epoch: [332][30/51]	Time  3.278 ( 2.615)	Data  1.976 ( 1.455)	Loss 6.3098e-02 (4.1205e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.75)
Epoch: [332][40/51]	Time  3.424 ( 2.742)	Data  2.066 ( 1.545)	Loss 2.1204e-02 (5.0970e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.62)
Epoch: [332][50/51]	Time  2.312 ( 2.788)	Data  0.945 ( 1.577)	Loss 2.3163e-01 (6.0449e-02)	Acc@1  96.77 ( 98.58)	Acc@5 100.00 ( 99.57)
learning rate is: 1.0000000000000002e-06
Epoch: [333][ 0/51]	Time  3.163 ( 3.163)	Data  1.918 ( 1.918)	Loss 2.2147e-02 (2.2147e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [333][10/51]	Time  3.249 ( 3.117)	Data  2.163 ( 1.845)	Loss 7.8020e-02 (5.1958e-02)	Acc@1  98.44 ( 99.01)	Acc@5  98.44 ( 99.57)
Epoch: [333][20/51]	Time  2.912 ( 3.116)	Data  1.599 ( 1.838)	Loss 5.2027e-03 (3.3987e-02)	Acc@1 100.00 ( 99.33)	Acc@5 100.00 ( 99.78)
Epoch: [333][30/51]	Time  3.617 ( 3.143)	Data  2.177 ( 1.853)	Loss 1.0745e-01 (4.1640e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 ( 99.80)
Epoch: [333][40/51]	Time  3.217 ( 3.120)	Data  1.917 ( 1.831)	Loss 1.1258e-02 (4.6934e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 ( 99.70)
Epoch: [333][50/51]	Time  2.029 ( 3.107)	Data  0.760 ( 1.819)	Loss 3.5095e-01 (4.9333e-02)	Acc@1  87.10 ( 98.82)	Acc@5 100.00 ( 99.72)
learning rate is: 1.0000000000000002e-06
Epoch: [334][ 0/51]	Time  2.942 ( 2.942)	Data  1.694 ( 1.694)	Loss 1.6323e-01 (1.6323e-01)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [334][10/51]	Time  3.084 ( 3.075)	Data  1.874 ( 1.801)	Loss 3.5730e-02 (5.9658e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.86)
Epoch: [334][20/51]	Time  3.176 ( 3.045)	Data  1.804 ( 1.790)	Loss 6.5854e-02 (6.3439e-02)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.93)
Epoch: [334][30/51]	Time  3.184 ( 3.053)	Data  1.727 ( 1.795)	Loss 5.8635e-03 (5.2680e-02)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.95)
Epoch: [334][40/51]	Time  3.111 ( 3.028)	Data  1.763 ( 1.773)	Loss 7.0586e-02 (4.8755e-02)	Acc@1  98.44 ( 98.67)	Acc@5  98.44 ( 99.92)
Epoch: [334][50/51]	Time  1.062 ( 2.967)	Data  0.245 ( 1.725)	Loss 1.4256e-01 (5.2558e-02)	Acc@1  96.77 ( 98.58)	Acc@5 100.00 ( 99.91)
Test: [0/8]	Time  1.042 ( 1.042)	Loss 1.4914e-01 (1.4914e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  0.656 ( 0.852)	Loss 1.6043e-01 (1.6747e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
learning rate is: 1.0000000000000002e-06
Epoch: [335][ 0/51]	Time  3.154 ( 3.154)	Data  1.988 ( 1.988)	Loss 4.8967e-02 (4.8967e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [335][10/51]	Time  2.969 ( 3.099)	Data  1.795 ( 1.855)	Loss 1.5538e-02 (6.1059e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.57)
Epoch: [335][20/51]	Time  3.025 ( 2.744)	Data  1.720 ( 1.597)	Loss 1.0712e-01 (5.6734e-02)	Acc@1  96.88 ( 98.88)	Acc@5 100.00 ( 99.70)
Epoch: [335][30/51]	Time  2.994 ( 2.845)	Data  1.646 ( 1.654)	Loss 2.6860e-02 (4.7463e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.80)
Epoch: [335][40/51]	Time  3.164 ( 2.897)	Data  1.842 ( 1.679)	Loss 2.1126e-02 (4.7367e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.73)
Epoch: [335][50/51]	Time  1.972 ( 2.897)	Data  0.739 ( 1.668)	Loss 1.3601e-01 (4.8275e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000002e-06
Epoch: [336][ 0/51]	Time  2.981 ( 2.981)	Data  1.759 ( 1.759)	Loss 2.0148e-02 (2.0148e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [336][10/51]	Time  2.303 ( 3.006)	Data  1.402 ( 1.753)	Loss 4.1326e-02 (6.6578e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [336][20/51]	Time  3.154 ( 2.939)	Data  1.811 ( 1.709)	Loss 3.0224e-02 (5.2603e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.70)
Epoch: [336][30/51]	Time  3.405 ( 2.969)	Data  2.068 ( 1.739)	Loss 6.7569e-03 (4.6743e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.80)
Epoch: [336][40/51]	Time  3.061 ( 2.975)	Data  1.756 ( 1.731)	Loss 1.1749e-02 (4.9578e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.77)
Epoch: [336][50/51]	Time  2.036 ( 2.969)	Data  0.899 ( 1.720)	Loss 1.0059e-01 (4.4607e-02)	Acc@1  96.77 ( 99.01)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000002e-06
Epoch: [337][ 0/51]	Time  2.944 ( 2.944)	Data  1.680 ( 1.680)	Loss 6.6578e-02 (6.6578e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [337][10/51]	Time  3.629 ( 3.022)	Data  2.382 ( 1.791)	Loss 1.2767e-02 (3.9462e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [337][20/51]	Time  3.099 ( 3.135)	Data  1.816 ( 1.853)	Loss 5.6872e-02 (4.6008e-02)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.85)
Epoch: [337][30/51]	Time  3.312 ( 3.134)	Data  2.010 ( 1.850)	Loss 3.7134e-02 (4.7065e-02)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.90)
Epoch: [337][40/51]	Time  2.831 ( 3.027)	Data  1.626 ( 1.781)	Loss 7.6849e-02 (5.1013e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.89)
Epoch: [337][50/51]	Time  1.975 ( 2.936)	Data  0.844 ( 1.713)	Loss 2.0884e-01 (5.0771e-02)	Acc@1  93.55 ( 98.55)	Acc@5 100.00 ( 99.88)
learning rate is: 1.0000000000000002e-06
Epoch: [338][ 0/51]	Time  2.247 ( 2.247)	Data  1.261 ( 1.261)	Loss 6.0224e-02 (6.0224e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [338][10/51]	Time  3.002 ( 2.768)	Data  1.680 ( 1.598)	Loss 5.9564e-02 (6.3727e-02)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.86)
Epoch: [338][20/51]	Time  3.366 ( 2.959)	Data  2.009 ( 1.721)	Loss 6.5987e-02 (4.7891e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 ( 99.85)
Epoch: [338][30/51]	Time  3.206 ( 3.020)	Data  1.901 ( 1.770)	Loss 9.3302e-02 (5.1674e-02)	Acc@1  96.88 ( 98.54)	Acc@5 100.00 ( 99.85)
Epoch: [338][40/51]	Time  3.051 ( 3.046)	Data  1.868 ( 1.799)	Loss 6.8635e-03 (4.7706e-02)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.85)
Epoch: [338][50/51]	Time  2.092 ( 2.986)	Data  0.821 ( 1.749)	Loss 7.7105e-02 (5.1767e-02)	Acc@1  96.77 ( 98.55)	Acc@5 100.00 ( 99.78)
learning rate is: 1.0000000000000002e-06
Epoch: [339][ 0/51]	Time  2.938 ( 2.938)	Data  1.767 ( 1.767)	Loss 6.8888e-02 (6.8888e-02)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [339][10/51]	Time  2.196 ( 2.964)	Data  1.413 ( 1.688)	Loss 6.5283e-02 (5.0934e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.86)
Epoch: [339][20/51]	Time  3.082 ( 2.972)	Data  1.883 ( 1.705)	Loss 8.2769e-02 (5.5235e-02)	Acc@1  98.44 ( 98.81)	Acc@5  98.44 ( 99.70)
Epoch: [339][30/51]	Time  3.217 ( 2.997)	Data  1.889 ( 1.738)	Loss 9.4603e-02 (5.7830e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 ( 99.70)
Epoch: [339][40/51]	Time  2.872 ( 3.059)	Data  1.512 ( 1.791)	Loss 2.3073e-02 (5.5973e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.77)
Epoch: [339][50/51]	Time  2.391 ( 3.035)	Data  1.137 ( 1.768)	Loss 9.0185e-02 (5.0856e-02)	Acc@1  96.77 ( 98.76)	Acc@5 100.00 ( 99.81)
Test: [0/8]	Time  3.242 ( 3.242)	Loss 1.3973e-01 (1.3973e-01)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Test: [5/8]	Time  1.133 ( 2.131)	Loss 1.7852e-01 (1.6739e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 ( 99.48)
 * Acc@1 95.400 Acc@5 99.600
copy config.json and customize_service.py success

Process finished with exit code 0
